{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqWTWF5EFCuV"
      },
      "source": [
        "# Anemll-Style Layer-by-Layer QAT\n",
        "\n",
        "This notebook implements layer-by-layer QAT training using `AnemllQATLinear` with:\n",
        "- Groupwise LUT quantization\n",
        "- Low-rank scale factors (A @ B)\n",
        "- KD cache for distillation\n",
        "- **Hard label loss** for improved convergence\n",
        "\n",
        "## Pipeline:\n",
        "1. Load model and replace linears with AnemllQATLinear\n",
        "2. Layer-by-layer scale optimization (weights frozen)\n",
        "3. Layer-by-layer weight training (with hard label loss)\n",
        "4. End-to-end refinement\n",
        "5. (Optional) LoRA recovery\n",
        "\n",
        "## Distillation Options:\n",
        "- `temperature`: KL divergence temperature (default: 2.0)\n",
        "- `hard_top1_weight`: Hard label top-1 loss weight (recommended: 0.1 for weights, 0.0 for scales)\n",
        "- `hard_full_weight`: Hard label full vocab loss weight (optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Kfh54i9XFCuW"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# GOOGLE DRIVE PATHS (STANDARD)\n",
        "# ============================================================\n",
        "\n",
        "# Checkpoints/runs go here\n",
        "GD_RUNS = '/content/drive/MyDrive/qwen3_runs'\n",
        "\n",
        "# KD caches go here\n",
        "GD_CACHES = '/content/drive/MyDrive/qwen3_caches'\n",
        "\n",
        "# Local directories (on Colab VM)\n",
        "LOCAL_RUNS = 'runs'\n",
        "LOCAL_CACHES = 'caches'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Tw1k9-anFCuW",
        "outputId": "9c82b0b4-4a4e-4852-b064-128804bb1430",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GITUB"
      ],
      "metadata": {
        "id": "7X9uxbCPPykd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "HtdvB50DFCuW",
        "outputId": "ea1fb98c-6e27-4765-ac42-3a22f6bf888a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'qwen3_apple_style_2bit_qat_lora'...\n",
            "remote: Enumerating objects: 449, done.\u001b[K\n",
            "remote: Counting objects: 100% (139/139), done.\u001b[K\n",
            "remote: Compressing objects: 100% (104/104), done.\u001b[K\n",
            "remote: Total 449 (delta 98), reused 68 (delta 35), pack-reused 310 (from 1)\u001b[K\n",
            "Receiving objects: 100% (449/449), 589.07 KiB | 12.02 MiB/s, done.\n",
            "Resolving deltas: 100% (289/289), done.\n",
            "/content/qwen3_apple_style_2bit_qat_lora\n",
            "Already up to date.\n",
            "HEAD is now at c577e82 Enhance logging in train_e2e function with formatted time display\n"
          ]
        }
      ],
      "source": [
        "# Clone repo if needed\n",
        "!git clone https://github.com/anemll/qwen3_apple_style_2bit_qat_lora.git || (cd qwen3_apple_style_2bit_qat_lora && git pull)\n",
        "%cd qwen3_apple_style_2bit_qat_lora\n",
        "# to allow updates\n",
        "!git fetch\n",
        "!git pull\n",
        "!git reset --hard HEAD\n",
        "import sys\n",
        "[sys.modules.pop(k) for k in list(sys.modules) if k.startswith('qat_lora')]\n",
        "\n",
        "from qat_lora import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1dJ5vGK9FCuW"
      },
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "!pip install -q transformers accelerate safetensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "hgqQOvUpFCuW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4946891f-313c-423f-e82c-0d8919f44c7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting alpaca_chat_think_both_L128_K128_R1024.tgz from Google Drive...\n",
            "total 17157672\n",
            "drwx------ 2 root root      4096 Dec 26 02:45 .\n",
            "drwxr-xr-x 3 root root      4096 Dec 29 00:46 ..\n",
            "-rw------- 1 root root       423 Dec 26 02:45 meta.json\n",
            "-rw------- 1 root root 899550149 Dec 26 02:46 shard_00000.pt\n",
            "-rw------- 1 root root 899550149 Dec 26 02:43 shard_00001.pt\n",
            "-rw------- 1 root root 899550149 Dec 26 02:44 shard_00002.pt\n",
            "-rw------- 1 root root 899550149 Dec 26 02:44 shard_00003.pt\n",
            "-rw------- 1 root root 899550149 Dec 26 02:44 shard_00004.pt\n",
            "-rw------- 1 root root 899550149 Dec 26 02:43 shard_00005.pt\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# LOAD KD CACHE FROM GOOGLE DRIVE\n",
        "# ============================================================\n",
        "\n",
        "#CACHE_NAME = 'alpaca_chat_think_both_L128_K32_R256'\n",
        "#CACHE_NAME = 'alpaca_chat_think_both_L128_K64_R512'\n",
        "CACHE_NAME = 'alpaca_chat_think_both_L128_K128_R1024'\n",
        "\n",
        "\n",
        "CACHE_TGZ = f'{CACHE_NAME}.tgz'\n",
        "\n",
        "!mkdir -p {LOCAL_CACHES}\n",
        "\n",
        "# Check if cache exists locally\n",
        "import os\n",
        "cache_local_path = f'{LOCAL_CACHES}/{CACHE_NAME}'\n",
        "if not os.path.exists(cache_local_path):\n",
        "    print(f'Extracting {CACHE_TGZ} from Google Drive...')\n",
        "    !tar -xzf {GD_CACHES}/{CACHE_TGZ} -C {LOCAL_CACHES}/\n",
        "else:\n",
        "    print(f'Cache already exists at {cache_local_path}')\n",
        "\n",
        "!ls -la {cache_local_path}/ | head -10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "EJ239_eUFCuW",
        "outputId": "3bbfadc8-4925-4980-b19d-aa02005beaa3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quality: q4_a4\n",
            "Device: cuda, dtype: torch.bfloat16\n",
            "Quant config: lut=16, group=16, rank=4\n",
            "Distillation: temp=2.0, hard_top1=0.2, hard_full=5e-05\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# CONFIGURATION\n",
        "# ============================================================\n",
        "\n",
        "import torch\n",
        "\n",
        "# Model\n",
        "MODEL_ID = 'Qwen/Qwen3-0.6B'\n",
        "\n",
        "# Quantization config (4-bit with groupwise LUT)\n",
        "LUT_BITS = 4\n",
        "LUT_SIZE = 2**LUT_BITS\n",
        "GROUP_SIZE = 16      # Group size for scales\n",
        "SCALE_RANK = 4       # Low-rank for A @ B scales\n",
        "\n",
        "# Attention quantization (same params)\n",
        "ATTN_LUT_BITS = 4\n",
        "ATTN_LUT_SIZE = 2**ATTN_LUT_BITS\n",
        "ATTN_GROUP_SIZE = 16\n",
        "ATTN_SCALE_RANK = 4\n",
        "\n",
        "# Training\n",
        "BATCH_SIZE = 4\n",
        "GRAD_ACCUM = 4\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    BATCH_SIZE=32\n",
        "    GRAD_ACCUM=1\n",
        "\n",
        "LR = 2e-5\n",
        "EPOCHS_PER_LAYER = 1\n",
        "\n",
        "# KD / Distillation params\n",
        "DISTILL_TEMP = 2.0\n",
        "HARD_TOP1_WEIGHT = 0.2    # Hard label top-1 loss (helps convergence)\n",
        "HARD_FULL_WEIGHT = 0.00005    # Hard label full vocab loss (optional)\n",
        "\n",
        "# Device\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "DTYPE = torch.bfloat16\n",
        "\n",
        "\n",
        "QUAL = f'q{LUT_BITS}_a{ATTN_LUT_BITS}'\n",
        "\n",
        "print(f'Quality: {QUAL}')\n",
        "\n",
        "print(f'Device: {DEVICE}, dtype: {DTYPE}')\n",
        "print(f'Quant config: lut={LUT_SIZE}, group={GROUP_SIZE}, rank={SCALE_RANK}')\n",
        "print(f'Distillation: temp={DISTILL_TEMP}, hard_top1={HARD_TOP1_WEIGHT}, hard_full={HARD_FULL_WEIGHT}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Extracting LOCAL CACHE\n",
        "# ============================================================\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Verify drive is mounted and cache exists\n",
        "if not os.path.exists('/content/drive/MyDrive'):\n",
        "    print('Google Drive not mounted! Mounting now...')\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "if not os.path.exists(cache_local_path):\n",
        "    print(f'Cache not found at {cache_local_path}')\n",
        "    print(f'Extracting from Google Drive...')\n",
        "    os.makedirs(LOCAL_CACHES, exist_ok=True)\n",
        "    !tar -xzf {GD_CACHES}/{CACHE_TGZ} -C {LOCAL_CACHES}/\n",
        "\n",
        "# Verify cache exists now\n",
        "assert os.path.exists(cache_local_path), f'Cache still not found at {cache_local_path}'\n",
        "cache_files = list(Path(cache_local_path).glob('*.pt'))\n",
        "print(f'Cache ready: {len(cache_files)} files in {cache_local_path}')"
      ],
      "metadata": {
        "id": "r-V8ZhsWGl1d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a29703e5-da99-49d4-9dac-ac6bc35cd1e6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cache ready: 20 files in caches/alpaca_chat_think_both_L128_K128_R1024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "5e5kQrkxFCuX",
        "outputId": "0579b2d0-ad59-4a30-bca7-a4ca78361275",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417,
          "referenced_widgets": [
            "9ceaade381e94c258a3c0ffe6b8993ee",
            "09079f4c40b24d47b16b3a9d39eac18f",
            "c1ca5e81b3884530acba75733f2b2ef3",
            "b66e47d1dccd4aaa9053968667cfafe3",
            "02947099e48c465691d6d41dcd1e877b",
            "f10f6efb961f426dba0e85b4f4fc54ba",
            "f029416c83fe4e1daf94c137e9b70038",
            "723cb77b570b43c780f7816ce9aa4f81",
            "02f92b038c3942369d6bbda0b85561bd",
            "eab5f44c082e486cbfef722597968c27",
            "c181cb34a1c44cff9f701fcb264f4639",
            "3f33d3f10a104364a08b5a972d868404",
            "e34e197865624c319e5c3efd61cec5f1",
            "e1f9a8ad18a0404f91bd633266a987c1",
            "7dafcef8629943bba8b552eb65cf4319",
            "cd45240c029a4d89bf7856dfe692f487",
            "1643098c16724226b2f135666c853021",
            "b89e33aa337d495b9c5f0afa5c4e531f",
            "cdde30488ec24b2f8ff1ac50adf677c1",
            "e4a9b6abc3bb4d72b33910184b8dee53",
            "32ddfc19754f4f3ba3fd05ceb443200b",
            "9d78c3b445ae4b4b9255f381dbbbf297",
            "6d34db691b8549708447dc4528918bd7",
            "6f4a70c1d8b443019ce0db5845dbeabe",
            "fbd65fe0ad714e719255caa92dc42988",
            "458a362e07ef46fdab537612157215fc",
            "6401e8dd76cf43c9bca85eafa9584072",
            "d28e621974114f798fa7f6f7147c18c1",
            "c4f53cf052434846851f7bb9681f06f3",
            "1a5a12de6a824d8784f0b5c8b39df05c",
            "a5c2c0a43dff4b78bd2dea20244a743b",
            "b8c783ede2f445dd8538a743155eb07d",
            "d4c27e7c0c394e75b28c3a2da7233afd",
            "7c23ec2e04e04555bcc86795b8b98a6a",
            "1222d75ab8a34dd7b4bdb4e57403b74a",
            "dcfa4ead89b34a038cbbff240f802027",
            "06e9bae2da334bfe87877b18848fc0e0",
            "b8c1d61e8f7f40d0a2dfb0aa44d9e4b2",
            "7f0f985b8ba44c80bd30840946cec59f",
            "78f024244cfa4226bb3abbdba4611ac8",
            "13407d3e50f44934ba4cc8d125319a97",
            "395b60bd9d62499ebdf4db8f98d6d060",
            "a0dc69628c774dcab4fdc057d871c71e",
            "c7550f00e5f5491e848cc033cb52d695",
            "9e9b3bbd2ed04af2983090df7fdfa860",
            "79dba7f9976e4d56ba95542576ad784e",
            "61b4ff17161a4472983d9ae7c4038f4c",
            "97e02cb7cc054c76a2a236208bd39288",
            "1e61be30fd06489997bc1073cdf4b63f",
            "cccaf0d3bbbc4d1fab88478bfde18570",
            "9cfe70d1c90d4570a537ba3ba9af8758",
            "1be8597c80774992b05b2b2a3db7e3ca",
            "58c6d1daf9dc4736ad8888fdd2e13051",
            "31c50cde54ce455484d8959587b6761e",
            "756e3d0cd08d444f974dbb4a0d03aeee",
            "aebedea1c0aa48c996f59ceff3b7f59d",
            "99f53192c01e48d28edeaa60bcc93316",
            "f8707033b6bc4ff39b211d9e79429d8f",
            "412c3035861a4d9fa384f8b8285415b7",
            "60d59a18029944c48ec1fa1e667d6c8e",
            "86ca268b812540e98715edec5bcfc312",
            "650dce7e0dfe41c5a7aad9ab6fcb4b7f",
            "69988406b6fd406ca9a657ca1164b716",
            "045937442f11451fae75cf71818f2771",
            "434330f256ed46f384bf6fa47b423b80",
            "5da05f1cfe8a4913b38c49789f367319",
            "ab4ff2b64d29443ba180766a384840b7",
            "ca7eb173d158416cbf10a5c6f485e9a1",
            "683cb5329ed749d593c4592d21095b03",
            "2e1db963227241848378d59b903e9eac",
            "fe3be4ef1c22496091ec419cba32966f",
            "d4c07e275393496f8dee96dd3168a40f",
            "b6a1ab44a70a43d3a6c3fe8be56ff1cb",
            "44606bd8389a4dd7acec4c4e8b27236f",
            "beadf9955191423587bc789d96b539b5",
            "c9ed78eb0a274a4eaa5e9115ae344042",
            "7d71667b5bf8458e846b371058fe0fca"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Qwen/Qwen3-0.6B...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9ceaade381e94c258a3c0ffe6b8993ee"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3f33d3f10a104364a08b5a972d868404"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6d34db691b8549708447dc4528918bd7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7c23ec2e04e04555bcc86795b8b98a6a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/726 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9e9b3bbd2ed04af2983090df7fdfa860"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`torch_dtype` is deprecated! Use `dtype` instead!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.50G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aebedea1c0aa48c996f59ceff3b7f59d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ab4ff2b64d29443ba180766a384840b7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded. Parameters: 596,049,920\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# LOAD MODEL\n",
        "# ============================================================\n",
        "\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "print(f'Loading {MODEL_ID}...')\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, trust_remote_code=True)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_ID,\n",
        "    torch_dtype=DTYPE,\n",
        "    trust_remote_code=True,\n",
        ")\n",
        "model.to(DEVICE)\n",
        "model.eval()\n",
        "print(f'Loaded. Parameters: {sum(p.numel() for p in model.parameters()):,}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "n29f0NexFCuX",
        "outputId": "6fae7409-4a57-489b-b378-0b493fa1b2f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking model structure...\n",
            "  Found Linear: model.layers.0.self_attn.q_proj\n",
            "  Found Linear: model.layers.0.self_attn.k_proj\n",
            "  Found Linear: model.layers.0.self_attn.v_proj\n",
            "  Found Linear: model.layers.0.self_attn.o_proj\n",
            "  Found Linear: model.layers.0.mlp.gate_proj\n",
            "Total Linear modules: 197\n",
            "\n",
            "Replacing linear layers...\n",
            "  [replaced] model.layers.0.self_attn.q_proj\n",
            "  [replaced] model.layers.0.self_attn.k_proj\n",
            "  [replaced] model.layers.0.self_attn.v_proj\n",
            "  [replaced] model.layers.0.self_attn.o_proj\n",
            "  [replaced] model.layers.0.mlp.gate_proj\n",
            "  [replaced] model.layers.0.mlp.up_proj\n",
            "  [replaced] model.layers.0.mlp.down_proj\n",
            "  [replaced] model.layers.1.self_attn.q_proj\n",
            "  [replaced] model.layers.1.self_attn.k_proj\n",
            "  [replaced] model.layers.1.self_attn.v_proj\n",
            "  [replaced] model.layers.1.self_attn.o_proj\n",
            "  [replaced] model.layers.1.mlp.gate_proj\n",
            "  [replaced] model.layers.1.mlp.up_proj\n",
            "  [replaced] model.layers.1.mlp.down_proj\n",
            "  [replaced] model.layers.2.self_attn.q_proj\n",
            "  [replaced] model.layers.2.self_attn.k_proj\n",
            "  [replaced] model.layers.2.self_attn.v_proj\n",
            "  [replaced] model.layers.2.self_attn.o_proj\n",
            "  [replaced] model.layers.2.mlp.gate_proj\n",
            "  [replaced] model.layers.2.mlp.up_proj\n",
            "  [replaced] model.layers.2.mlp.down_proj\n",
            "  [replaced] model.layers.3.self_attn.q_proj\n",
            "  [replaced] model.layers.3.self_attn.k_proj\n",
            "  [replaced] model.layers.3.self_attn.v_proj\n",
            "  [replaced] model.layers.3.self_attn.o_proj\n",
            "  [replaced] model.layers.3.mlp.gate_proj\n",
            "  [replaced] model.layers.3.mlp.up_proj\n",
            "  [replaced] model.layers.3.mlp.down_proj\n",
            "  [replaced] model.layers.4.self_attn.q_proj\n",
            "  [replaced] model.layers.4.self_attn.k_proj\n",
            "  [replaced] model.layers.4.self_attn.v_proj\n",
            "  [replaced] model.layers.4.self_attn.o_proj\n",
            "  [replaced] model.layers.4.mlp.gate_proj\n",
            "  [replaced] model.layers.4.mlp.up_proj\n",
            "  [replaced] model.layers.4.mlp.down_proj\n",
            "  [replaced] model.layers.5.self_attn.q_proj\n",
            "  [replaced] model.layers.5.self_attn.k_proj\n",
            "  [replaced] model.layers.5.self_attn.v_proj\n",
            "  [replaced] model.layers.5.self_attn.o_proj\n",
            "  [replaced] model.layers.5.mlp.gate_proj\n",
            "  [replaced] model.layers.5.mlp.up_proj\n",
            "  [replaced] model.layers.5.mlp.down_proj\n",
            "  [replaced] model.layers.6.self_attn.q_proj\n",
            "  [replaced] model.layers.6.self_attn.k_proj\n",
            "  [replaced] model.layers.6.self_attn.v_proj\n",
            "  [replaced] model.layers.6.self_attn.o_proj\n",
            "  [replaced] model.layers.6.mlp.gate_proj\n",
            "  [replaced] model.layers.6.mlp.up_proj\n",
            "  [replaced] model.layers.6.mlp.down_proj\n",
            "  [replaced] model.layers.7.self_attn.q_proj\n",
            "  [replaced] model.layers.7.self_attn.k_proj\n",
            "  [replaced] model.layers.7.self_attn.v_proj\n",
            "  [replaced] model.layers.7.self_attn.o_proj\n",
            "  [replaced] model.layers.7.mlp.gate_proj\n",
            "  [replaced] model.layers.7.mlp.up_proj\n",
            "  [replaced] model.layers.7.mlp.down_proj\n",
            "  [replaced] model.layers.8.self_attn.q_proj\n",
            "  [replaced] model.layers.8.self_attn.k_proj\n",
            "  [replaced] model.layers.8.self_attn.v_proj\n",
            "  [replaced] model.layers.8.self_attn.o_proj\n",
            "  [replaced] model.layers.8.mlp.gate_proj\n",
            "  [replaced] model.layers.8.mlp.up_proj\n",
            "  [replaced] model.layers.8.mlp.down_proj\n",
            "  [replaced] model.layers.9.self_attn.q_proj\n",
            "  [replaced] model.layers.9.self_attn.k_proj\n",
            "  [replaced] model.layers.9.self_attn.v_proj\n",
            "  [replaced] model.layers.9.self_attn.o_proj\n",
            "  [replaced] model.layers.9.mlp.gate_proj\n",
            "  [replaced] model.layers.9.mlp.up_proj\n",
            "  [replaced] model.layers.9.mlp.down_proj\n",
            "  [replaced] model.layers.10.self_attn.q_proj\n",
            "  [replaced] model.layers.10.self_attn.k_proj\n",
            "  [replaced] model.layers.10.self_attn.v_proj\n",
            "  [replaced] model.layers.10.self_attn.o_proj\n",
            "  [replaced] model.layers.10.mlp.gate_proj\n",
            "  [replaced] model.layers.10.mlp.up_proj\n",
            "  [replaced] model.layers.10.mlp.down_proj\n",
            "  [replaced] model.layers.11.self_attn.q_proj\n",
            "  [replaced] model.layers.11.self_attn.k_proj\n",
            "  [replaced] model.layers.11.self_attn.v_proj\n",
            "  [replaced] model.layers.11.self_attn.o_proj\n",
            "  [replaced] model.layers.11.mlp.gate_proj\n",
            "  [replaced] model.layers.11.mlp.up_proj\n",
            "  [replaced] model.layers.11.mlp.down_proj\n",
            "  [replaced] model.layers.12.self_attn.q_proj\n",
            "  [replaced] model.layers.12.self_attn.k_proj\n",
            "  [replaced] model.layers.12.self_attn.v_proj\n",
            "  [replaced] model.layers.12.self_attn.o_proj\n",
            "  [replaced] model.layers.12.mlp.gate_proj\n",
            "  [replaced] model.layers.12.mlp.up_proj\n",
            "  [replaced] model.layers.12.mlp.down_proj\n",
            "  [replaced] model.layers.13.self_attn.q_proj\n",
            "  [replaced] model.layers.13.self_attn.k_proj\n",
            "  [replaced] model.layers.13.self_attn.v_proj\n",
            "  [replaced] model.layers.13.self_attn.o_proj\n",
            "  [replaced] model.layers.13.mlp.gate_proj\n",
            "  [replaced] model.layers.13.mlp.up_proj\n",
            "  [replaced] model.layers.13.mlp.down_proj\n",
            "  [replaced] model.layers.14.self_attn.q_proj\n",
            "  [replaced] model.layers.14.self_attn.k_proj\n",
            "  [replaced] model.layers.14.self_attn.v_proj\n",
            "  [replaced] model.layers.14.self_attn.o_proj\n",
            "  [replaced] model.layers.14.mlp.gate_proj\n",
            "  [replaced] model.layers.14.mlp.up_proj\n",
            "  [replaced] model.layers.14.mlp.down_proj\n",
            "  [replaced] model.layers.15.self_attn.q_proj\n",
            "  [replaced] model.layers.15.self_attn.k_proj\n",
            "  [replaced] model.layers.15.self_attn.v_proj\n",
            "  [replaced] model.layers.15.self_attn.o_proj\n",
            "  [replaced] model.layers.15.mlp.gate_proj\n",
            "  [replaced] model.layers.15.mlp.up_proj\n",
            "  [replaced] model.layers.15.mlp.down_proj\n",
            "  [replaced] model.layers.16.self_attn.q_proj\n",
            "  [replaced] model.layers.16.self_attn.k_proj\n",
            "  [replaced] model.layers.16.self_attn.v_proj\n",
            "  [replaced] model.layers.16.self_attn.o_proj\n",
            "  [replaced] model.layers.16.mlp.gate_proj\n",
            "  [replaced] model.layers.16.mlp.up_proj\n",
            "  [replaced] model.layers.16.mlp.down_proj\n",
            "  [replaced] model.layers.17.self_attn.q_proj\n",
            "  [replaced] model.layers.17.self_attn.k_proj\n",
            "  [replaced] model.layers.17.self_attn.v_proj\n",
            "  [replaced] model.layers.17.self_attn.o_proj\n",
            "  [replaced] model.layers.17.mlp.gate_proj\n",
            "  [replaced] model.layers.17.mlp.up_proj\n",
            "  [replaced] model.layers.17.mlp.down_proj\n",
            "  [replaced] model.layers.18.self_attn.q_proj\n",
            "  [replaced] model.layers.18.self_attn.k_proj\n",
            "  [replaced] model.layers.18.self_attn.v_proj\n",
            "  [replaced] model.layers.18.self_attn.o_proj\n",
            "  [replaced] model.layers.18.mlp.gate_proj\n",
            "  [replaced] model.layers.18.mlp.up_proj\n",
            "  [replaced] model.layers.18.mlp.down_proj\n",
            "  [replaced] model.layers.19.self_attn.q_proj\n",
            "  [replaced] model.layers.19.self_attn.k_proj\n",
            "  [replaced] model.layers.19.self_attn.v_proj\n",
            "  [replaced] model.layers.19.self_attn.o_proj\n",
            "  [replaced] model.layers.19.mlp.gate_proj\n",
            "  [replaced] model.layers.19.mlp.up_proj\n",
            "  [replaced] model.layers.19.mlp.down_proj\n",
            "  [replaced] model.layers.20.self_attn.q_proj\n",
            "  [replaced] model.layers.20.self_attn.k_proj\n",
            "  [replaced] model.layers.20.self_attn.v_proj\n",
            "  [replaced] model.layers.20.self_attn.o_proj\n",
            "  [replaced] model.layers.20.mlp.gate_proj\n",
            "  [replaced] model.layers.20.mlp.up_proj\n",
            "  [replaced] model.layers.20.mlp.down_proj\n",
            "  [replaced] model.layers.21.self_attn.q_proj\n",
            "  [replaced] model.layers.21.self_attn.k_proj\n",
            "  [replaced] model.layers.21.self_attn.v_proj\n",
            "  [replaced] model.layers.21.self_attn.o_proj\n",
            "  [replaced] model.layers.21.mlp.gate_proj\n",
            "  [replaced] model.layers.21.mlp.up_proj\n",
            "  [replaced] model.layers.21.mlp.down_proj\n",
            "  [replaced] model.layers.22.self_attn.q_proj\n",
            "  [replaced] model.layers.22.self_attn.k_proj\n",
            "  [replaced] model.layers.22.self_attn.v_proj\n",
            "  [replaced] model.layers.22.self_attn.o_proj\n",
            "  [replaced] model.layers.22.mlp.gate_proj\n",
            "  [replaced] model.layers.22.mlp.up_proj\n",
            "  [replaced] model.layers.22.mlp.down_proj\n",
            "  [replaced] model.layers.23.self_attn.q_proj\n",
            "  [replaced] model.layers.23.self_attn.k_proj\n",
            "  [replaced] model.layers.23.self_attn.v_proj\n",
            "  [replaced] model.layers.23.self_attn.o_proj\n",
            "  [replaced] model.layers.23.mlp.gate_proj\n",
            "  [replaced] model.layers.23.mlp.up_proj\n",
            "  [replaced] model.layers.23.mlp.down_proj\n",
            "  [replaced] model.layers.24.self_attn.q_proj\n",
            "  [replaced] model.layers.24.self_attn.k_proj\n",
            "  [replaced] model.layers.24.self_attn.v_proj\n",
            "  [replaced] model.layers.24.self_attn.o_proj\n",
            "  [replaced] model.layers.24.mlp.gate_proj\n",
            "  [replaced] model.layers.24.mlp.up_proj\n",
            "  [replaced] model.layers.24.mlp.down_proj\n",
            "  [replaced] model.layers.25.self_attn.q_proj\n",
            "  [replaced] model.layers.25.self_attn.k_proj\n",
            "  [replaced] model.layers.25.self_attn.v_proj\n",
            "  [replaced] model.layers.25.self_attn.o_proj\n",
            "  [replaced] model.layers.25.mlp.gate_proj\n",
            "  [replaced] model.layers.25.mlp.up_proj\n",
            "  [replaced] model.layers.25.mlp.down_proj\n",
            "  [replaced] model.layers.26.self_attn.q_proj\n",
            "  [replaced] model.layers.26.self_attn.k_proj\n",
            "  [replaced] model.layers.26.self_attn.v_proj\n",
            "  [replaced] model.layers.26.self_attn.o_proj\n",
            "  [replaced] model.layers.26.mlp.gate_proj\n",
            "  [replaced] model.layers.26.mlp.up_proj\n",
            "  [replaced] model.layers.26.mlp.down_proj\n",
            "  [replaced] model.layers.27.self_attn.q_proj\n",
            "  [replaced] model.layers.27.self_attn.k_proj\n",
            "  [replaced] model.layers.27.self_attn.v_proj\n",
            "  [replaced] model.layers.27.self_attn.o_proj\n",
            "  [replaced] model.layers.27.mlp.gate_proj\n",
            "  [replaced] model.layers.27.mlp.up_proj\n",
            "  [replaced] model.layers.27.mlp.down_proj\n",
            "\n",
            "Replaced 196 layers\n",
            "\n",
            "Verification: 0 AnemllQATLinear modules in model\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# REPLACE LINEARS WITH AnemllQATLinear\n",
        "# ============================================================\n",
        "\n",
        "import sys\n",
        "sys.path.insert(0, '.')\n",
        "\n",
        "# Force reimport to get latest code\n",
        "import importlib\n",
        "import qat_lora\n",
        "importlib.reload(qat_lora)\n",
        "import qat_lora.ane_qat_linear as ane_module\n",
        "importlib.reload(ane_module)\n",
        "import qat_lora.layer_qat as layer_module\n",
        "importlib.reload(layer_module)\n",
        "\n",
        "from qat_lora import AnemllQuantConfig, replace_linear_with_anemll\n",
        "\n",
        "# Debug: Check what modules exist in the model\n",
        "print(\"Checking model structure...\")\n",
        "import torch.nn as nn\n",
        "linear_count = 0\n",
        "for name, m in model.named_modules():\n",
        "    if isinstance(m, nn.Linear):\n",
        "        linear_count += 1\n",
        "        if linear_count <= 5:\n",
        "            print(f\"  Found Linear: {name}\")\n",
        "print(f\"Total Linear modules: {linear_count}\")\n",
        "\n",
        "# Create configs\n",
        "mlp_config = AnemllQuantConfig(\n",
        "    lut_size=LUT_SIZE,\n",
        "    group_size=GROUP_SIZE,\n",
        "    scale_rank=SCALE_RANK,\n",
        "    learnable_lut=False,\n",
        ")\n",
        "\n",
        "attn_config = AnemllQuantConfig(\n",
        "    lut_size=ATTN_LUT_SIZE,\n",
        "    group_size=ATTN_GROUP_SIZE,\n",
        "    scale_rank=ATTN_SCALE_RANK,\n",
        "    learnable_lut=False,\n",
        ")\n",
        "\n",
        "print('\\nReplacing linear layers...')\n",
        "count = replace_linear_with_anemll(\n",
        "    model,\n",
        "    mlp_config=mlp_config,\n",
        "    attn_config=attn_config,\n",
        "    quantize_attn=True,\n",
        "    quantize_lm_head=False,\n",
        ")\n",
        "\n",
        "# Verify replacement worked\n",
        "from qat_lora import AnemllQATLinear\n",
        "qat_count = sum(1 for _, m in model.named_modules() if isinstance(m, AnemllQATLinear))\n",
        "print(f\"\\nVerification: {qat_count} AnemllQATLinear modules in model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "D_gOyY1qFCuX",
        "outputId": "844dd8ce-8ccb-4052-8f87-627c7539416c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer QAT utilities imported from qat_lora\n",
            "\n",
            "Verifying gradient flow...\n",
            "ERROR: No AnemllQATLinear modules found! Replacement failed.\n",
            "\n",
            "Computing initial KD loss...\n",
            "Initial KD Loss: 1.6692\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# IMPORT LAYER-BY-LAYER QAT UTILITIES & VERIFY GRADIENTS\n",
        "# ============================================================\n",
        "\n",
        "from qat_lora import (\n",
        "    evaluate_kd_loss,\n",
        "    train_all_layers,\n",
        "    AnemllQATLinear,\n",
        ")\n",
        "\n",
        "print('Layer QAT utilities imported from qat_lora')\n",
        "\n",
        "# Verify gradient flow works\n",
        "print('\\nVerifying gradient flow...')\n",
        "layer0 = model.model.layers[0]\n",
        "test_module = None\n",
        "for name, m in layer0.named_modules():\n",
        "    if isinstance(m, AnemllQATLinear):\n",
        "        test_module = m\n",
        "        break\n",
        "\n",
        "if test_module is None:\n",
        "    print(\"ERROR: No AnemllQATLinear modules found! Replacement failed.\")\n",
        "else:\n",
        "    # Test gradient flow\n",
        "    test_module.weight.requires_grad = True\n",
        "    x = torch.randn(1, 10, test_module.in_features, device=DEVICE, dtype=DTYPE)\n",
        "    y = test_module(x)\n",
        "    loss = y.sum()\n",
        "    try:\n",
        "        loss.backward()\n",
        "        if test_module.weight.grad is not None:\n",
        "            print(f\"  Gradient OK: weight.grad.shape = {test_module.weight.grad.shape}\")\n",
        "            test_module.weight.grad = None  # Clear for actual training\n",
        "        else:\n",
        "            print(\"  ERROR: weight.grad is None after backward!\")\n",
        "    except Exception as e:\n",
        "        print(f\"  ERROR during backward: {e}\")\n",
        "\n",
        "# Compute initial KD loss\n",
        "print('\\nComputing initial KD loss...')\n",
        "initial_loss = evaluate_kd_loss(model, cache_local_path, DEVICE, num_samples=40, temperature=DISTILL_TEMP)\n",
        "print(f'Initial KD Loss: {initial_loss:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **SCALE OPTIMIZATION** (Weights Frozen)\n",
        "\n",
        "After layer-by-layer QAT on weights, optimize the per-weight scales (A @ B) to further reduce quantization error.\n",
        "\n",
        "- Weights are **frozen**\n",
        "- Only `scale_A` and `scale_B` are trained\n",
        "- Much fewer parameters → can use higher learning rate"
      ],
      "metadata": {
        "id": "9B4uAJDNfRgs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# LAYER-BY-LAYER SCALE OPTIMIZATION\n",
        "# ============================================================\n",
        "# Freeze weights, only train scale_A and scale_B tensors\n",
        "# Higher LR since fewer parameters\n",
        "# Note: Hard label loss not needed for scale optimization\n",
        "\n",
        "SCALE_LR = 1e-3  # Higher LR for scales (fewer params)\n",
        "SCALE_EPOCHS = 2  # More epochs since scales have less capacity\n",
        "\n",
        "\n",
        "print('Starting scale-only layer-by-layer optimization...')\n",
        "print(f'LR: {SCALE_LR}, Epochs per layer: {SCALE_EPOCHS}')\n",
        "\n",
        "# Get loss before scale optimization\n",
        "pre_scale_loss = evaluate_kd_loss(model, cache_local_path, DEVICE, num_samples=40)\n",
        "print(f'KD Loss before scale optimization: {pre_scale_loss:.4f}')\n",
        "\n",
        "# Train scales layer-by-layer (no hard label needed for scales)\n",
        "scale_losses = train_all_layers(\n",
        "    model=model,\n",
        "    cache_dir=cache_local_path,\n",
        "    device=DEVICE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    lr=SCALE_LR,\n",
        "    epochs_per_layer=SCALE_EPOCHS,\n",
        "    grad_accum=GRAD_ACCUM,\n",
        "    temperature=DISTILL_TEMP,\n",
        "    train_weights=False,  # Freeze weights\n",
        "    train_scales=True,    # Train scales only\n",
        "    local_weight=0.5,\n",
        "    global_weight=0.5,\n",
        "    hard_top1_weight=0.0,  # Not needed for scale optimization\n",
        "    hard_full_weight=0.0,\n",
        "    verbose=True,\n",
        "    steps_per_layer=100,\n",
        ")\n",
        "\n",
        "# Evaluate after scale optimization\n",
        "post_scale_loss = evaluate_kd_loss(model, cache_local_path, DEVICE, num_samples=40)\n",
        "print(f'\\n=== Scale Optimization Results ===')\n",
        "print(f'Before: {pre_scale_loss:.4f}')\n",
        "print(f'After:  {post_scale_loss:.4f}')\n",
        "print(f'Improvement: {pre_scale_loss - post_scale_loss:.4f}')"
      ],
      "metadata": {
        "id": "cQ1kq2a9fRgs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **RUN** LAYER-BY-LAYER TRAINING"
      ],
      "metadata": {
        "id": "o2veFRWaQEkB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gupQzmm5FCuX"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# LAYER-BY-LAYER WEIGHT TRAINING\n",
        "# ============================================================\n",
        "# Train weights with hard label loss for better convergence\n",
        "\n",
        "print('Starting layer-by-layer weight training...')\n",
        "print(f'LR: {LR}, Hard label: top1={HARD_TOP1_WEIGHT}, full={HARD_FULL_WEIGHT}')\n",
        "\n",
        "# Train all layers using the imported function\n",
        "layer_losses = train_all_layers(\n",
        "    model=model,\n",
        "    cache_dir=cache_local_path,\n",
        "    device=DEVICE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    lr=LR,\n",
        "    epochs_per_layer=EPOCHS_PER_LAYER,\n",
        "    grad_accum=GRAD_ACCUM,\n",
        "    temperature=DISTILL_TEMP,\n",
        "    train_weights=True,   # Train weights\n",
        "    train_scales=False,   # Keep scales frozen for now\n",
        "    local_weight=0.5,\n",
        "    global_weight=0.5,\n",
        "    hard_top1_weight=HARD_TOP1_WEIGHT,  # Helps convergence\n",
        "    hard_full_weight=HARD_FULL_WEIGHT,\n",
        "    verbose=True,\n",
        "    steps_per_layer=100,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uv6rcQvuFCuX"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# EVALUATE AFTER LAYER-BY-LAYER\n",
        "# ============================================================\n",
        "\n",
        "model.eval()\n",
        "post_layer_loss = evaluate_kd_loss(model, cache_local_path, DEVICE, num_samples=40)\n",
        "print(f'Initial KD Loss: {initial_loss:.4f}')\n",
        "print(f'After Layer-by-Layer: {post_layer_loss:.4f}')\n",
        "print(f'Improvement: {initial_loss - post_layer_loss:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lxSBHcq6FCuX"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# SAVE CHECKPOINT\n",
        "# ============================================================\n",
        "\n",
        "import os\n",
        "\n",
        "RUN_NAME = f'anemll_{QUAL}_layer_by_layer_v1'\n",
        "SAVE_DIR = f'{LOCAL_RUNS}/{RUN_NAME}'\n",
        "\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "\n",
        "# Save state dict\n",
        "torch.save(model.state_dict(), f'{SAVE_DIR}/model_state_dict.pt')\n",
        "\n",
        "# Save config\n",
        "import json\n",
        "config = {\n",
        "    'model_id': MODEL_ID,\n",
        "    'lut_size': LUT_SIZE,\n",
        "    'group_size': GROUP_SIZE,\n",
        "    'scale_rank': SCALE_RANK,\n",
        "    'attn_lut_size': ATTN_LUT_SIZE,\n",
        "    'attn_group_size': ATTN_GROUP_SIZE,\n",
        "    'attn_scale_rank': ATTN_SCALE_RANK,\n",
        "    'initial_kd_loss': initial_loss,\n",
        "    'post_layer_loss': post_layer_loss,\n",
        "    'layer_losses': layer_losses,\n",
        "}\n",
        "with open(f'{SAVE_DIR}/config.json', 'w') as f:\n",
        "    json.dump(config, f, indent=2)\n",
        "\n",
        "print(f'Saved to {SAVE_DIR}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R4wh-UVDFCuX"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# UPLOAD TO GOOGLE DRIVE\n",
        "# ============================================================\n",
        "\n",
        "!tar -czvf {RUN_NAME}.tgz -C {LOCAL_RUNS} {RUN_NAME}\n",
        "!cp {RUN_NAME}.tgz {GD_RUNS}/\n",
        "print(f'Uploaded to {GD_RUNS}/{RUN_NAME}.tgz')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **END-TO-END KD-QAT REFINEMENT**\n",
        "\n",
        "After layer-by-layer training, refine the model with all layers unfrozen.\n",
        "\n",
        "Two modes:\n",
        "1. **Train weights** (scales frozen) - Fine-tune weights globally with hard label loss\n",
        "2. **Train scales** (weights frozen) - Optimize scales for better quantization\n",
        "\n",
        "## Distillation Options\n",
        "\n",
        "| Parameter | Weight Training | Scale Training |\n",
        "|-----------|----------------|----------------|\n",
        "| `temperature` | 2.0 | 2.0 |\n",
        "| `hard_top1_weight` | 0.1 (recommended) | 0.0 |\n",
        "| `hard_full_weight` | 0.0 | 0.0 |\n",
        "\n",
        "Hard label loss helps prevent divergence during weight training."
      ],
      "metadata": {
        "id": "SpN8WSKqD2hK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# END-TO-END KD-QAT: TRAIN SCALES (WEIGHTS FROZEN)\n",
        "# ============================================================\n",
        "# Scale training doesn't need hard label loss\n",
        "\n",
        "# Train scales (weights frozen) - higher LR since fewer params\n",
        "e2e_scales_result = train_e2e(\n",
        "    model=model,\n",
        "    cache_dir=cache_local_path,\n",
        "    device=DEVICE,\n",
        "    max_steps=4000,\n",
        "    batch_size=64 if torch.cuda.is_available() else 32,\n",
        "    lr=5e-4,  # Higher LR for scales\n",
        "    use_cosine_schedule=True,\n",
        "    warmup_steps=100,          # Linear warmup\n",
        "    min_lr_ratio=0.1,      # End at 5e-5\n",
        "    temperature=DISTILL_TEMP,\n",
        "    train_weights=False,\n",
        "    train_scales=True,\n",
        "    hard_top1_weight=0.0,  # Not needed for scale training\n",
        "    hard_full_weight=0.0,\n",
        "    logging_steps=20,\n",
        "    eval_steps=100,\n",
        "    verbose=True,\n",
        "    train_mlp_only=True,  # ← Freeze attention (4-bit), train MLP (2-bit) only\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrQA3CXHD2hK",
        "outputId": "c700ad21-feda-49c7-b895-919a613bcca6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== End-to-End KD-QAT ===\n",
            "Mode: scales (MLP only)\n",
            "Trainable params: 1,376,256\n",
            "Frozen attention params: 177,307,648\n",
            "Steps: 4000, LR: 0.0005, Batch: 64\n",
            "LR Schedule: warmup=100, cosine→5.00e-05\n",
            "\n",
            "Initial KD Loss: 1.6692\n",
            "[20/4000] loss=1.5389 lr=1.00e-04 (0:12, ETA 42:31)\n",
            "[40/4000] loss=1.0328 lr=2.00e-04 (0:20, ETA 33:18)\n",
            "[60/4000] loss=0.7492 lr=3.00e-04 (0:27, ETA 30:08)\n",
            "[80/4000] loss=0.6013 lr=4.00e-04 (0:34, ETA 28:29)\n",
            "[100/4000] loss=0.5284 lr=5.00e-04 (0:42, ETA 27:48)\n",
            "  [Eval] KD Loss: 0.5085 (best: 1.6692)\n",
            "[120/4000] loss=0.4974 lr=5.00e-04 (0:55, ETA 30:06)\n",
            "[140/4000] loss=0.4700 lr=5.00e-04 (1:03, ETA 29:03)\n",
            "[160/4000] loss=0.4445 lr=5.00e-04 (1:10, ETA 28:13)\n",
            "[180/4000] loss=0.4349 lr=5.00e-04 (1:18, ETA 27:45)\n",
            "[200/4000] loss=0.4200 lr=4.99e-04 (1:25, ETA 27:10)\n",
            "  [Eval] KD Loss: 0.4008 (best: 0.5085)\n",
            "[220/4000] loss=0.4154 lr=4.99e-04 (1:38, ETA 28:18)\n",
            "[240/4000] loss=0.4169 lr=4.99e-04 (1:46, ETA 27:42)\n",
            "[260/4000] loss=0.4216 lr=4.98e-04 (1:53, ETA 27:10)\n",
            "[280/4000] loss=0.4070 lr=4.98e-04 (2:00, ETA 26:42)\n",
            "[300/4000] loss=0.4064 lr=4.97e-04 (2:08, ETA 26:22)\n",
            "  [Eval] KD Loss: 0.3878 (best: 0.4008)\n",
            "[320/4000] loss=0.3913 lr=4.96e-04 (2:20, ETA 26:54)\n",
            "[340/4000] loss=0.3861 lr=4.96e-04 (2:27, ETA 26:29)\n",
            "[360/4000] loss=0.3788 lr=4.95e-04 (2:34, ETA 26:06)\n",
            "[380/4000] loss=0.3982 lr=4.94e-04 (2:42, ETA 25:48)\n",
            "[400/4000] loss=0.3839 lr=4.93e-04 (2:49, ETA 25:28)\n",
            "  [Eval] KD Loss: 0.3855 (best: 0.3878)\n",
            "[420/4000] loss=0.3782 lr=4.93e-04 (3:02, ETA 25:54)\n",
            "[440/4000] loss=0.3783 lr=4.92e-04 (3:09, ETA 25:33)\n",
            "[460/4000] loss=0.3900 lr=4.91e-04 (3:17, ETA 25:16)\n",
            "[480/4000] loss=0.3842 lr=4.90e-04 (3:26, ETA 25:13)\n",
            "[500/4000] loss=0.3841 lr=4.88e-04 (3:34, ETA 24:58)\n",
            "  [Eval] KD Loss: 0.3888 (best: 0.3855)\n",
            "[520/4000] loss=0.3790 lr=4.87e-04 (3:45, ETA 25:12)\n",
            "[540/4000] loss=0.3780 lr=4.86e-04 (3:53, ETA 24:54)\n",
            "[560/4000] loss=0.3781 lr=4.85e-04 (4:00, ETA 24:37)\n",
            "[580/4000] loss=0.3819 lr=4.83e-04 (4:08, ETA 24:23)\n",
            "[600/4000] loss=0.3792 lr=4.82e-04 (4:15, ETA 24:07)\n",
            "  [Eval] KD Loss: 0.3541 (best: 0.3855)\n",
            "[620/4000] loss=0.3744 lr=4.81e-04 (4:28, ETA 24:21)\n",
            "[640/4000] loss=0.3671 lr=4.79e-04 (4:35, ETA 24:04)\n",
            "[660/4000] loss=0.3623 lr=4.77e-04 (4:42, ETA 23:51)\n",
            "[680/4000] loss=0.3562 lr=4.76e-04 (4:50, ETA 23:36)\n",
            "[700/4000] loss=0.3530 lr=4.74e-04 (4:57, ETA 23:22)\n",
            "  [Eval] KD Loss: 0.3360 (best: 0.3541)\n",
            "[720/4000] loss=0.3525 lr=4.73e-04 (5:09, ETA 23:32)\n",
            "[740/4000] loss=0.3615 lr=4.71e-04 (5:17, ETA 23:19)\n",
            "[760/4000] loss=0.3657 lr=4.69e-04 (5:24, ETA 23:05)\n",
            "[780/4000] loss=0.3761 lr=4.67e-04 (5:32, ETA 22:51)\n",
            "[800/4000] loss=0.3599 lr=4.65e-04 (5:39, ETA 22:38)\n",
            "  [Eval] KD Loss: 0.3448 (best: 0.3360)\n",
            "[820/4000] loss=0.3689 lr=4.63e-04 (5:51, ETA 22:44)\n",
            "[840/4000] loss=0.3663 lr=4.61e-04 (5:59, ETA 22:31)\n",
            "[860/4000] loss=0.3629 lr=4.59e-04 (6:06, ETA 22:18)\n",
            "[880/4000] loss=0.3634 lr=4.57e-04 (6:13, ETA 22:05)\n",
            "[900/4000] loss=0.3624 lr=4.55e-04 (6:21, ETA 21:53)\n",
            "  [Eval] KD Loss: 0.3510 (best: 0.3360)\n",
            "[920/4000] loss=0.3607 lr=4.53e-04 (6:33, ETA 21:56)\n",
            "[940/4000] loss=0.3696 lr=4.50e-04 (6:40, ETA 21:43)\n",
            "[960/4000] loss=0.3441 lr=4.48e-04 (6:47, ETA 21:31)\n",
            "[980/4000] loss=0.3522 lr=4.46e-04 (6:55, ETA 21:20)\n",
            "[1000/4000] loss=0.3512 lr=4.43e-04 (7:02, ETA 21:08)\n",
            "  [Eval] KD Loss: 0.3489 (best: 0.3360)\n",
            "[1020/4000] loss=0.3490 lr=4.41e-04 (7:14, ETA 21:10)\n",
            "[1040/4000] loss=0.3557 lr=4.39e-04 (7:21, ETA 20:57)\n",
            "[1060/4000] loss=0.3569 lr=4.36e-04 (7:29, ETA 20:47)\n",
            "[1080/4000] loss=0.3500 lr=4.33e-04 (7:37, ETA 20:35)\n",
            "[1100/4000] loss=0.3549 lr=4.31e-04 (7:44, ETA 20:24)\n",
            "  [Eval] KD Loss: 0.3487 (best: 0.3360)\n",
            "[1120/4000] loss=0.3531 lr=4.28e-04 (7:56, ETA 20:24)\n",
            "[1140/4000] loss=0.3477 lr=4.26e-04 (8:04, ETA 20:14)\n",
            "[1160/4000] loss=0.3460 lr=4.23e-04 (8:11, ETA 20:02)\n",
            "[1180/4000] loss=0.3485 lr=4.20e-04 (8:18, ETA 19:51)\n",
            "[1200/4000] loss=0.3451 lr=4.17e-04 (8:25, ETA 19:40)\n",
            "  [Eval] KD Loss: 0.3268 (best: 0.3360)\n",
            "[1220/4000] loss=0.3456 lr=4.14e-04 (8:38, ETA 19:42)\n",
            "[1240/4000] loss=0.3554 lr=4.12e-04 (8:46, ETA 19:31)\n",
            "[1260/4000] loss=0.3471 lr=4.09e-04 (8:53, ETA 19:19)\n",
            "[1280/4000] loss=0.3502 lr=4.06e-04 (9:00, ETA 19:08)\n",
            "[1300/4000] loss=0.3421 lr=4.03e-04 (9:07, ETA 18:57)\n",
            "  [Eval] KD Loss: 0.3339 (best: 0.3268)\n",
            "[1320/4000] loss=0.3338 lr=4.00e-04 (9:20, ETA 18:56)\n",
            "[1340/4000] loss=0.3440 lr=3.97e-04 (9:27, ETA 18:46)\n",
            "[1360/4000] loss=0.3472 lr=3.94e-04 (9:34, ETA 18:35)\n",
            "[1380/4000] loss=0.3355 lr=3.91e-04 (9:41, ETA 18:24)\n",
            "[1400/4000] loss=0.3351 lr=3.88e-04 (9:49, ETA 18:14)\n",
            "  [Eval] KD Loss: 0.3133 (best: 0.3268)\n",
            "[1420/4000] loss=0.3368 lr=3.84e-04 (10:02, ETA 18:13)\n",
            "[1440/4000] loss=0.3447 lr=3.81e-04 (10:09, ETA 18:03)\n",
            "[1460/4000] loss=0.3374 lr=3.78e-04 (10:16, ETA 17:52)\n",
            "[1480/4000] loss=0.3397 lr=3.75e-04 (10:24, ETA 17:43)\n",
            "[1500/4000] loss=0.3415 lr=3.71e-04 (10:31, ETA 17:32)\n",
            "  [Eval] KD Loss: 0.3305 (best: 0.3133)\n",
            "[1520/4000] loss=0.3355 lr=3.68e-04 (10:43, ETA 17:30)\n",
            "[1540/4000] loss=0.3399 lr=3.65e-04 (10:51, ETA 17:19)\n",
            "[1560/4000] loss=0.3412 lr=3.62e-04 (10:58, ETA 17:09)\n",
            "[1580/4000] loss=0.3219 lr=3.58e-04 (11:05, ETA 16:59)\n",
            "[1600/4000] loss=0.3230 lr=3.55e-04 (11:13, ETA 16:49)\n",
            "  [Eval] KD Loss: 0.3327 (best: 0.3133)\n",
            "[1620/4000] loss=0.3439 lr=3.51e-04 (11:25, ETA 16:46)\n",
            "[1640/4000] loss=0.3327 lr=3.48e-04 (11:32, ETA 16:36)\n",
            "[1660/4000] loss=0.3336 lr=3.45e-04 (11:39, ETA 16:26)\n",
            "[1680/4000] loss=0.3429 lr=3.41e-04 (11:47, ETA 16:16)\n",
            "[1700/4000] loss=0.3342 lr=3.38e-04 (11:54, ETA 16:06)\n",
            "  [Eval] KD Loss: 0.3153 (best: 0.3133)\n",
            "[1720/4000] loss=0.3327 lr=3.34e-04 (12:06, ETA 16:03)\n",
            "[1740/4000] loss=0.3326 lr=3.31e-04 (12:14, ETA 15:53)\n",
            "[1760/4000] loss=0.3419 lr=3.27e-04 (12:21, ETA 15:43)\n",
            "[1780/4000] loss=0.3368 lr=3.24e-04 (12:28, ETA 15:33)\n",
            "[1800/4000] loss=0.3373 lr=3.20e-04 (12:36, ETA 15:24)\n",
            "  [Eval] KD Loss: 0.3279 (best: 0.3133)\n",
            "[1820/4000] loss=0.3375 lr=3.16e-04 (12:48, ETA 15:20)\n",
            "[1840/4000] loss=0.3395 lr=3.13e-04 (12:55, ETA 15:10)\n",
            "[1860/4000] loss=0.3377 lr=3.09e-04 (13:02, ETA 15:00)\n",
            "[1880/4000] loss=0.3268 lr=3.06e-04 (13:10, ETA 14:51)\n",
            "[1900/4000] loss=0.3270 lr=3.02e-04 (13:17, ETA 14:41)\n",
            "  [Eval] KD Loss: 0.3258 (best: 0.3133)\n",
            "[1920/4000] loss=0.3244 lr=2.99e-04 (13:29, ETA 14:37)\n",
            "[1940/4000] loss=0.3266 lr=2.95e-04 (13:36, ETA 14:27)\n",
            "[1960/4000] loss=0.3284 lr=2.91e-04 (13:44, ETA 14:18)\n",
            "[1980/4000] loss=0.3238 lr=2.88e-04 (13:51, ETA 14:08)\n",
            "[2000/4000] loss=0.3257 lr=2.84e-04 (13:59, ETA 13:59)\n",
            "  [Eval] KD Loss: 0.3133 (best: 0.3133)\n",
            "[2020/4000] loss=0.3285 lr=2.80e-04 (14:11, ETA 13:54)\n",
            "[2040/4000] loss=0.3291 lr=2.77e-04 (14:18, ETA 13:44)\n",
            "[2060/4000] loss=0.3273 lr=2.73e-04 (14:25, ETA 13:35)\n",
            "[2080/4000] loss=0.3244 lr=2.70e-04 (14:33, ETA 13:26)\n",
            "[2100/4000] loss=0.3305 lr=2.66e-04 (14:40, ETA 13:16)\n",
            "  [Eval] KD Loss: 0.3202 (best: 0.3133)\n",
            "[2120/4000] loss=0.3362 lr=2.62e-04 (14:52, ETA 13:11)\n",
            "[2140/4000] loss=0.3333 lr=2.59e-04 (15:00, ETA 13:02)\n",
            "[2160/4000] loss=0.3182 lr=2.55e-04 (15:07, ETA 12:53)\n",
            "[2180/4000] loss=0.3291 lr=2.51e-04 (15:15, ETA 12:43)\n",
            "[2200/4000] loss=0.3273 lr=2.48e-04 (15:22, ETA 12:34)\n",
            "  [Eval] KD Loss: 0.3234 (best: 0.3133)\n",
            "[2220/4000] loss=0.3171 lr=2.44e-04 (15:34, ETA 12:29)\n",
            "[2240/4000] loss=0.3218 lr=2.41e-04 (15:41, ETA 12:20)\n",
            "[2260/4000] loss=0.3280 lr=2.37e-04 (15:49, ETA 12:10)\n",
            "[2280/4000] loss=0.3141 lr=2.34e-04 (15:56, ETA 12:01)\n",
            "[2300/4000] loss=0.3274 lr=2.30e-04 (16:04, ETA 11:52)\n",
            "  [Eval] KD Loss: 0.3109 (best: 0.3133)\n",
            "[2320/4000] loss=0.3292 lr=2.26e-04 (16:17, ETA 11:47)\n",
            "[2340/4000] loss=0.3212 lr=2.23e-04 (16:24, ETA 11:38)\n",
            "[2360/4000] loss=0.3139 lr=2.19e-04 (16:31, ETA 11:29)\n",
            "[2380/4000] loss=0.3238 lr=2.16e-04 (16:39, ETA 11:20)\n",
            "[2400/4000] loss=0.3237 lr=2.12e-04 (16:46, ETA 11:11)\n",
            "  [Eval] KD Loss: 0.3153 (best: 0.3109)\n",
            "[2420/4000] loss=0.3270 lr=2.09e-04 (16:58, ETA 11:05)\n",
            "[2440/4000] loss=0.3246 lr=2.05e-04 (17:05, ETA 10:55)\n",
            "[2460/4000] loss=0.3219 lr=2.02e-04 (17:13, ETA 10:46)\n",
            "[2480/4000] loss=0.3211 lr=1.99e-04 (17:20, ETA 10:37)\n",
            "[2500/4000] loss=0.3235 lr=1.95e-04 (17:27, ETA 10:28)\n",
            "  [Eval] KD Loss: 0.3196 (best: 0.3109)\n",
            "[2520/4000] loss=0.3220 lr=1.92e-04 (17:39, ETA 10:22)\n",
            "[2540/4000] loss=0.3174 lr=1.88e-04 (17:47, ETA 10:13)\n",
            "[2560/4000] loss=0.3230 lr=1.85e-04 (17:54, ETA 10:04)\n",
            "[2580/4000] loss=0.3139 lr=1.82e-04 (18:01, ETA 9:55)\n",
            "[2600/4000] loss=0.3172 lr=1.79e-04 (18:09, ETA 9:46)\n",
            "  [Eval] KD Loss: 0.3127 (best: 0.3109)\n",
            "[2620/4000] loss=0.3178 lr=1.75e-04 (18:21, ETA 9:40)\n",
            "[2640/4000] loss=0.3186 lr=1.72e-04 (18:28, ETA 9:31)\n",
            "[2660/4000] loss=0.3192 lr=1.69e-04 (18:36, ETA 9:22)\n",
            "[2680/4000] loss=0.3170 lr=1.66e-04 (18:43, ETA 9:13)\n",
            "[2700/4000] loss=0.3176 lr=1.63e-04 (18:50, ETA 9:04)\n",
            "  [Eval] KD Loss: 0.3151 (best: 0.3109)\n",
            "[2720/4000] loss=0.3154 lr=1.59e-04 (19:02, ETA 8:57)\n",
            "[2740/4000] loss=0.3237 lr=1.56e-04 (19:10, ETA 8:49)\n",
            "[2760/4000] loss=0.3243 lr=1.53e-04 (19:17, ETA 8:40)\n",
            "[2780/4000] loss=0.3232 lr=1.50e-04 (19:25, ETA 8:31)\n",
            "[2800/4000] loss=0.3163 lr=1.47e-04 (19:32, ETA 8:22)\n",
            "  [Eval] KD Loss: 0.3176 (best: 0.3109)\n",
            "[2820/4000] loss=0.3109 lr=1.44e-04 (19:44, ETA 8:15)\n",
            "[2840/4000] loss=0.3165 lr=1.41e-04 (19:51, ETA 8:06)\n",
            "[2860/4000] loss=0.3183 lr=1.38e-04 (19:58, ETA 7:57)\n",
            "[2880/4000] loss=0.3133 lr=1.36e-04 (20:06, ETA 7:49)\n",
            "[2900/4000] loss=0.3170 lr=1.33e-04 (20:14, ETA 7:40)\n",
            "  [Eval] KD Loss: 0.3183 (best: 0.3109)\n",
            "[2920/4000] loss=0.3160 lr=1.30e-04 (20:25, ETA 7:33)\n",
            "[2940/4000] loss=0.3198 lr=1.27e-04 (20:33, ETA 7:24)\n",
            "[2960/4000] loss=0.3193 lr=1.24e-04 (20:40, ETA 7:15)\n",
            "[2980/4000] loss=0.3137 lr=1.22e-04 (20:48, ETA 7:07)\n",
            "[3000/4000] loss=0.3193 lr=1.19e-04 (20:55, ETA 6:58)\n",
            "  [Eval] KD Loss: 0.3192 (best: 0.3109)\n",
            "[3020/4000] loss=0.3145 lr=1.17e-04 (21:07, ETA 6:51)\n",
            "[3040/4000] loss=0.3220 lr=1.14e-04 (21:14, ETA 6:42)\n",
            "[3060/4000] loss=0.3141 lr=1.11e-04 (21:22, ETA 6:33)\n",
            "[3080/4000] loss=0.3084 lr=1.09e-04 (21:29, ETA 6:25)\n",
            "[3100/4000] loss=0.3141 lr=1.07e-04 (21:36, ETA 6:16)\n",
            "  [Eval] KD Loss: 0.3139 (best: 0.3109)\n",
            "[3120/4000] loss=0.3148 lr=1.04e-04 (21:48, ETA 6:09)\n",
            "[3140/4000] loss=0.3110 lr=1.02e-04 (21:56, ETA 6:00)\n",
            "[3160/4000] loss=0.3110 lr=9.96e-05 (22:03, ETA 5:51)\n",
            "[3180/4000] loss=0.3076 lr=9.73e-05 (22:10, ETA 5:43)\n",
            "[3200/4000] loss=0.3146 lr=9.51e-05 (22:18, ETA 5:34)\n",
            "  [Eval] KD Loss: 0.3152 (best: 0.3109)\n",
            "[3220/4000] loss=0.3162 lr=9.30e-05 (22:30, ETA 5:27)\n",
            "[3240/4000] loss=0.3161 lr=9.09e-05 (22:37, ETA 5:18)\n",
            "[3260/4000] loss=0.3108 lr=8.88e-05 (22:44, ETA 5:09)\n",
            "[3280/4000] loss=0.3154 lr=8.68e-05 (22:52, ETA 5:01)\n",
            "[3300/4000] loss=0.3135 lr=8.48e-05 (23:00, ETA 4:52)\n",
            "  [Eval] KD Loss: 0.3148 (best: 0.3109)\n",
            "[3320/4000] loss=0.3192 lr=8.29e-05 (23:11, ETA 4:45)\n",
            "[3340/4000] loss=0.3086 lr=8.11e-05 (23:19, ETA 4:36)\n",
            "[3360/4000] loss=0.3154 lr=7.92e-05 (23:26, ETA 4:27)\n",
            "[3380/4000] loss=0.3136 lr=7.75e-05 (23:34, ETA 4:19)\n",
            "[3400/4000] loss=0.3102 lr=7.58e-05 (23:41, ETA 4:10)\n",
            "  [Eval] KD Loss: 0.3134 (best: 0.3109)\n",
            "[3420/4000] loss=0.3126 lr=7.41e-05 (23:53, ETA 4:03)\n",
            "[3440/4000] loss=0.3180 lr=7.25e-05 (24:00, ETA 3:54)\n",
            "[3460/4000] loss=0.3177 lr=7.10e-05 (24:08, ETA 3:46)\n",
            "[3480/4000] loss=0.3103 lr=6.95e-05 (24:15, ETA 3:37)\n",
            "[3500/4000] loss=0.3073 lr=6.80e-05 (24:22, ETA 3:28)\n",
            "  [Eval] KD Loss: 0.3139 (best: 0.3109)\n",
            "[3520/4000] loss=0.3109 lr=6.66e-05 (24:34, ETA 3:21)\n",
            "[3540/4000] loss=0.3106 lr=6.53e-05 (24:42, ETA 3:12)\n",
            "[3560/4000] loss=0.3164 lr=6.40e-05 (24:49, ETA 3:04)\n",
            "[3580/4000] loss=0.3191 lr=6.28e-05 (24:56, ETA 2:55)\n",
            "[3600/4000] loss=0.3132 lr=6.16e-05 (25:04, ETA 2:47)\n",
            "  [Eval] KD Loss: 0.3142 (best: 0.3109)\n",
            "[3620/4000] loss=0.3123 lr=6.05e-05 (25:16, ETA 2:39)\n",
            "[3640/4000] loss=0.3134 lr=5.94e-05 (25:23, ETA 2:30)\n",
            "[3660/4000] loss=0.3105 lr=5.84e-05 (25:31, ETA 2:22)\n",
            "[3680/4000] loss=0.3098 lr=5.74e-05 (25:38, ETA 2:13)\n",
            "[3700/4000] loss=0.3145 lr=5.65e-05 (25:45, ETA 2:05)\n",
            "  [Eval] KD Loss: 0.3139 (best: 0.3109)\n",
            "[3720/4000] loss=0.3142 lr=5.57e-05 (25:57, ETA 1:57)\n",
            "[3740/4000] loss=0.3143 lr=5.49e-05 (26:05, ETA 1:48)\n",
            "[3760/4000] loss=0.3145 lr=5.42e-05 (26:12, ETA 1:40)\n",
            "[3780/4000] loss=0.3129 lr=5.35e-05 (26:19, ETA 1:31)\n",
            "[3800/4000] loss=0.3112 lr=5.29e-05 (26:27, ETA 1:23)\n",
            "  [Eval] KD Loss: 0.3126 (best: 0.3109)\n",
            "[3820/4000] loss=0.3193 lr=5.24e-05 (26:39, ETA 1:15)\n",
            "[3840/4000] loss=0.3151 lr=5.19e-05 (26:46, ETA 1:06)\n",
            "[3860/4000] loss=0.3125 lr=5.14e-05 (26:54, ETA 0:58)\n",
            "[3880/4000] loss=0.3097 lr=5.11e-05 (27:01, ETA 0:50)\n",
            "[3900/4000] loss=0.3073 lr=5.07e-05 (27:08, ETA 0:41)\n",
            "  [Eval] KD Loss: 0.3135 (best: 0.3109)\n",
            "[3920/4000] loss=0.3149 lr=5.05e-05 (27:20, ETA 0:33)\n",
            "[3940/4000] loss=0.3161 lr=5.03e-05 (27:28, ETA 0:25)\n",
            "[3960/4000] loss=0.3081 lr=5.01e-05 (27:35, ETA 0:16)\n",
            "[3980/4000] loss=0.3181 lr=5.00e-05 (27:43, ETA 0:08)\n",
            "[4000/4000] loss=0.3081 lr=5.00e-05 (27:50, ETA 0:00)\n",
            "  [Eval] KD Loss: 0.3139 (best: 0.3109)\n",
            "\n",
            "=== Results ===\n",
            "Initial: 1.6692\n",
            "Final:   0.3139\n",
            "Best:    0.3109\n",
            "Improvement: 1.3553\n",
            "Time: 1679.5s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "I0uILDU-OXLv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# FINE-TUNE END-TO-END KD-QAT: TRAIN WEIGHTS (SCALES FROZEN)\n",
        "# ============================================================\n",
        "# Use hard label loss for stable weight training\n",
        "\n",
        "from qat_lora import train_e2e, save_checkpoint, load_checkpoint, unfreeze_model_for_training\n",
        "\n",
        "# Unfreeze for training (clear any cached weights)\n",
        "unfreeze_model_for_training(model)\n",
        "\n",
        "print('E2E weight training with hard label loss...')\n",
        "print(f'Hard label: top1={HARD_TOP1_WEIGHT}, full={HARD_FULL_WEIGHT}')\n",
        "\n",
        "# Train weights (scales frozen)\n",
        "e2e_weights_result = train_e2e(\n",
        "    model=model,\n",
        "    cache_dir=cache_local_path,\n",
        "    device=DEVICE,\n",
        "    max_steps=1000,\n",
        "    batch_size=64 if torch.cuda.is_available() else 32,\n",
        "    lr=1e-4,  # 5x lower for polish\n",
        "    use_cosine_schedule=True,\n",
        "    warmup_steps=0,        # Skip - LR already gentle\n",
        "    min_lr_ratio=0.1,      # End at 1e-5\n",
        "    temperature=DISTILL_TEMP,\n",
        "    train_weights=True,\n",
        "    train_scales=False,\n",
        "    hard_top1_weight=0.2,  # Helps prevent divergence\n",
        "    hard_full_weight=HARD_FULL_WEIGHT,\n",
        "    logging_steps=50,\n",
        "    eval_steps=500,\n",
        "    verbose=True,\n",
        ")"
      ],
      "metadata": {
        "id": "5UYzccZuHoQo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "238cad01-8205-46fb-b81f-7932eb150c8d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E2E weight training with hard label loss...\n",
            "Hard label: top1=0.2, full=5e-05\n",
            "=== End-to-End KD-QAT ===\n",
            "Mode: weights\n",
            "Trainable params: 440,401,920\n",
            "Steps: 1000, LR: 0.0001, Batch: 64\n",
            "Hard label: top1=0.2, full=5e-05\n",
            "LR Schedule: cosine→1.00e-05\n",
            "\n",
            "Initial KD Loss: 0.3142\n",
            "[50/1000] loss=0.9857 lr=9.94e-05 (0:27, ETA 8:45)\n",
            "[100/1000] loss=0.5629 lr=9.78e-05 (0:49, ETA 7:28)\n",
            "[150/1000] loss=0.5132 lr=9.51e-05 (1:11, ETA 6:46)\n",
            "[200/1000] loss=0.5000 lr=9.14e-05 (1:34, ETA 6:16)\n",
            "[250/1000] loss=0.4771 lr=8.68e-05 (1:56, ETA 5:50)\n",
            "[300/1000] loss=0.4587 lr=8.15e-05 (2:19, ETA 5:24)\n",
            "[350/1000] loss=0.4179 lr=7.54e-05 (2:41, ETA 4:59)\n",
            "[400/1000] loss=0.3830 lr=6.89e-05 (3:03, ETA 4:35)\n",
            "[450/1000] loss=0.3623 lr=6.20e-05 (3:25, ETA 4:11)\n",
            "[500/1000] loss=0.3584 lr=5.50e-05 (3:47, ETA 3:47)\n",
            "  [Eval] KD Loss: 0.1882 (best: 0.3142)\n",
            "[550/1000] loss=0.3518 lr=4.80e-05 (4:16, ETA 3:29)\n",
            "[600/1000] loss=0.3498 lr=4.11e-05 (4:38, ETA 3:05)\n",
            "[650/1000] loss=0.3628 lr=3.46e-05 (5:00, ETA 2:41)\n",
            "[700/1000] loss=0.3066 lr=2.85e-05 (5:23, ETA 2:18)\n",
            "[750/1000] loss=0.3047 lr=2.32e-05 (5:45, ETA 1:55)\n",
            "[800/1000] loss=0.2964 lr=1.86e-05 (6:07, ETA 1:31)\n",
            "[850/1000] loss=0.2978 lr=1.49e-05 (6:29, ETA 1:08)\n",
            "[900/1000] loss=0.2961 lr=1.22e-05 (6:52, ETA 0:45)\n",
            "[950/1000] loss=0.2960 lr=1.06e-05 (7:14, ETA 0:22)\n",
            "[1000/1000] loss=0.2885 lr=1.00e-05 (7:36, ETA 0:00)\n",
            "  [Eval] KD Loss: 0.1596 (best: 0.1882)\n",
            "\n",
            "=== Results ===\n",
            "Initial: 0.3142\n",
            "Final:   0.1596\n",
            "Best:    0.1596\n",
            "Improvement: 0.1546\n",
            "Time: 467.3s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# END-TO-END KD-QAT: TRAIN WEIGHTS (SCALES FROZEN)\n",
        "# ============================================================\n",
        "# Use hard label loss for stable weight training\n",
        "\n",
        "from qat_lora import train_e2e, save_checkpoint, load_checkpoint, unfreeze_model_for_training\n",
        "\n",
        "# Unfreeze for training (clear any cached weights)\n",
        "unfreeze_model_for_training(model)\n",
        "\n",
        "print('E2E weight training with hard label loss...')\n",
        "print(f'Hard label: top1={HARD_TOP1_WEIGHT}, full={HARD_FULL_WEIGHT}')\n",
        "\n",
        "# Train weights (scales frozen)\n",
        "e2e_weights_result = train_e2e(\n",
        "    model=model,\n",
        "    cache_dir=cache_local_path,\n",
        "    device=DEVICE,\n",
        "    max_steps=1000,\n",
        "    batch_size=64 if torch.cuda.is_available() else 32,\n",
        "    lr=1e-5,\n",
        "    temperature=DISTILL_TEMP,\n",
        "    train_weights=True,\n",
        "    train_scales=False,\n",
        "    hard_top1_weight=0.2,  # Helps prevent divergence\n",
        "    hard_full_weight=0.0,\n",
        "    logging_steps=50,\n",
        "    eval_steps=500,\n",
        "    verbose=True,\n",
        "    train_mlp_only=True,\n",
        "    use_cosine_schedule=True,\n",
        "    warmup_steps=100,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYjQRat_D2hK",
        "outputId": "f33f0d7c-365d-4e65-933b-23dbf095a552"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E2E weight training with hard label loss...\n",
            "Hard label: top1=0.2, full=5e-05\n",
            "=== End-to-End KD-QAT ===\n",
            "Mode: weights (MLP only)\n",
            "Trainable params: 264,241,152\n",
            "Frozen attention params: 177,307,648\n",
            "Steps: 1000, LR: 1e-05, Batch: 64\n",
            "Hard label: top1=0.2, full=0.0\n",
            "LR Schedule: warmup=100, cosine→1.00e-06\n",
            "\n",
            "Initial KD Loss: 0.1596\n",
            "[50/1000] loss=0.2883 lr=5.00e-06 (0:25, ETA 8:08)\n",
            "[100/1000] loss=0.2848 lr=1.00e-05 (0:46, ETA 6:57)\n",
            "[150/1000] loss=0.2875 lr=9.93e-06 (1:07, ETA 6:20)\n",
            "[200/1000] loss=0.2845 lr=9.73e-06 (1:27, ETA 5:51)\n",
            "[250/1000] loss=0.2866 lr=9.40e-06 (1:49, ETA 5:27)\n",
            "[300/1000] loss=0.2947 lr=8.95e-06 (2:09, ETA 5:03)\n",
            "[350/1000] loss=0.2884 lr=8.39e-06 (2:30, ETA 4:39)\n",
            "[400/1000] loss=0.2872 lr=7.75e-06 (2:51, ETA 4:16)\n",
            "[450/1000] loss=0.2792 lr=7.04e-06 (3:12, ETA 3:54)\n",
            "[500/1000] loss=0.2810 lr=6.28e-06 (3:32, ETA 3:32)\n",
            "  [Eval] KD Loss: 0.1494 (best: 0.1596)\n",
            "[550/1000] loss=0.2802 lr=5.50e-06 (3:59, ETA 3:15)\n",
            "[600/1000] loss=0.2783 lr=4.72e-06 (4:20, ETA 2:53)\n",
            "[650/1000] loss=0.2738 lr=3.96e-06 (4:40, ETA 2:31)\n",
            "[700/1000] loss=0.2756 lr=3.25e-06 (5:01, ETA 2:09)\n",
            "[750/1000] loss=0.2893 lr=2.61e-06 (5:22, ETA 1:47)\n",
            "[800/1000] loss=0.2725 lr=2.05e-06 (5:43, ETA 1:25)\n",
            "[850/1000] loss=0.2769 lr=1.60e-06 (6:04, ETA 1:04)\n",
            "[900/1000] loss=0.2756 lr=1.27e-06 (6:25, ETA 0:42)\n",
            "[950/1000] loss=0.2747 lr=1.07e-06 (6:45, ETA 0:21)\n",
            "[1000/1000] loss=0.2829 lr=1.00e-06 (7:06, ETA 0:00)\n",
            "  [Eval] KD Loss: 0.1465 (best: 0.1494)\n",
            "\n",
            "=== Results ===\n",
            "Initial: 0.1596\n",
            "Final:   0.1465\n",
            "Best:    0.1465\n",
            "Improvement: 0.0130\n",
            "Time: 437.3s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# END-TO-END -Attention: GENTLE MLP+ATT TRAIN SCALES (WEIGHTS FROZEN)\n"
      ],
      "metadata": {
        "id": "vBe_UGa1HtPl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# END-TO-END KD-QAT: GENTLE MLP+ATT TRAIN SCALES (WEIGHTS FROZEN)\n",
        "# ============================================================\n",
        "# Scale training doesn't need hard label loss\n",
        "unfreeze_model_for_training(model)\n",
        "\n",
        "# Freeze MLP scales, only train attention scales\n",
        "for name, module in model.named_modules():\n",
        "    if type(module).__name__ == 'AnemllQATLinear':\n",
        "        is_attn = any(x in name for x in ['q_proj', 'k_proj', 'v_proj', 'o_proj'])\n",
        "        if hasattr(module, 'scale_A') and module.scale_A is not None:\n",
        "            module.scale_A.requires_grad = is_attn\n",
        "            module.scale_B.requires_grad = is_attn\n",
        "        module.weight.requires_grad = False\n",
        "\n",
        "# Train scales (weights frozen) - higher LR since fewer params\n",
        "e2e_scales_result = train_e2e(\n",
        "    model=model,\n",
        "    cache_dir=cache_local_path,\n",
        "    device=DEVICE,\n",
        "    max_steps=2000,\n",
        "    batch_size=64 if torch.cuda.is_available() else 32,\n",
        "    lr=1e-4,  # Higher LR for scales\n",
        "    use_cosine_schedule=True,\n",
        "    warmup_steps=100,          # Linear warmup\n",
        "    min_lr_ratio=0.1,      # End at 5e-5\n",
        "    temperature=DISTILL_TEMP,\n",
        "    train_weights=False,\n",
        "    train_scales=True,\n",
        "    hard_top1_weight=0.0,  # Not needed for scale training\n",
        "    hard_full_weight=0.0,\n",
        "    logging_steps=20,\n",
        "    eval_steps=100,\n",
        "    verbose=True,\n",
        "    train_mlp_only=False,  # ← Freeze attention (4-bit), train MLP (2-bit) only\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "id": "O9BaTY8MFrVA",
        "outputId": "193aabb5-c88d-43f5-c302-1ad38deb38c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== End-to-End KD-QAT ===\n",
            "Mode: scales\n",
            "Trainable params: 13,303,808\n",
            "Steps: 2000, LR: 0.0001, Batch: 64\n",
            "LR Schedule: warmup=100, cosine→1.00e-05\n",
            "\n",
            "Initial KD Loss: 0.4702\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-376557537.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Train scales (weights frozen) - higher LR since fewer params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m e2e_scales_result = train_e2e(\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_local_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/qwen3_apple_style_2bit_qat_lora/qat_lora/layer_qat.py\u001b[0m in \u001b[0;36mtrain_e2e\u001b[0;34m(model, cache_dir, device, max_steps, batch_size, lr, temperature, train_weights, train_scales, train_mlp_only, hard_top1_weight, hard_full_weight, logging_steps, eval_steps, eval_samples, save_dir, verbose, use_cosine_schedule, warmup_steps, min_lr_ratio)\u001b[0m\n\u001b[1;32m   1194\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1196\u001b[0;31m             loss = compute_kd_loss_batch(\n\u001b[0m\u001b[1;32m   1197\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1198\u001b[0m                 \u001b[0mno_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/qwen3_apple_style_2bit_qat_lora/qat_lora/layer_qat.py\u001b[0m in \u001b[0;36mcompute_kd_loss_batch\u001b[0;34m(model, batch, device, temperature, no_grad, hard_top1_weight, hard_full_weight)\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m         \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/qwen3_apple_style_2bit_qat_lora/qat_lora/layer_qat.py\u001b[0m in \u001b[0;36mforward_pass\u001b[0;34m()\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;31m# Get hidden states (not full logits)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m         out = model.model(\n\u001b[0m\u001b[1;32m    252\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1070\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1072\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1073\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moriginal_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m                 \u001b[0;31m# If we get a TypeError, it's possible that the model is not receiving the recordable kwargs correctly.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/qwen3/modeling_qwen3.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdecoder_layer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m             hidden_states = decoder_layer(\n\u001b[0m\u001b[1;32m    411\u001b[0m                 \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m                 \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcausal_mask_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdecoder_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_layers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gradient_checkpointing_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/deprecation.py\u001b[0m in \u001b[0;36mwrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/qwen3/modeling_qwen3.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_values, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_layernorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;31m# Self Attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m         hidden_states, _ = self.self_attn(\n\u001b[0m\u001b[1;32m    261\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/deprecation.py\u001b[0m in \u001b[0;36mwrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/qwen3/modeling_qwen3.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, position_embeddings, attention_mask, past_key_values, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0mhidden_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m         \u001b[0mquery_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m         \u001b[0mkey_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mk_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0mvalue_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# SAVE FINAL CHECKPOINT\n",
        "# ============================================================\n",
        "\n",
        "unfreeze_model_for_training(model)\n",
        "E2E_RUN_NAME = f'anemll_{QUAL}_e2e_v2_scales_only'\n",
        "E2E_SAVE_DIR = f'{LOCAL_RUNS}/{E2E_RUN_NAME}'\n",
        "\n",
        "# Save with config\n",
        "config = {\n",
        "    'model_id': MODEL_ID,\n",
        "    'lut_size': LUT_SIZE,\n",
        "    #'group_size': GROUP_SIZE,\n",
        "    'scale_rank': SCALE_RANK,\n",
        "    'attn_lut_size': ATTN_LUT_SIZE,\n",
        "    'attn_group_size': ATTN_GROUP_SIZE,\n",
        "    'attn_scale_rank': ATTN_SCALE_RANK,\n",
        "    #'e2e_weights_result': e2e_weights_result,\n",
        "    'e2e_scales_result': e2e_scales_result,\n",
        "}\n",
        "\n",
        "save_checkpoint(model, E2E_SAVE_DIR, config=config)\n",
        "\n",
        "# Upload to Google Drive\n",
        "!tar -czvf {E2E_RUN_NAME}.tgz -C {LOCAL_RUNS} {E2E_RUN_NAME}\n",
        "!cp {E2E_RUN_NAME}.tgz {GD_RUNS}/\n",
        "print(f'\\nUploaded to {GD_RUNS}/{E2E_RUN_NAME}.tgz')"
      ],
      "metadata": {
        "id": "wh3twk6GD2hK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ffdc08f-2681-42a3-cb58-ab951b7e76b9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved checkpoint to runs/anemll_q4_a4_e2e_v2_scales_only/\n",
            "  - model_state_dict.pt\n",
            "  - indices.pt (196 layers, 420.0 MB)\n",
            "  - config.json\n",
            "anemll_q4_a4_e2e_v2_scales_only/\n",
            "anemll_q4_a4_e2e_v2_scales_only/config.json\n",
            "anemll_q4_a4_e2e_v2_scales_only/indices.pt\n",
            "anemll_q4_a4_e2e_v2_scales_only/model_state_dict.pt\n",
            "\n",
            "Uploaded to /content/drive/MyDrive/qwen3_runs/anemll_q4_a4_e2e_v2_scales_only.tgz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **INFERENCE OPTIMIZATION**\n",
        "\n",
        "Before running inference, freeze all layers to precompute quantized weights.\n",
        "This avoids recomputing `LUT[indices] * (scale_A @ scale_B)` on every forward pass."
      ],
      "metadata": {
        "id": "fqafgf8KfRgs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# FREEZE MODEL FOR FAST INFERENCE\n",
        "# ============================================================\n",
        "# Precompute quantized weights once for all layers\n",
        "# This caches LUT[idx] * scale to avoid recomputation per token\n",
        "\n",
        "from qat_lora import freeze_model_for_inference, unfreeze_model_for_training\n",
        "\n",
        "\n",
        "print('Freezing model for inference...')\n",
        "num_frozen = freeze_model_for_inference(model, verbose=False)\n",
        "print(f'Frozen {num_frozen} layers')\n",
        "\n",
        "# To resume training later:\n",
        "# unfreeze_model_for_training(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lWZ2KP18fRgs",
        "outputId": "4d13eca7-c7ae-45b5-fe1b-4eb1ee7bc208"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Freezing model for inference...\n",
            "Frozen 196 layers\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bIT_brkMCfrW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Ugmqo-MHFCuX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2a176aa-f9fc-480e-decf-64c7edf911e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: What is the capital of France?\n",
            "Response: <think>\n",
            "<think>\n",
            "</think>\n",
            "\n",
            "The capital of France is **Paris**.\n",
            "--------------------------------------------------\n",
            "Prompt: What is Apple Neural Engine?\n",
            "Response: <think>\n",
            "<think>\n",
            "</think>\n",
            "\n",
            "The **Apple Neural Engine** is a powerful computing platform developed by Apple Inc. It is designed to run on Apple devices and is used for various applications, including AI and machine learning. It is a key component of Apple's ecosystem and is known for its performance and efficiency in handling complex tasks.\n",
            "--------------------------------------------------\n",
            "Prompt: Explain quantum mechanics\n",
            "Response: <think>\n",
            "<think>\n",
            "</think>\n",
            "\n",
            "Quantum mechanics is a fundamental theory of physics that describes the behavior of particles at the smallest scales, such as atoms, molecules, and even subatomic particles. It is a revolutionary theory that challenges our classical understanding of the physical world, which is based on the principles of classical mechanics and electromagnetism.\n",
            "\n",
            "The key ideas of quantum mechanics include:\n",
            "\n",
            "1. **Wave-particle duality**: The behavior of particles can be described both as waves and particles, depending on the observer. This means that particles can exhibit both wave-like properties (e.g., wave-particle duality) and particle-like properties (e.g., as particles in motion).\n",
            "\n",
            "2. **Quantum superposition**: Particles can exist in multiple states at once, which is a phenomenon that is not explained by classical mechanics. This is a key feature of quantum mechanics.\n",
            "\n",
            "3. **Quantum entanglement**: Particles can be entangled, meaning that the state of one particle is correlated with the state of another, even if they are separated by large distances. This phenomenon is a key feature of quantum mechanics.\n",
            "\n",
            "4. **Wave-particle duality**: This is the fundamental principle that explains how particles can behave both as waves and particles. It is a key concept in quantum mechanics.\n",
            "\n",
            "5. **Quantum uncertainty**: The behavior of particles is not completely predictable, and there is a fundamental uncertainty in the measurement of their properties. This is a key feature of quantum mechanics.\n",
            "\n",
            "6. **Quantum tunneling**: Particles can tunnel through potential barriers, which is a phenomenon that is not explained by classical mechanics.\n",
            "\n",
            "7. **Quantum entanglement**: This is a phenomenon where particles are connected in such a way that their states are correlated, even if they are separated by large distances. This is a key feature of quantum mechanics.\n",
            "\n",
            "These principles form the foundation of quantum mechanics and have profound implications for our understanding of the universe.\n",
            "--------------------------------------------------\n",
            "Prompt: What is speed of light\n",
            "Response: <think>\n",
            "<think>\n",
            "</think>\n",
            "\n",
            "The speed of light in a vacuum is approximately **299,792,458 meters per second** (or 386,282,360 kilometers per hour). This is the speed at which light travels in a vacuum, and it is a fundamental constant in physics.\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# ============================================================\n",
        "# TEST INFERENCE\n",
        "# ============================================================\n",
        "\n",
        "def run_inference(model, tokenizer, prompt, max_new_tokens=128):\n",
        "    messages = [\n",
        "        {'role': 'system', 'content': 'You are a helpful assistant.'},\n",
        "        {'role': 'user', 'content': prompt}\n",
        "    ]\n",
        "    text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "    inputs = tokenizer(text, return_tensors='pt').to(DEVICE)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model.generate(**inputs, max_new_tokens=max_new_tokens, do_sample=False)\n",
        "\n",
        "    return tokenizer.decode(output[0][inputs['input_ids'].shape[1]:], skip_special_tokens=True)\n",
        "\n",
        "# List of prompts to test\n",
        "prompts = [\n",
        "    'What is the capital of France?',\n",
        "    'What is Apple Neural Engine?',\n",
        "    'Explain quantum mechanics',\n",
        "    'What is speed of light'\n",
        "]\n",
        "\n",
        "model.eval() # Set model to evaluation mode once\n",
        "\n",
        "for prompt in prompts:\n",
        "    response = run_inference(model, tokenizer, prompt,max_new_tokens=1024)\n",
        "    print(f'Prompt: {prompt}')\n",
        "    print(f'Response: {response}')\n",
        "    print('-' * 50) # Separator for readability\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# TEST INFERENCE\n",
        "# ============================================================\n",
        "\n",
        "def run_inference(model, tokenizer, prompt, max_new_tokens=512):\n",
        "    messages = [\n",
        "        {'role': 'user', 'content': prompt}\n",
        "    ]\n",
        "    text = tokenizer.apply_chat_template(\n",
        "        messages,\n",
        "        tokenize=False,\n",
        "        add_generation_prompt=True,\n",
        "        enable_thinking=True\n",
        "    )\n",
        "    inputs = tokenizer(text, return_tensors='pt').to(DEVICE)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            do_sample=True,\n",
        "            temperature=0.6,\n",
        "            top_p=0.9,\n",
        "            repetition_penalty=1.1,\n",
        "        )\n",
        "\n",
        "    return tokenizer.decode(output[0][inputs['input_ids'].shape[1]:], skip_special_tokens=False)\n",
        "\n",
        "# List of prompts to test\n",
        "prompts = [\n",
        "    'What is the capital of France?',\n",
        "    'What is Apple Neural Engine?',\n",
        "    'Explain quantum mechanics',\n",
        "    'What is speed of light'\n",
        "]\n",
        "\n",
        "model.eval()\n",
        "\n",
        "for prompt in prompts:\n",
        "    response = run_inference(model, tokenizer, prompt, max_new_tokens=512)\n",
        "    print(f'Prompt: {prompt}')\n",
        "    print(f'Response: {response}')\n",
        "    print('-' * 50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UjaRRvbYDzhw",
        "outputId": "17d3301e-ce1a-4aa3-d257-49429e479975"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: What is the capital of France?\n",
            "Response: <think>\n",
            "<think>\n",
            "</think>\n",
            "\n",
            "The capital of France is **Paris**, located in the western part of the country.<|im_end|>\n",
            "--------------------------------------------------\n",
            "Prompt: What is Apple Neural Engine?\n",
            "Response: <think>\n",
            "<think>\n",
            "</think>\n",
            "\n",
            "The **Apple Neural Engine** is a key component of Apple's operating system, specifically the **iOS** operating system. It is developed by Apple and is part of the iOS ecosystem. The neural engine is responsible for handling various tasks such as image processing, speech recognition, and machine learning, which are essential for applications like apps, games, and other services. It plays a crucial role in enabling the development and performance of Apple products.<|im_end|>\n",
            "--------------------------------------------------\n",
            "Prompt: Explain quantum mechanics\n",
            "Response: <think>\n",
            "<think>\n",
            "</think>\n",
            "\n",
            "Quantum Mechanics is a fundamental field of physics that describes the behavior of particles at the smallest possible scale, and it is often referred to as \"the quantum realm.\" It is a theory that governs the behavior of subatomic particles such as electrons, photons, and protons. The theory is based on the principles of quantum superposition and entanglement, which are key concepts in quantum mechanics.\n",
            "\n",
            "The main idea of quantum mechanics is that particles can exist simultaneously in different states of existence (like in a superposition or in a different state), and they are in a relationship with other particles in this quantum system. This phenomenon is called **superposition**, and it is the basis for many physical phenomena in our universe. For example, particles can be in both a stationary and moving state at the same time, but their positions are different depending on the observer's position.\n",
            "\n",
            "In addition to superposition, there are other important quantum phenomena, such as:\n",
            "\n",
            "- **Quantum entanglement**: When two particles are in separate locations in space, their positions are correlated, even if they are separated by a large distance. This is a phenomenon known as **quantum entanglement** and is essential for understanding and predicting the behavior of quantum systems.\n",
            "\n",
            "- **Wave function**: A wave function represents the probability of finding a particle in a specific location in a quantum system, and it has a continuous nature. It also includes a wave function that takes into account the probabilities of finding a particle in various states.\n",
            "\n",
            "In summary, quantum mechanics is a complex and dynamic field that has made significant contributions to modern physics and technology. It provides an understanding of the behavior of particles at the atomic level, and it has enabled the development of new technologies and applications across all domains of science and engineering.<|im_end|>\n",
            "--------------------------------------------------\n",
            "Prompt: What is speed of light\n",
            "Response: <think>\n",
            "<think>\n",
            "</think>\n",
            "\n",
            "The **speed of light** is a fundamental physical property that describes how fast light travels in space. It's approximately **386,000 kilometers per second (km/sec)** at standard vacuum conditions, which is about 29 million times faster than the speed of sound in an air bubble.\n",
            "\n",
            "### Key Points:\n",
            "- **Speed of light**:  \n",
            "  - **Definition**: The speed of light in an empty medium (like vacuum or space) is approximately 386,000 km/s.  \n",
            "  - **Units**:  \n",
            "    - **km/s**: 386,000 km/s.  \n",
            "    - **m/s**: 1,000,000 m/s.  \n",
            "\n",
            "### Summary:  \n",
            "The speed of light is the maximum speed at which light can propagate in any medium, and it's about 386,000 km/s.<|im_end|>\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKGYuTbyFCuX"
      },
      "source": [
        "## Next Steps\n",
        "\n",
        "After layer-by-layer training, you can:\n",
        "\n",
        "1. **End-to-end refinement** - Unfreeze all layers and train together\n",
        "2. **Train scales (A, B)** - Unfreeze scale_A, scale_B parameters\n",
        "3. **LoRA recovery** - Add LoRA adapters to recover quality"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **EXPORT FOR ANEMLL CONVERTER**\n",
        "\n",
        "Snap weights to quantized values and export for external tools.\n",
        "\n",
        "Two export modes:\n",
        "- `store_lut_values=True`: weights = LUT[idx] (normalized in [-1,1]), scales separate\n",
        "- `store_lut_values=False`: weights = LUT[idx] * scale (full dequant)"
      ],
      "metadata": {
        "id": "rYhCJltqD2hL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# SNAP WEIGHTS AND EXPORT\n",
        "# ============================================================\n",
        "# Snap weights to LUT[idx] values for ANEMLL converter\n",
        "\n",
        "from qat_lora import snap_all_weights, export_quantized_model, unfreeze_model_for_training\n",
        "\n",
        "# First unfreeze to clear cached weights\n",
        "unfreeze_model_for_training(model)\n",
        "\n",
        "# Export quantized representation BEFORE snapping (keeps original weights)\n",
        "print('Exporting quantized model representation...')\n",
        "export_dict = export_quantized_model(model, verbose=True)\n",
        "\n",
        "# Save export for ANEMLL converter\n",
        "EXPORT_DIR = f'{LOCAL_RUNS}/{E2E_RUN_NAME}_export'\n",
        "os.makedirs(EXPORT_DIR, exist_ok=True)\n",
        "torch.save(export_dict, f'{EXPORT_DIR}/quantized_model.pt')\n",
        "print(f'\\nSaved export to {EXPORT_DIR}/quantized_model.pt')\n",
        "\n",
        "# Each layer in export_dict contains:\n",
        "# - indices: [out, in] uint8 LUT indices\n",
        "# - quantized_weights: [out, in] LUT[idx] values in [-1, 1]\n",
        "# - scales: {'scale_A': [out, rank], 'scale_B': [rank, in]} or full [out, in]\n",
        "# - lut: [lut_size] values\n",
        "# - bias, in_features, out_features, etc."
      ],
      "metadata": {
        "id": "alJrTNGED2hL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# SNAP WEIGHTS TO FULL DEQUANT AND TEST\n",
        "# ============================================================\n",
        "# Snap weights = LUT[idx] * scale, then disable fake_quant for direct use\n",
        "\n",
        "print('Snapping weights to full dequantized values (LUT[idx] * scale)...')\n",
        "indices = snap_all_weights(model, store_lut_values=False, verbose=True)\n",
        "\n",
        "# Disable fake quantization - use snapped weights directly\n",
        "for name, module in model.named_modules():\n",
        "    if type(module).__name__ == 'AnemllQATLinear':\n",
        "        module.enable_fake_quant = False\n",
        "\n",
        "print('\\nTesting inference with snapped weights...')\n",
        "model.eval()\n",
        "\n",
        "# Quick test\n",
        "response = run_inference(model, tokenizer, 'What is 2+2?', max_new_tokens=1024)\n",
        "print(f'Prompt: What is 2+2?')\n",
        "print(f'Response: {response}')"
      ],
      "metadata": {
        "id": "Ny_MXsYgD2hL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), '/tmp/backup_mlp_e2e_0.4613.pt')  # Local, fast"
      ],
      "metadata": {
        "id": "ZUlMBHHEcQ0R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "torch.save(model.state_dict(), '/tmp/backup_mlp_e2e_w_0.3824.pt')  # Local, fast"
      ],
      "metadata": {
        "id": "tGydB-nzDEiM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), '/tmp/backup_mlp_e4e_4_4.pt')  # Local, fast"
      ],
      "metadata": {
        "id": "LzDrNrYEDKTE"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('/tmp/backup_initial.pt', map_location=DEVICE))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6YdQUk9q3DbH",
        "outputId": "3292185a-6f75-4354-e3b8-8d991757445e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "AVGwV43BxCem"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load('/tmp/backup_mlp_e2e_w_0.3824.pt', map_location=DEVICE))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hi2MkZnJ_pXq",
        "outputId": "84aefbbf-9c3a-4fda-e70f-4f2133d35063"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "history_visible": true,
      "toc_visible": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9ceaade381e94c258a3c0ffe6b8993ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_09079f4c40b24d47b16b3a9d39eac18f",
              "IPY_MODEL_c1ca5e81b3884530acba75733f2b2ef3",
              "IPY_MODEL_b66e47d1dccd4aaa9053968667cfafe3"
            ],
            "layout": "IPY_MODEL_02947099e48c465691d6d41dcd1e877b"
          }
        },
        "09079f4c40b24d47b16b3a9d39eac18f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f10f6efb961f426dba0e85b4f4fc54ba",
            "placeholder": "​",
            "style": "IPY_MODEL_f029416c83fe4e1daf94c137e9b70038",
            "value": "tokenizer_config.json: "
          }
        },
        "c1ca5e81b3884530acba75733f2b2ef3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_723cb77b570b43c780f7816ce9aa4f81",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_02f92b038c3942369d6bbda0b85561bd",
            "value": 1
          }
        },
        "b66e47d1dccd4aaa9053968667cfafe3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eab5f44c082e486cbfef722597968c27",
            "placeholder": "​",
            "style": "IPY_MODEL_c181cb34a1c44cff9f701fcb264f4639",
            "value": " 9.73k/? [00:00&lt;00:00, 1.05MB/s]"
          }
        },
        "02947099e48c465691d6d41dcd1e877b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f10f6efb961f426dba0e85b4f4fc54ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f029416c83fe4e1daf94c137e9b70038": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "723cb77b570b43c780f7816ce9aa4f81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "02f92b038c3942369d6bbda0b85561bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eab5f44c082e486cbfef722597968c27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c181cb34a1c44cff9f701fcb264f4639": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3f33d3f10a104364a08b5a972d868404": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e34e197865624c319e5c3efd61cec5f1",
              "IPY_MODEL_e1f9a8ad18a0404f91bd633266a987c1",
              "IPY_MODEL_7dafcef8629943bba8b552eb65cf4319"
            ],
            "layout": "IPY_MODEL_cd45240c029a4d89bf7856dfe692f487"
          }
        },
        "e34e197865624c319e5c3efd61cec5f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1643098c16724226b2f135666c853021",
            "placeholder": "​",
            "style": "IPY_MODEL_b89e33aa337d495b9c5f0afa5c4e531f",
            "value": "vocab.json: "
          }
        },
        "e1f9a8ad18a0404f91bd633266a987c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cdde30488ec24b2f8ff1ac50adf677c1",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e4a9b6abc3bb4d72b33910184b8dee53",
            "value": 1
          }
        },
        "7dafcef8629943bba8b552eb65cf4319": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32ddfc19754f4f3ba3fd05ceb443200b",
            "placeholder": "​",
            "style": "IPY_MODEL_9d78c3b445ae4b4b9255f381dbbbf297",
            "value": " 2.78M/? [00:00&lt;00:00, 32.9MB/s]"
          }
        },
        "cd45240c029a4d89bf7856dfe692f487": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1643098c16724226b2f135666c853021": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b89e33aa337d495b9c5f0afa5c4e531f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cdde30488ec24b2f8ff1ac50adf677c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "e4a9b6abc3bb4d72b33910184b8dee53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "32ddfc19754f4f3ba3fd05ceb443200b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d78c3b445ae4b4b9255f381dbbbf297": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6d34db691b8549708447dc4528918bd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6f4a70c1d8b443019ce0db5845dbeabe",
              "IPY_MODEL_fbd65fe0ad714e719255caa92dc42988",
              "IPY_MODEL_458a362e07ef46fdab537612157215fc"
            ],
            "layout": "IPY_MODEL_6401e8dd76cf43c9bca85eafa9584072"
          }
        },
        "6f4a70c1d8b443019ce0db5845dbeabe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d28e621974114f798fa7f6f7147c18c1",
            "placeholder": "​",
            "style": "IPY_MODEL_c4f53cf052434846851f7bb9681f06f3",
            "value": "merges.txt: "
          }
        },
        "fbd65fe0ad714e719255caa92dc42988": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a5a12de6a824d8784f0b5c8b39df05c",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a5c2c0a43dff4b78bd2dea20244a743b",
            "value": 1
          }
        },
        "458a362e07ef46fdab537612157215fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8c783ede2f445dd8538a743155eb07d",
            "placeholder": "​",
            "style": "IPY_MODEL_d4c27e7c0c394e75b28c3a2da7233afd",
            "value": " 1.67M/? [00:00&lt;00:00, 66.1MB/s]"
          }
        },
        "6401e8dd76cf43c9bca85eafa9584072": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d28e621974114f798fa7f6f7147c18c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4f53cf052434846851f7bb9681f06f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1a5a12de6a824d8784f0b5c8b39df05c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "a5c2c0a43dff4b78bd2dea20244a743b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b8c783ede2f445dd8538a743155eb07d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4c27e7c0c394e75b28c3a2da7233afd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7c23ec2e04e04555bcc86795b8b98a6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1222d75ab8a34dd7b4bdb4e57403b74a",
              "IPY_MODEL_dcfa4ead89b34a038cbbff240f802027",
              "IPY_MODEL_06e9bae2da334bfe87877b18848fc0e0"
            ],
            "layout": "IPY_MODEL_b8c1d61e8f7f40d0a2dfb0aa44d9e4b2"
          }
        },
        "1222d75ab8a34dd7b4bdb4e57403b74a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f0f985b8ba44c80bd30840946cec59f",
            "placeholder": "​",
            "style": "IPY_MODEL_78f024244cfa4226bb3abbdba4611ac8",
            "value": "tokenizer.json: 100%"
          }
        },
        "dcfa4ead89b34a038cbbff240f802027": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_13407d3e50f44934ba4cc8d125319a97",
            "max": 11422654,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_395b60bd9d62499ebdf4db8f98d6d060",
            "value": 11422654
          }
        },
        "06e9bae2da334bfe87877b18848fc0e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0dc69628c774dcab4fdc057d871c71e",
            "placeholder": "​",
            "style": "IPY_MODEL_c7550f00e5f5491e848cc033cb52d695",
            "value": " 11.4M/11.4M [00:00&lt;00:00, 39.8MB/s]"
          }
        },
        "b8c1d61e8f7f40d0a2dfb0aa44d9e4b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f0f985b8ba44c80bd30840946cec59f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78f024244cfa4226bb3abbdba4611ac8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "13407d3e50f44934ba4cc8d125319a97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "395b60bd9d62499ebdf4db8f98d6d060": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a0dc69628c774dcab4fdc057d871c71e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7550f00e5f5491e848cc033cb52d695": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e9b3bbd2ed04af2983090df7fdfa860": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_79dba7f9976e4d56ba95542576ad784e",
              "IPY_MODEL_61b4ff17161a4472983d9ae7c4038f4c",
              "IPY_MODEL_97e02cb7cc054c76a2a236208bd39288"
            ],
            "layout": "IPY_MODEL_1e61be30fd06489997bc1073cdf4b63f"
          }
        },
        "79dba7f9976e4d56ba95542576ad784e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cccaf0d3bbbc4d1fab88478bfde18570",
            "placeholder": "​",
            "style": "IPY_MODEL_9cfe70d1c90d4570a537ba3ba9af8758",
            "value": "config.json: 100%"
          }
        },
        "61b4ff17161a4472983d9ae7c4038f4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1be8597c80774992b05b2b2a3db7e3ca",
            "max": 726,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_58c6d1daf9dc4736ad8888fdd2e13051",
            "value": 726
          }
        },
        "97e02cb7cc054c76a2a236208bd39288": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31c50cde54ce455484d8959587b6761e",
            "placeholder": "​",
            "style": "IPY_MODEL_756e3d0cd08d444f974dbb4a0d03aeee",
            "value": " 726/726 [00:00&lt;00:00, 100kB/s]"
          }
        },
        "1e61be30fd06489997bc1073cdf4b63f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cccaf0d3bbbc4d1fab88478bfde18570": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9cfe70d1c90d4570a537ba3ba9af8758": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1be8597c80774992b05b2b2a3db7e3ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58c6d1daf9dc4736ad8888fdd2e13051": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "31c50cde54ce455484d8959587b6761e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "756e3d0cd08d444f974dbb4a0d03aeee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aebedea1c0aa48c996f59ceff3b7f59d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_99f53192c01e48d28edeaa60bcc93316",
              "IPY_MODEL_f8707033b6bc4ff39b211d9e79429d8f",
              "IPY_MODEL_412c3035861a4d9fa384f8b8285415b7"
            ],
            "layout": "IPY_MODEL_60d59a18029944c48ec1fa1e667d6c8e"
          }
        },
        "99f53192c01e48d28edeaa60bcc93316": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86ca268b812540e98715edec5bcfc312",
            "placeholder": "​",
            "style": "IPY_MODEL_650dce7e0dfe41c5a7aad9ab6fcb4b7f",
            "value": "model.safetensors: 100%"
          }
        },
        "f8707033b6bc4ff39b211d9e79429d8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69988406b6fd406ca9a657ca1164b716",
            "max": 1503300328,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_045937442f11451fae75cf71818f2771",
            "value": 1503300328
          }
        },
        "412c3035861a4d9fa384f8b8285415b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_434330f256ed46f384bf6fa47b423b80",
            "placeholder": "​",
            "style": "IPY_MODEL_5da05f1cfe8a4913b38c49789f367319",
            "value": " 1.50G/1.50G [00:01&lt;00:00, 766MB/s]"
          }
        },
        "60d59a18029944c48ec1fa1e667d6c8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86ca268b812540e98715edec5bcfc312": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "650dce7e0dfe41c5a7aad9ab6fcb4b7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "69988406b6fd406ca9a657ca1164b716": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "045937442f11451fae75cf71818f2771": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "434330f256ed46f384bf6fa47b423b80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5da05f1cfe8a4913b38c49789f367319": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab4ff2b64d29443ba180766a384840b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ca7eb173d158416cbf10a5c6f485e9a1",
              "IPY_MODEL_683cb5329ed749d593c4592d21095b03",
              "IPY_MODEL_2e1db963227241848378d59b903e9eac"
            ],
            "layout": "IPY_MODEL_fe3be4ef1c22496091ec419cba32966f"
          }
        },
        "ca7eb173d158416cbf10a5c6f485e9a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d4c07e275393496f8dee96dd3168a40f",
            "placeholder": "​",
            "style": "IPY_MODEL_b6a1ab44a70a43d3a6c3fe8be56ff1cb",
            "value": "generation_config.json: 100%"
          }
        },
        "683cb5329ed749d593c4592d21095b03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_44606bd8389a4dd7acec4c4e8b27236f",
            "max": 239,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_beadf9955191423587bc789d96b539b5",
            "value": 239
          }
        },
        "2e1db963227241848378d59b903e9eac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9ed78eb0a274a4eaa5e9115ae344042",
            "placeholder": "​",
            "style": "IPY_MODEL_7d71667b5bf8458e846b371058fe0fca",
            "value": " 239/239 [00:00&lt;00:00, 28.2kB/s]"
          }
        },
        "fe3be4ef1c22496091ec419cba32966f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4c07e275393496f8dee96dd3168a40f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6a1ab44a70a43d3a6c3fe8be56ff1cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "44606bd8389a4dd7acec4c4e8b27236f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "beadf9955191423587bc789d96b539b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c9ed78eb0a274a4eaa5e9115ae344042": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d71667b5bf8458e846b371058fe0fca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}