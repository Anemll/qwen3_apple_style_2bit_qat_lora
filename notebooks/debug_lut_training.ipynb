{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug LUT Training Experiment\n",
    "\n",
    "**Rev: 1.0 (2026-01-17)**\n",
    "\n",
    "## Goal\n",
    "Investigate why LUT + scales training appears to change `_Q` tensors unexpectedly.\n",
    "\n",
    "## Hypothesis\n",
    "During training, `_Q` buffer should NOT change because:\n",
    "1. `_Q` is a buffer (not a parameter) - has no gradients\n",
    "2. Forward pass uses `lut[_indices]` when LUT training is enabled, bypassing `_Q`\n",
    "3. `_Q` is only updated by explicit calls to `sync_q_from_indices()` or baking\n",
    "\n",
    "## Experiment Plan\n",
    "1. Snapshot initial checkpoint tensor hashes\n",
    "2. Run short training (20 steps) with LUT + scales\n",
    "3. Compare tensors: what actually changed?\n",
    "4. Verify `_Q` buffers are unchanged\n",
    "\n",
    "## Expected Results\n",
    "\n",
    "| Tensor Type | Should Change? | Why |\n",
    "|-------------|----------------|-----|\n",
    "| `.lut` | YES | `--train-lut` enables LUT training |\n",
    "| `_lut_raw_deltas` | YES | LUT training uses delta parameterization |\n",
    "| `scale_A`, `scale_B` | YES | `train_scales=True` (hardcoded) |\n",
    "| `rank_magnitude` | YES | Part of scale training |\n",
    "| `_Q` | **NO** | Buffer, bypassed when LUT training enabled |\n",
    "| `_indices` | NO | Frozen at init |\n",
    "\n",
    "## Cell Index\n",
    "\n",
    "| Cell | Purpose |\n",
    "|------|---------|\n",
    "| 1 | Google Drive paths |\n",
    "| 2 | Mount Google Drive |\n",
    "| 3 | Clone/update repo |\n",
    "| 4 | Install dependencies |\n",
    "| 5 | Configuration |\n",
    "| 6 | Snapshot initial checkpoint |\n",
    "| 7 | Run short training |\n",
    "| 8 | Compare results |\n",
    "| 9 | Categorize changes |\n",
    "| 10 | Analyze _Q changes (key result) |\n",
    "| 11 | Verify LUT training worked |\n",
    "| 12 | Conclusion |\n",
    "| 13-14 | Bonus: compare srLUT-004c input vs output |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [CELL 1: Google Drive paths]\n",
    "# ============================================================\n",
    "# GOOGLE DRIVE PATHS (STANDARD)\n",
    "# ============================================================\n",
    "\n",
    "# Checkpoints/runs go here\n",
    "GD_RUNS = '/content/drive/MyDrive/qwen3_runs'\n",
    "\n",
    "# KD caches go here\n",
    "GD_CACHES = '/content/drive/MyDrive/qwen3_caches'\n",
    "\n",
    "# Local directories (on Colab VM)\n",
    "LOCAL_RUNS = 'runs'\n",
    "LOCAL_CACHES = 'caches'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [CELL 2: Mount Google Drive]\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [CELL 3: Clone/update repo]\n",
    "# ============================================================\n",
    "# CLONE/UPDATE REPO (re-run safe)\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "\n",
    "REPO_DIR = '/content/qwen3_apple_style_2bit_qat_lora'\n",
    "\n",
    "if not os.path.exists(REPO_DIR):\n",
    "    print(f\"Cloning repo to {REPO_DIR}...\")\n",
    "    !git clone https://github.com/anemll/qwen3_apple_style_2bit_qat_lora.git {REPO_DIR}\n",
    "else:\n",
    "    print(f\"Repo exists at {REPO_DIR}, updating...\")\n",
    "\n",
    "%cd {REPO_DIR}\n",
    "!git fetch && git pull\n",
    "\n",
    "# Clear cached imports\n",
    "import sys\n",
    "[sys.modules.pop(k) for k in list(sys.modules) if k.startswith('qat_lora')]\n",
    "\n",
    "print(f\"\\nWorking directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [CELL 4: Install dependencies]\n",
    "!pip install -q transformers accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [CELL 5: Configuration]\n",
    "# ============================================================\n",
    "# EXPERIMENT CONFIGURATION\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "\n",
    "# Initial checkpoint (the \"truth\" before any training)\n",
    "INITIAL_CKPT = f'{GD_RUNS}/sr011-q4a4-FP4-init/v2_initial.pt'\n",
    "\n",
    "# KD cache for training\n",
    "CACHE_NAME = 'alpaca_chat_think_both_L128_K128_R1024'\n",
    "CACHE_DIR = f'{LOCAL_CACHES}/{CACHE_NAME}'\n",
    "\n",
    "# Output directory for this experiment\n",
    "OUTPUT_DIR = f'{LOCAL_RUNS}/debug_lut_training'\n",
    "\n",
    "# Training config\n",
    "MAX_STEPS = 20      # Short run to verify behavior\n",
    "BATCH_SIZE = 2\n",
    "ACCUMULATION = 1\n",
    "WARMUP_STEPS = 5\n",
    "LR = 2e-5\n",
    "LUT_LR = 1e-5\n",
    "LUT_MAX_ABS = 2.0\n",
    "\n",
    "# Verify paths\n",
    "print(f\"=== Debug LUT Training Experiment ===\")\n",
    "print(f\"\")\n",
    "print(f\"Initial checkpoint: {INITIAL_CKPT}\")\n",
    "print(f\"  Exists: {os.path.exists(INITIAL_CKPT)}\")\n",
    "print(f\"\")\n",
    "print(f\"Cache dir: {CACHE_DIR}\")\n",
    "print(f\"  Exists: {os.path.exists(CACHE_DIR)}\")\n",
    "print(f\"\")\n",
    "print(f\"Output dir: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [CELL 5b: Download cache if needed]\n",
    "# ============================================================\n",
    "# DOWNLOAD KD CACHE (if not already present)\n",
    "# ============================================================\n",
    "\n",
    "if not os.path.exists(CACHE_DIR):\n",
    "    print(f\"Cache not found locally, copying from Google Drive...\")\n",
    "    !mkdir -p {LOCAL_CACHES}\n",
    "    \n",
    "    # Try tgz first\n",
    "    tgz_path = f\"{GD_CACHES}/{CACHE_NAME}.tgz\"\n",
    "    if os.path.exists(tgz_path):\n",
    "        print(f\"Extracting {tgz_path}...\")\n",
    "        !tar -xzf \"{tgz_path}\" -C {LOCAL_CACHES}\n",
    "    else:\n",
    "        # Try direct folder copy\n",
    "        folder_path = f\"{GD_CACHES}/{CACHE_NAME}\"\n",
    "        if os.path.exists(folder_path):\n",
    "            print(f\"Copying {folder_path}...\")\n",
    "            !cp -r \"{folder_path}\" {CACHE_DIR}\n",
    "        else:\n",
    "            print(f\"ERROR: Cache not found in Google Drive!\")\n",
    "            print(f\"  Tried: {tgz_path}\")\n",
    "            print(f\"  Tried: {folder_path}\")\n",
    "else:\n",
    "    print(f\"Cache already exists: {CACHE_DIR}\")\n",
    "\n",
    "# Verify\n",
    "if os.path.exists(CACHE_DIR):\n",
    "    !ls -la {CACHE_DIR} | head -5\n",
    "    print(f\"...\")\n",
    "    !ls {CACHE_DIR} | wc -l\n",
    "    print(f\"files total\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Snapshot Initial Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [CELL 6: Snapshot initial checkpoint]\n",
    "# ============================================================\n",
    "# LOAD AND ANALYZE INITIAL CHECKPOINT\n",
    "# ============================================================\n",
    "\n",
    "import torch\n",
    "import hashlib\n",
    "\n",
    "def tensor_hash(t):\n",
    "    \"\"\"Quick hash for tensor comparison.\"\"\"\n",
    "    return hashlib.md5(t.cpu().numpy().tobytes()).hexdigest()[:16]\n",
    "\n",
    "print(f\"Loading initial checkpoint: {INITIAL_CKPT}\")\n",
    "initial_sd = torch.load(INITIAL_CKPT, map_location='cpu', weights_only=False)\n",
    "\n",
    "# Categorize keys\n",
    "lut_keys = [k for k in initial_sd if '.lut' in k and '_lut' not in k]\n",
    "q_keys = [k for k in initial_sd if '._Q' in k]\n",
    "indices_keys = [k for k in initial_sd if '._indices' in k]\n",
    "scale_keys = [k for k in initial_sd if 'scale_A' in k or 'scale_B' in k or 'rank_magnitude' in k]\n",
    "delta_keys = [k for k in initial_sd if '_lut_raw_deltas' in k]\n",
    "\n",
    "print(f\"\\n=== Initial Checkpoint Structure ===\")\n",
    "print(f\"Total keys: {len(initial_sd)}\")\n",
    "print(f\"\")\n",
    "print(f\"  LUT keys (.lut):        {len(lut_keys)}\")\n",
    "print(f\"  _Q keys:                {len(q_keys)}\")\n",
    "print(f\"  _indices keys:          {len(indices_keys)}\")\n",
    "print(f\"  Scale keys:             {len(scale_keys)}\")\n",
    "print(f\"  _lut_raw_deltas keys:   {len(delta_keys)}\")\n",
    "\n",
    "# Save hashes for comparison\n",
    "initial_q_hashes = {k: tensor_hash(initial_sd[k]) for k in q_keys}\n",
    "initial_lut_hashes = {k: tensor_hash(initial_sd[k]) for k in lut_keys}\n",
    "\n",
    "print(f\"\\nCaptured {len(initial_q_hashes)} _Q hashes\")\n",
    "print(f\"Captured {len(initial_lut_hashes)} LUT hashes\")\n",
    "\n",
    "# Show sample\n",
    "print(f\"\\nSample _Q tensor:\")\n",
    "sample_q = q_keys[0] if q_keys else None\n",
    "if sample_q:\n",
    "    t = initial_sd[sample_q]\n",
    "    print(f\"  {sample_q}\")\n",
    "    print(f\"  shape: {t.shape}, dtype: {t.dtype}\")\n",
    "    print(f\"  hash: {initial_q_hashes[sample_q]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Short Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [CELL 7: Run short training]\n",
    "# ============================================================\n",
    "# RUN SHORT TRAINING (LUT + SCALES)\n",
    "# ============================================================\n",
    "\n",
    "# Clean output directory\n",
    "!rm -rf {OUTPUT_DIR}\n",
    "!mkdir -p {OUTPUT_DIR}\n",
    "\n",
    "print(f\"Starting training...\")\n",
    "print(f\"  Checkpoint: {INITIAL_CKPT}\")\n",
    "print(f\"  Cache: {CACHE_DIR}\")\n",
    "print(f\"  Output: {OUTPUT_DIR}\")\n",
    "print(f\"  Steps: {MAX_STEPS}\")\n",
    "print(f\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# [CELL 7b: Execute training]\n",
    "# Training command with LUT + scales\n",
    "\n",
    "!python scripts/train_v2_simple.py \\\n",
    "    --tpu --mixed-precision \\\n",
    "    --config q4_r32 \\\n",
    "    --v2-checkpoint \"{INITIAL_CKPT}\" \\\n",
    "    --cache-dir {CACHE_DIR} \\\n",
    "    --output-dir {OUTPUT_DIR} \\\n",
    "    --max-steps {MAX_STEPS} \\\n",
    "    --batch-size {BATCH_SIZE} \\\n",
    "    --accumulation-steps {ACCUMULATION} \\\n",
    "    --warmup-steps {WARMUP_STEPS} \\\n",
    "    --train-lut --lut-scope all --lut-max-abs {LUT_MAX_ABS} --lut-lr {LUT_LR} \\\n",
    "    --lr {LR} \\\n",
    "    --hard-top1 0.0 --hard-full 0.0 \\\n",
    "    --save-steps {MAX_STEPS} \\\n",
    "    --eval-steps 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [CELL 8: Load trained checkpoint and compare]\n",
    "# ============================================================\n",
    "# COMPARE INITIAL VS TRAINED\n",
    "# ============================================================\n",
    "\n",
    "import glob\n",
    "\n",
    "# Find checkpoint\n",
    "ckpt_files = glob.glob(f\"{OUTPUT_DIR}/checkpoint_step*.pt\") + glob.glob(f\"{OUTPUT_DIR}/best_state_dict.pt\")\n",
    "print(f\"Found checkpoints: {ckpt_files}\")\n",
    "\n",
    "if not ckpt_files:\n",
    "    print(\"ERROR: No checkpoint found! Training may have failed.\")\n",
    "    trained_sd = None\n",
    "else:\n",
    "    trained_path = ckpt_files[0]\n",
    "    print(f\"\\nLoading trained checkpoint: {trained_path}\")\n",
    "    trained_sd = torch.load(trained_path, map_location='cpu', weights_only=False)\n",
    "    print(f\"Loaded {len(trained_sd)} keys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [CELL 8b: Compare all tensors]\n",
    "# ============================================================\n",
    "# TENSOR-BY-TENSOR COMPARISON\n",
    "# ============================================================\n",
    "\n",
    "if trained_sd:\n",
    "    changed = []\n",
    "    unchanged = []\n",
    "    \n",
    "    common_keys = set(initial_sd.keys()) & set(trained_sd.keys())\n",
    "    only_initial = set(initial_sd.keys()) - set(trained_sd.keys())\n",
    "    only_trained = set(trained_sd.keys()) - set(initial_sd.keys())\n",
    "    \n",
    "    for k in sorted(common_keys):\n",
    "        t1 = initial_sd[k]\n",
    "        t2 = trained_sd[k]\n",
    "        \n",
    "        if t1.shape != t2.shape:\n",
    "            changed.append((k, 'shape_mismatch', None, None))\n",
    "        elif not torch.equal(t1, t2):\n",
    "            diff = (t1.float() - t2.float()).abs()\n",
    "            changed.append((k, diff.max().item(), diff.mean().item(), diff.sum().item()))\n",
    "        else:\n",
    "            unchanged.append(k)\n",
    "    \n",
    "    print(f\"=== COMPARISON RESULTS ===\")\n",
    "    print(f\"\")\n",
    "    print(f\"Common keys:      {len(common_keys)}\")\n",
    "    print(f\"Only in initial:  {len(only_initial)}\")\n",
    "    print(f\"Only in trained:  {len(only_trained)}\")\n",
    "    print(f\"\")\n",
    "    print(f\"Unchanged:        {len(unchanged)} tensors\")\n",
    "    print(f\"Changed:          {len(changed)} tensors\")\n",
    "    \n",
    "    if only_trained:\n",
    "        print(f\"\\nNew keys in trained (first 5):\")\n",
    "        for k in sorted(only_trained)[:5]:\n",
    "            print(f\"  {k}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [CELL 9: Categorize changes]\n",
    "# ============================================================\n",
    "# CATEGORIZE CHANGES BY TENSOR TYPE\n",
    "# ============================================================\n",
    "\n",
    "if trained_sd and changed:\n",
    "    # Filter out shape mismatches for stats\n",
    "    valid_changes = [(k, mx, mn, sm) for k, mx, mn, sm in changed if mx != 'shape_mismatch']\n",
    "    \n",
    "    lut_changed = [x for x in valid_changes if '.lut' in x[0] and '_lut' not in x[0]]\n",
    "    q_changed = [x for x in valid_changes if '._Q' in x[0]]\n",
    "    scale_changed = [x for x in valid_changes if 'scale_A' in x[0] or 'scale_B' in x[0] or 'rank_magnitude' in x[0]]\n",
    "    delta_changed = [x for x in valid_changes if '_lut_raw_deltas' in x[0]]\n",
    "    indices_changed = [x for x in valid_changes if '._indices' in x[0]]\n",
    "    other_changed = [x for x in valid_changes \n",
    "                    if '.lut' not in x[0] and '._Q' not in x[0] \n",
    "                    and 'scale_' not in x[0] and 'rank_magnitude' not in x[0]\n",
    "                    and '_lut_raw_deltas' not in x[0] and '._indices' not in x[0]]\n",
    "    \n",
    "    print(f\"=== CHANGES BY CATEGORY ===\")\n",
    "    print(f\"\")\n",
    "    print(f\"EXPECTED CHANGES:\")\n",
    "    print(f\"  LUT (.lut):           {len(lut_changed):3d}  {'✓' if lut_changed else '✗'}\")\n",
    "    print(f\"  _lut_raw_deltas:      {len(delta_changed):3d}  {'✓' if delta_changed else '✗'}\")\n",
    "    print(f\"  Scales (A/B/mag):     {len(scale_changed):3d}  {'✓' if scale_changed else '✗'}\")\n",
    "    print(f\"\")\n",
    "    print(f\"SHOULD NOT CHANGE:\")\n",
    "    print(f\"  _Q buffers:           {len(q_changed):3d}  {'✗ BUG!' if q_changed else '✓ OK'}\")\n",
    "    print(f\"  _indices:             {len(indices_changed):3d}  {'✗ BUG!' if indices_changed else '✓ OK'}\")\n",
    "    print(f\"  Other:                {len(other_changed):3d}  {'?' if other_changed else '✓ OK'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [CELL 10: Analyze _Q changes - THE KEY RESULT]\n",
    "# ============================================================\n",
    "# DETAILED _Q ANALYSIS (THIS IS WHAT WE'RE TESTING)\n",
    "# ============================================================\n",
    "\n",
    "if trained_sd:\n",
    "    if q_changed:\n",
    "        print(f\"!!! _Q BUFFERS CHANGED (UNEXPECTED) !!!\")\n",
    "        print(f\"\")\n",
    "        print(f\"Found {len(q_changed)} _Q tensors that changed during training.\")\n",
    "        print(f\"This indicates a bug in the training code.\")\n",
    "        print(f\"\")\n",
    "        print(f\"Top 20 changes:\")\n",
    "        for k, mx, mn, sm in sorted(q_changed, key=lambda x: x[1], reverse=True)[:20]:\n",
    "            print(f\"  max={mx:.6e}  mean={mn:.6e}  {k}\")\n",
    "        \n",
    "        # Analyze one in detail\n",
    "        sample_key = q_changed[0][0]\n",
    "        t1 = initial_sd[sample_key]\n",
    "        t2 = trained_sd[sample_key]\n",
    "        \n",
    "        print(f\"\")\n",
    "        print(f\"=== Detailed analysis: {sample_key} ===\")\n",
    "        print(f\"  Shape: {t1.shape}\")\n",
    "        print(f\"  dtype: {t1.dtype} -> {t2.dtype}\")\n",
    "        \n",
    "        diff = (t1.float() - t2.float())\n",
    "        changed_mask = diff != 0\n",
    "        n_changed = changed_mask.sum().item()\n",
    "        \n",
    "        print(f\"  Elements changed: {n_changed} / {t1.numel()} ({100*n_changed/t1.numel():.2f}%)\")\n",
    "        if n_changed > 0 and n_changed < 100:\n",
    "            print(f\"  Change values: {diff[changed_mask].unique().tolist()}\")\n",
    "    else:\n",
    "        print(f\"=== _Q BUFFERS UNCHANGED (EXPECTED) ===\")\n",
    "        print(f\"\")\n",
    "        print(f\"All {len([k for k in unchanged if '._Q' in k])} _Q tensors remained unchanged.\")\n",
    "        print(f\"\")\n",
    "        print(f\"This confirms:\")\n",
    "        print(f\"  - _Q is a buffer (not trained)\")\n",
    "        print(f\"  - Forward pass uses lut[_indices] when LUT training enabled\")\n",
    "        print(f\"  - Any _Q changes in production runs come from BAKING, not training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [CELL 11: Verify LUT training worked]\n",
    "# ============================================================\n",
    "# VERIFY LUT TRAINING IS WORKING\n",
    "# ============================================================\n",
    "\n",
    "if trained_sd:\n",
    "    print(f\"=== LUT TRAINING VERIFICATION ===\")\n",
    "    print(f\"\")\n",
    "    \n",
    "    # Check delta values\n",
    "    delta_keys_trained = [k for k in trained_sd if '_lut_raw_deltas' in k]\n",
    "    if delta_keys_trained:\n",
    "        print(f\"Found {len(delta_keys_trained)} _lut_raw_deltas tensors\")\n",
    "        \n",
    "        # Check if any have non-zero values\n",
    "        nonzero_deltas = 0\n",
    "        for k in delta_keys_trained[:5]:\n",
    "            delta = trained_sd[k]\n",
    "            if delta.abs().max() > 1e-8:\n",
    "                nonzero_deltas += 1\n",
    "                print(f\"\")\n",
    "                print(f\"  {k}:\")\n",
    "                print(f\"    values: {delta.tolist()}\")\n",
    "                print(f\"    max_abs: {delta.abs().max().item():.6f}\")\n",
    "        \n",
    "        print(f\"\")\n",
    "        if nonzero_deltas > 0:\n",
    "            print(f\"✓ LUT deltas are non-zero - LUT training is working!\")\n",
    "        else:\n",
    "            print(f\"✗ WARNING: LUT deltas are all zero - LUT may not be training!\")\n",
    "    else:\n",
    "        print(f\"No _lut_raw_deltas found in trained checkpoint\")\n",
    "        print(f\"This might mean LUT training wasn't enabled properly.\")\n",
    "    \n",
    "    # Check LUT value changes\n",
    "    print(f\"\")\n",
    "    print(f\"=== LUT VALUE CHANGES ===\")\n",
    "    if lut_changed:\n",
    "        print(f\"\")\n",
    "        for k, mx, mn, sm in sorted(lut_changed, key=lambda x: x[1], reverse=True)[:3]:\n",
    "            print(f\"{k}:\")\n",
    "            print(f\"  max_diff: {mx:.6f}\")\n",
    "            print(f\"  initial:  {initial_sd[k].tolist()}\")\n",
    "            print(f\"  trained:  {trained_sd[k].tolist()}\")\n",
    "            print(f\"\")\n",
    "    else:\n",
    "        print(f\"No LUT values changed (they might be computed on-the-fly from deltas)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [CELL 12: Conclusion]\n",
    "# ============================================================\n",
    "# EXPERIMENT CONCLUSION\n",
    "# ============================================================\n",
    "\n",
    "if trained_sd:\n",
    "    print(f\"=\"*60)\n",
    "    print(f\"EXPERIMENT SUMMARY\")\n",
    "    print(f\"=\"*60)\n",
    "    print(f\"\")\n",
    "    print(f\"Training: {MAX_STEPS} steps, LUT + scales, from v2_initial.pt\")\n",
    "    print(f\"\")\n",
    "    print(f\"Expected changes:\")\n",
    "    print(f\"  - LUT values:     {len(lut_changed)} changed\")\n",
    "    print(f\"  - LUT deltas:     {len(delta_changed)} changed\")\n",
    "    print(f\"  - Scale params:   {len(scale_changed)} changed\")\n",
    "    print(f\"\")\n",
    "    print(f\"Unexpected changes:\")\n",
    "    print(f\"  - _Q buffers:     {len(q_changed)} changed\")\n",
    "    print(f\"  - _indices:       {len(indices_changed)} changed\")\n",
    "    print(f\"  - Other:          {len(other_changed)} changed\")\n",
    "    print(f\"\")\n",
    "    \n",
    "    if len(q_changed) == 0:\n",
    "        print(f\">>> RESULT: _Q buffers correctly UNCHANGED during training.\")\n",
    "        print(f\"\")\n",
    "        print(f\"    The _Q changes observed in srLUT-004c vs v2_initial\")\n",
    "        print(f\"    must have come from:\")\n",
    "        print(f\"      1. The PREVIOUS run's LUT training + baking\")\n",
    "        print(f\"      2. The bake_lut.py script that refreshes _Q from lut[_indices]\")\n",
    "        print(f\"\")\n",
    "        print(f\"    This is EXPECTED behavior - baking updates _Q to reflect trained LUT.\")\n",
    "    else:\n",
    "        print(f\">>> BUG FOUND: _Q buffers changed during training!\")\n",
    "        print(f\"\")\n",
    "        print(f\"    This indicates a bug in the training code.\")\n",
    "        print(f\"    _Q should be a frozen buffer that only changes via:\")\n",
    "        print(f\"      - freeze_Q() at init\")\n",
    "        print(f\"      - sync_q_from_indices() explicitly\")\n",
    "        print(f\"      - bake_lut.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: Compare srLUT-004c Input vs Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [CELL 13: Compare baked input to srLUT-004c output]\n",
    "# ============================================================\n",
    "# VERIFY: _Q unchanged during srLUT-004c training itself\n",
    "# ============================================================\n",
    "# This compares the INPUT checkpoint to srLUT-004c vs its OUTPUT\n",
    "# to confirm that training doesn't modify _Q.\n",
    "\n",
    "BAKED_INPUT = f\"{GD_RUNS}/srLUT-004_all_alpaca_M2p0_lr1e5_from_best/baked_step200.pt\"\n",
    "SRLUT_004C_OUTPUT = f\"{GD_RUNS}/srLUT-004c_all_alpaca_from_baked200_lut_plus_scales/best_state_dict.pt\"\n",
    "\n",
    "if os.path.exists(BAKED_INPUT) and os.path.exists(SRLUT_004C_OUTPUT):\n",
    "    print(f\"Comparing srLUT-004c INPUT vs OUTPUT...\")\n",
    "    print(f\"\")\n",
    "    print(f\"Input:  {BAKED_INPUT}\")\n",
    "    print(f\"Output: {SRLUT_004C_OUTPUT}\")\n",
    "    print(f\"\")\n",
    "    \n",
    "    baked_sd = torch.load(BAKED_INPUT, map_location='cpu', weights_only=False)\n",
    "    output_sd = torch.load(SRLUT_004C_OUTPUT, map_location='cpu', weights_only=False)\n",
    "    \n",
    "    q_diff_in_run = 0\n",
    "    q_same_in_run = 0\n",
    "    \n",
    "    for k in sorted(baked_sd.keys()):\n",
    "        if '._Q' in k and k in output_sd:\n",
    "            if torch.equal(baked_sd[k], output_sd[k]):\n",
    "                q_same_in_run += 1\n",
    "            else:\n",
    "                q_diff_in_run += 1\n",
    "    \n",
    "    print(f\"_Q comparison (baked_step200 vs best_state_dict):\")\n",
    "    print(f\"  Unchanged: {q_same_in_run}\")\n",
    "    print(f\"  Changed:   {q_diff_in_run}\")\n",
    "    print(f\"\")\n",
    "    \n",
    "    if q_diff_in_run == 0:\n",
    "        print(f\">>> _Q unchanged during srLUT-004c training (as expected)!\")\n",
    "        print(f\"    All _Q changes vs v2_initial came from the PREVIOUS run's baking.\")\n",
    "    else:\n",
    "        print(f\">>> _Q changed during srLUT-004c training!\")\n",
    "        print(f\"    This is unexpected - need to investigate further.\")\n",
    "else:\n",
    "    missing = []\n",
    "    if not os.path.exists(BAKED_INPUT):\n",
    "        missing.append(BAKED_INPUT)\n",
    "    if not os.path.exists(SRLUT_004C_OUTPUT):\n",
    "        missing.append(SRLUT_004C_OUTPUT)\n",
    "    print(f\"Cannot compare - missing files:\")\n",
    "    for m in missing:\n",
    "        print(f\"  {m}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [CELL 14: Compare v2_initial vs baked_step200]\n",
    "# ============================================================\n",
    "# TRACE THE SOURCE OF _Q CHANGES\n",
    "# ============================================================\n",
    "# This shows where the _Q changes actually came from.\n",
    "\n",
    "if os.path.exists(BAKED_INPUT):\n",
    "    print(f\"Comparing v2_initial vs baked_step200 (source of _Q changes)...\")\n",
    "    print(f\"\")\n",
    "    \n",
    "    if 'baked_sd' not in dir():\n",
    "        baked_sd = torch.load(BAKED_INPUT, map_location='cpu', weights_only=False)\n",
    "    \n",
    "    q_diff_from_init = 0\n",
    "    q_same_from_init = 0\n",
    "    \n",
    "    for k in sorted(initial_sd.keys()):\n",
    "        if '._Q' in k and k in baked_sd:\n",
    "            if torch.equal(initial_sd[k], baked_sd[k]):\n",
    "                q_same_from_init += 1\n",
    "            else:\n",
    "                q_diff_from_init += 1\n",
    "    \n",
    "    print(f\"_Q comparison (v2_initial vs baked_step200):\")\n",
    "    print(f\"  Unchanged: {q_same_from_init}\")\n",
    "    print(f\"  Changed:   {q_diff_from_init}\")\n",
    "    print(f\"\")\n",
    "    \n",
    "    if q_diff_from_init > 0:\n",
    "        print(f\">>> The baked_step200 checkpoint already has {q_diff_from_init} different _Q values!\")\n",
    "        print(f\"\")\n",
    "        print(f\"This confirms the chain of events:\")\n",
    "        print(f\"  1. v2_initial.pt created with original _Q\")\n",
    "        print(f\"  2. srLUT-004 trained LUTs (LUT values changed, _Q unchanged)\")\n",
    "        print(f\"  3. bake_lut.py refreshed _Q from trained lut[_indices]\")\n",
    "        print(f\"  4. baked_step200.pt saved with NEW _Q values\")\n",
    "        print(f\"  5. srLUT-004c started from baked_step200 (already has new _Q)\")\n",
    "        print(f\"  6. srLUT-004c training did NOT change _Q further\")\n",
    "    else:\n",
    "        print(f\"Interesting: _Q values are the same between v2_initial and baked_step200\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
