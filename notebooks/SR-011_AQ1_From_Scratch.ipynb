{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lqWTWF5EFCuV"
   },
   "source": "# SR-011: Q4_A4_r32 From Scratch\n\n**Rev: 1.4 (2026-01-09 16:00 PST)** - Deferred cache download until after model creation\n\n**Configuration: 4-bit MLP, 4-bit Attention, rank=32**\n\n| Component | LUT Size | Bits | Scale Rank |\n|-----------|----------|------|------------|\n| MLP | 16 | 4 | 32 |\n| Attention | 16 | 4 | 32 |\n\n## Workflow (IMPORTANT ORDER)\n\n### Step 0: Create Initial V2 Checkpoint (MUST BE FP32)\n1. Load Qwen3-0.6B base model (FP32)\n2. Replace linears with V2 (group init -> SVD decomposition)\n3. Freeze Q (compute quantization indices once)\n4. **Save initial checkpoint** (this is your \"truth\" checkpoint)\n5. Download KD cache (deferred to avoid wasting time if model creation fails)\n6. Run sanity checks (mags, LUT FP16 representability)\n\n### Step 1: MLP-Only Training + AutoSnap Mags (Terminal)\n- Train MLP scales only (`--mlp-only`)\n- Enable AutoSnap for rank_magnitude (`--auto-snap-mags --auto-snap-target mlp`)\n- Use **FP32** dtype (`--dtype fp32`) to avoid BF16 rounding during mag training\n- Mags automatically frozen when stable\n- Use `scripts/train_v2_simple.py` (terminal command in CELL 14)\n\n### Step 2: Attention Training (Python API)\n- Train attention scales (Python API, no CLI --attn-only flag)\n- MLP layers frozen (scales and mags)\n- Uses `train_e2e()` with explicit freeze/enable logic (CELL 18)\n\n### Step 3: Global Fine-tune + Export\n- Low LR polish (optional)\n- Final snap + export for ANE\n\n## CLI Flag Reference\n\n| Flag | Purpose |\n|------|---------|\n| `--v2-checkpoint` | Load V2 checkpoint (NOT --checkpoint) |\n| `--dtype fp32` | FP32 training (recommended for scale/mag training) |\n| `--dtype bf16` | BF16 training (faster, use after mags frozen) |\n| `--mlp-only` | Train MLP layers only, freeze attention |\n| `--freeze-mags-mlp` | Freeze MLP rank_magnitude (after AutoSnap) |\n| `--auto-snap-mags` | Enable auto-snap of rank_magnitude when stable |\n\n## Cell Index\n\n| Cell | Purpose |\n|------|---------|\n| 1-4 | Setup (paths, mount, clone, deps) |\n| 5 | Cache config (paths only, no download) |\n| 6 | Configuration (Q4_A4_r32, AutoSnap params) |\n| 7-9 | Load model, replace linears, freeze Q |\n| 9b | Save to /tmp for inspection |\n| **9c** | **Download KD cache (deferred)** |\n| 10 | Verify gradients, compute initial loss |\n| 11 | Save initial checkpoint (Step 0 complete) |\n| 12 | **Sanity checks** (Q frozen, LUT, mags) |\n| 13 | Upload to Google Drive |\n| **14** | **Phase A: MLP-only + AutoSnap (terminal cmd)** |\n| 15-17 | Optional: weight tuning, MLP refinement |\n| **18** | **Phase B: Attention training (Python API)** |\n| 19-20 | Joint fine-tune, save final |\n| 21-25 | Inference, export for ANE |\n\n## V2 Key Features:\n- Rank-by-rank forward pass (ANE-friendly)\n- Per-rank normalization: `scale_A` (unit columns), `scale_B` (unit rows), `rank_magnitude`\n- **Frozen Q**: indices computed once at init via group init + SVD\n- **STE-FP16**: Built into V2 forward (no --use-ste flag needed)\n\n## From-Scratch Initialization (Step 0):\n1. Group init: Compute per-group max-abs scales\n2. Expand: Repeat to per-weight scales\n3. SVD: `u, s, vh = svd(scales)` -> `scale_A=u[:,:r]`, `scale_B=vh[:r,:]`, `rank_magnitude=s[:r]`"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kfh54i9XFCuW"
   },
   "outputs": [],
   "source": "# [CELL 1: Google Drive paths]\n# ============================================================\n# GOOGLE DRIVE PATHS (STANDARD)\n# ============================================================\n\n# Checkpoints/runs go here\nGD_RUNS = '/content/drive/MyDrive/qwen3_runs'\n\n# KD caches go here\nGD_CACHES = '/content/drive/MyDrive/qwen3_caches'\n\n# Local directories (on Colab VM)\nLOCAL_RUNS = 'runs'\nLOCAL_CACHES = 'caches'"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tw1k9-anFCuW",
    "outputId": "9c82b0b4-4a4e-4852-b064-128804bb1430"
   },
   "outputs": [],
   "source": "# [CELL 2: Mount Google Drive]\n# Mount Google Drive\nfrom google.colab import drive\ndrive.mount('/content/drive')"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7X9uxbCPPykd"
   },
   "source": [
    "### GITUB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HtdvB50DFCuW",
    "outputId": "ea1fb98c-6e27-4765-ac42-3a22f6bf888a"
   },
   "outputs": [],
   "source": "# [CELL 3: Clone/update repo]\n# Clone repo if needed\n!git clone https://github.com/anemll/qwen3_apple_style_2bit_qat_lora.git || (cd qwen3_apple_style_2bit_qat_lora && git pull)\n%cd qwen3_apple_style_2bit_qat_lora\n# to allow updates\n!git fetch\n!git pull\n!git reset --hard HEAD\nimport sys\n[sys.modules.pop(k) for k in list(sys.modules) if k.startswith('qat_lora')]\n\n# Import V2 modules\nfrom qat_lora import (\n    # V2 ANE-friendly classes\n    AnemllQATLinearV2,\n    AnemllQuantConfigV2,\n    replace_linear_with_anemll_v2,\n    freeze_Q_all,\n    freeze_model_for_inference_v2,\n    unfreeze_model_for_training_v2,\n    # Training utilities\n    evaluate_kd_loss,\n    train_e2e,\n    save_checkpoint,\n    load_checkpoint,\n)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1dJ5vGK9FCuW"
   },
   "outputs": [],
   "source": "# [CELL 4: Install dependencies]\n# Install dependencies\n!pip install -q transformers accelerate safetensors"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hgqQOvUpFCuW",
    "outputId": "4946891f-313c-423f-e82c-0d8919f44c7e"
   },
   "outputs": [],
   "source": "# [CELL 5: Cache paths (download deferred)]\n# ============================================================\n# KD CACHE CONFIGURATION (download happens later)\n# ============================================================\n# Define cache name and paths here. Actual download is deferred\n# until after the V2 model is created (Cell 9c).\n\nimport os\n\n#CACHE_NAME = 'alpaca_chat_think_both_L128_K32_R256'\n#CACHE_NAME = 'alpaca_chat_think_both_L128_K64_R512'\nCACHE_NAME = 'alpaca_chat_think_both_L128_K128_R1024'\n\nCACHE_TGZ = f'{CACHE_NAME}.tgz'\ncache_local_path = f'{LOCAL_CACHES}/{CACHE_NAME}'\n\nprint(f\"Cache configured: {CACHE_NAME}\")\nprint(f\"  Local path: {cache_local_path}\")\nprint(f\"  Download will happen after model creation (Cell 9c)\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EJ239_eUFCuW",
    "outputId": "3bbfadc8-4925-4980-b19d-aa02005beaa3"
   },
   "outputs": [],
   "source": "# [CELL 6: Configuration - Q4_A4_r32]\n# ============================================================\n# CONFIGURATION - Q4_A4_r32 (4-bit MLP, 4-bit Attention, rank=32)\n# ============================================================\n# IMPORTANT: Step 0 MUST use FP32 for SVD init accuracy!\n\nimport torch\n\n# Model\nMODEL_ID = 'Qwen/Qwen3-0.6B'\n\n# === MLP Quantization (4-bit) ===\nLUT_BITS = 4\nLUT_SIZE = 2**LUT_BITS  # 16 values\nSCALE_RANK = 32  # High rank for quality\n\n# === Attention Quantization (4-bit) ===\nATTN_LUT_BITS = 4\nATTN_LUT_SIZE = 2**ATTN_LUT_BITS  # 16 values\nATTN_SCALE_RANK = 32  # Same rank as MLP\n\n# Training\nBATCH_SIZE = 8\nGRAD_ACCUM = 4\n\nif torch.cuda.is_available():\n    BATCH_SIZE = 16\n    GRAD_ACCUM = 2\n\nLR = 5e-5\nMIN_LR_RATIO = 0.1\n\n# KD / Distillation params\nDISTILL_TEMP = 2.0\nHARD_TOP1_WEIGHT = 0.0  # Pure KD for scale training\nHARD_FULL_WEIGHT = 0.0\n\n# Device\nDEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# CRITICAL: Step 0 must use FP32 for accurate SVD init\n# Training can later use BF16 for speed\nDTYPE = torch.float32  # FP32 for Step 0 checkpoint creation\n\n# ============================================================\n# AUTO-SNAP CONFIGURATION (for MLP-only training in Step 1)\n# ============================================================\nAUTO_SNAP_ENABLE = False   # OFF for Step 0, enable in Step 1\nAUTO_SNAP_TARGET = \"mlp\"   # \"mlp\" for MLP-only phase\nAUTO_SNAP_THRESHOLD = 0.05  # Max abs delta to consider stable\nAUTO_SNAP_PATIENCE = 2      # Consecutive stable saves before freeze\nAUTO_SNAP_START_STEP = 100  # Don't audit before this step\nAUTO_SNAP_MIN_SAVES = 2     # Minimum saves before eligible\nAUTO_SNAP_DRY_RUN = False   # Set True to audit without freezing\n\n# Quality string for filenames\nQUAL = f'q{LUT_BITS}_a{ATTN_LUT_BITS}_r{SCALE_RANK}'\n\nprint(f'=== SR-011: Q4_A4_r32 From Scratch ===')\nprint(f'Quality: {QUAL} (4-bit MLP, 4-bit Attention)')\nprint(f'Device: {DEVICE}')\nprint(f'')\nprint(f'*** STEP 0: FP32 dtype for SVD init accuracy ***')\nprint(f'dtype: {DTYPE}')\nprint(f'')\nprint(f'MLP Config:')\nprint(f'  LUT size: {LUT_SIZE} ({LUT_BITS}-bit)')\nprint(f'  Scale rank: {SCALE_RANK}')\nprint(f'')\nprint(f'Attention Config:')\nprint(f'  LUT size: {ATTN_LUT_SIZE} ({ATTN_LUT_BITS}-bit)')\nprint(f'  Scale rank: {ATTN_SCALE_RANK}')\nprint(f'')\nprint(f'AutoSnap Config (for Step 1):')\nprint(f'  Enabled: {AUTO_SNAP_ENABLE}')\nprint(f'  Target: {AUTO_SNAP_TARGET}')\nprint(f'  Threshold: {AUTO_SNAP_THRESHOLD}')\nprint(f'  Patience: {AUTO_SNAP_PATIENCE}')\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 417,
     "referenced_widgets": [
      "9ceaade381e94c258a3c0ffe6b8993ee",
      "09079f4c40b24d47b16b3a9d39eac18f",
      "c1ca5e81b3884530acba75733f2b2ef3",
      "b66e47d1dccd4aaa9053968667cfafe3",
      "02947099e48c465691d6d41dcd1e877b",
      "f10f6efb961f426dba0e85b4f4fc54ba",
      "f029416c83fe4e1daf94c137e9b70038",
      "723cb77b570b43c780f7816ce9aa4f81",
      "02f92b038c3942369d6bbda0b85561bd",
      "eab5f44c082e486cbfef722597968c27",
      "c181cb34a1c44cff9f701fcb264f4639",
      "3f33d3f10a104364a08b5a972d868404",
      "e34e197865624c319e5c3efd61cec5f1",
      "e1f9a8ad18a0404f91bd633266a987c1",
      "7dafcef8629943bba8b552eb65cf4319",
      "cd45240c029a4d89bf7856dfe692f487",
      "1643098c16724226b2f135666c853021",
      "b89e33aa337d495b9c5f0afa5c4e531f",
      "cdde30488ec24b2f8ff1ac50adf677c1",
      "e4a9b6abc3bb4d72b33910184b8dee53",
      "32ddfc19754f4f3ba3fd05ceb443200b",
      "9d78c3b445ae4b4b9255f381dbbbf297",
      "6d34db691b8549708447dc4528918bd7",
      "6f4a70c1d8b443019ce0db5845dbeabe",
      "fbd65fe0ad714e719255caa92dc42988",
      "458a362e07ef46fdab537612157215fc",
      "6401e8dd76cf43c9bca85eafa9584072",
      "d28e621974114f798fa7f6f7147c18c1",
      "c4f53cf052434846851f7bb9681f06f3",
      "1a5a12de6a824d8784f0b5c8b39df05c",
      "a5c2c0a43dff4b78bd2dea20244a743b",
      "b8c783ede2f445dd8538a743155eb07d",
      "d4c27e7c0c394e75b28c3a2da7233afd",
      "7c23ec2e04e04555bcc86795b8b98a6a",
      "1222d75ab8a34dd7b4bdb4e57403b74a",
      "dcfa4ead89b34a038cbbff240f802027",
      "06e9bae2da334bfe87877b18848fc0e0",
      "b8c1d61e8f7f40d0a2dfb0aa44d9e4b2",
      "7f0f985b8ba44c80bd30840946cec59f",
      "78f024244cfa4226bb3abbdba4611ac8",
      "13407d3e50f44934ba4cc8d125319a97",
      "395b60bd9d62499ebdf4db8f98d6d060",
      "a0dc69628c774dcab4fdc057d871c71e",
      "c7550f00e5f5491e848cc033cb52d695",
      "9e9b3bbd2ed04af2983090df7fdfa860",
      "79dba7f9976e4d56ba95542576ad784e",
      "61b4ff17161a4472983d9ae7c4038f4c",
      "97e02cb7cc054c76a2a236208bd39288",
      "1e61be30fd06489997bc1073cdf4b63f",
      "cccaf0d3bbbc4d1fab88478bfde18570",
      "9cfe70d1c90d4570a537ba3ba9af8758",
      "1be8597c80774992b05b2b2a3db7e3ca",
      "58c6d1daf9dc4736ad8888fdd2e13051",
      "31c50cde54ce455484d8959587b6761e",
      "756e3d0cd08d444f974dbb4a0d03aeee",
      "aebedea1c0aa48c996f59ceff3b7f59d",
      "99f53192c01e48d28edeaa60bcc93316",
      "f8707033b6bc4ff39b211d9e79429d8f",
      "412c3035861a4d9fa384f8b8285415b7",
      "60d59a18029944c48ec1fa1e667d6c8e",
      "86ca268b812540e98715edec5bcfc312",
      "650dce7e0dfe41c5a7aad9ab6fcb4b7f",
      "69988406b6fd406ca9a657ca1164b716",
      "045937442f11451fae75cf71818f2771",
      "434330f256ed46f384bf6fa47b423b80",
      "5da05f1cfe8a4913b38c49789f367319",
      "ab4ff2b64d29443ba180766a384840b7",
      "ca7eb173d158416cbf10a5c6f485e9a1",
      "683cb5329ed749d593c4592d21095b03",
      "2e1db963227241848378d59b903e9eac",
      "fe3be4ef1c22496091ec419cba32966f",
      "d4c07e275393496f8dee96dd3168a40f",
      "b6a1ab44a70a43d3a6c3fe8be56ff1cb",
      "44606bd8389a4dd7acec4c4e8b27236f",
      "beadf9955191423587bc789d96b539b5",
      "c9ed78eb0a274a4eaa5e9115ae344042",
      "7d71667b5bf8458e846b371058fe0fca"
     ]
    },
    "id": "5e5kQrkxFCuX",
    "outputId": "0579b2d0-ad59-4a30-bca7-a4ca78361275"
   },
   "outputs": [],
   "source": "# [CELL 8: Load model]\n# ============================================================\n# LOAD MODEL\n# ============================================================\n\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\n\nprint(f'Loading {MODEL_ID}...')\ntokenizer = AutoTokenizer.from_pretrained(MODEL_ID, trust_remote_code=True)\nmodel = AutoModelForCausalLM.from_pretrained(\n    MODEL_ID,\n    torch_dtype=DTYPE,\n    trust_remote_code=True,\n)\nmodel.to(DEVICE)\nmodel.eval()\nprint(f'Loaded. Parameters: {sum(p.numel() for p in model.parameters()):,}')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n29f0NexFCuX",
    "outputId": "6fae7409-4a57-489b-b378-0b493fa1b2f5"
   },
   "outputs": [],
   "source": "# [CELL 9: Replace linears + SVD init + freeze Q]\n# ============================================================\n# REPLACE LINEARS WITH AnemllQATLinearV2\n# ============================================================\n\nimport sys\nsys.path.insert(0, '.')\n\n# Force reimport to get latest code\nimport importlib\nimport qat_lora\nimportlib.reload(qat_lora)\nimport qat_lora.ane_qat_linear_v2 as ane_module_v2\nimportlib.reload(ane_module_v2)\nimport qat_lora.layer_qat as layer_module\nimportlib.reload(layer_module)\n\nfrom qat_lora import AnemllQuantConfigV2, replace_linear_with_anemll_v2, freeze_Q_all\n\n# Debug: Check what modules exist in the model\nprint(\"Checking model structure...\")\nimport torch.nn as nn\nlinear_count = 0\nfor name, m in model.named_modules():\n    if isinstance(m, nn.Linear):\n        linear_count += 1\n        if linear_count <= 5:\n            print(f\"  Found Linear: {name}\")\nprint(f\"Total Linear modules: {linear_count}\")\n\n# Create V2 configs with POSITIVE SCALE CONSTRAINTS\n# This prevents scale sign flips when Q is frozen (key fix!)\nmlp_config = AnemllQuantConfigV2(\n    lut_size=LUT_SIZE,\n    scale_rank=SCALE_RANK,\n    learnable_lut=False,\n    # Positive scale constraints (prevents sign flips with frozen Q)\n    force_positive_scales=True,\n    positive_scale_method=\"abs\",      # \"abs\" or \"softplus\"\n    magnitude_activation=\"softplus\",  # keeps g >= 0\n    magnitude_eps=1e-6,\n)\n\nattn_config = AnemllQuantConfigV2(\n    lut_size=ATTN_LUT_SIZE,\n    scale_rank=ATTN_SCALE_RANK,\n    learnable_lut=False,\n    # Positive scale constraints\n    force_positive_scales=True,\n    positive_scale_method=\"abs\",\n    magnitude_activation=\"softplus\",\n    magnitude_eps=1e-6,\n)\n\nprint(f'\\nV2 Config: force_positive_scales={mlp_config.force_positive_scales}')\nprint(f'           positive_scale_method={mlp_config.positive_scale_method}')\nprint(f'           magnitude_activation={mlp_config.magnitude_activation}')\n\nprint('\\nReplacing linear layers with V2...')\ncount = replace_linear_with_anemll_v2(\n    model,\n    mlp_config=mlp_config,\n    attn_config=attn_config,\n    quantize_attn=True,\n    quantize_lm_head=False,\n)\n\n# Verify replacement worked (use type name to avoid reload issues)\nqat_count = sum(1 for _, m in model.named_modules() if type(m).__name__ == 'AnemllQATLinearV2')\nprint(f\"\\nVerification: {qat_count} AnemllQATLinearV2 modules in model\")\n\n# ============================================================\n# FREEZE Q - CRITICAL STEP FOR V2\n# ============================================================\n# Compute Q = lut[indices] once. After this, only scales are trained.\nprint('\\nFreezing Q (computing indices once)...')\nfreeze_Q_all(model, verbose=False)\nprint('Q frozen for all layers. Training will only update scale_A, scale_B, rank_magnitude.')"
  },
  {
   "cell_type": "code",
   "source": "# [CELL 9b: Save V2 model + snap + compare]\n# ============================================================\n# SAVE V2 MODEL TO /tmp + SNAP WITH SCRIPT + COMPARE\n# ============================================================\n# 1. Save initial V2 model (FP32)\n# 2. Save config.json for snap script\n# 3. Run snap_and_test_v2.py (proper snap with all params)\n# 4. Run debug_snap_difference.py to compare\n#\n# NOTE: FP16 snap is always done on CPU internally (.cpu().half().float())\n\nimport os\nimport json\nimport subprocess\n\n# Paths\nORIG_PATH = '/tmp/v2_initial_frozen_Q.pt'\nSNAP_PATH = '/tmp/v2_initial_frozen_Q_snapped.pt'\nCONFIG_PATH = '/tmp/v2_config.json'\n\n# ============================================================\n# STEP 1: Save original model\n# ============================================================\nprint(\"=\" * 60)\nprint(\"STEP 1: Save original V2 model\")\nprint(\"=\" * 60)\ntorch.save(model.state_dict(), ORIG_PATH)\nprint(f\"Saved: {ORIG_PATH}\")\nprint(f\"  Size: {os.path.getsize(ORIG_PATH) / 1e6:.1f} MB\")\n\n# ============================================================\n# STEP 2: Save config.json for reference\n# ============================================================\nprint(\"\\n\" + \"=\" * 60)\nprint(\"STEP 2: Save config.json\")\nprint(\"=\" * 60)\nsnap_config = {\n    'model_id': MODEL_ID,\n    'version': 'v2',\n    'mlp_lut_bits': LUT_BITS,\n    'mlp_scale_rank': SCALE_RANK,\n    'attn_lut_bits': ATTN_LUT_BITS,\n    'attn_scale_rank': ATTN_SCALE_RANK,\n}\nwith open(CONFIG_PATH, 'w') as f:\n    json.dump(snap_config, f, indent=2)\nprint(f\"Saved: {CONFIG_PATH}\")\nprint(f\"  MLP:  {LUT_BITS}-bit LUT, rank={SCALE_RANK}\")\nprint(f\"  Attn: {ATTN_LUT_BITS}-bit LUT, rank={ATTN_SCALE_RANK}\")\n\n# ============================================================\n# STEP 3: Run snap_and_test_v2.py\n# ============================================================\n# CLI args (from --help):\n#   --lut-bits        : MLP LUT bits\n#   --attn-lut-bits   : Attention LUT bits\n#   --scale-rank      : MLP scale rank\n#   --attn-scale-rank : Attention scale rank\n#   --fp16            : Snap to FP16 for ANE (always uses CPU internally)\nprint(\"\\n\" + \"=\" * 60)\nprint(\"STEP 3: Run snap_and_test_v2.py\")\nprint(\"=\" * 60)\n\nsnap_cmd = [\n    'python', 'scripts/snap_and_test_v2.py',\n    '--checkpoint', ORIG_PATH,\n    '--output', SNAP_PATH,\n    '--lut-bits', str(LUT_BITS),\n    '--scale-rank', str(SCALE_RANK),\n    '--attn-lut-bits', str(ATTN_LUT_BITS),\n    '--attn-scale-rank', str(ATTN_SCALE_RANK),\n    '--fp16',  # Snap to FP16 for ANE (internally uses .cpu().half().float())\n    '--no-test',  # Skip inference test (no tokenizer loaded yet)\n]\nprint(f\"Running: {' '.join(snap_cmd)}\")\nprint()\n\nresult = subprocess.run(snap_cmd, capture_output=True, text=True)\nprint(result.stdout)\nif result.stderr:\n    print(\"STDERR:\", result.stderr)\n\nif result.returncode != 0:\n    print(f\"ERROR: snap_and_test_v2.py failed with code {result.returncode}\")\nelse:\n    print(f\"Snapped checkpoint saved: {SNAP_PATH}\")\n\n# ============================================================\n# STEP 4: Run debug_snap_difference.py to compare\n# ============================================================\n# Note: This script always loads on CPU (map_location='cpu')\nprint(\"\\n\" + \"=\" * 60)\nprint(\"STEP 4: Compare with debug_snap_difference.py\")\nprint(\"=\" * 60)\n\ndiff_cmd = [\n    'python', 'scripts/debug_snap_difference.py',\n    ORIG_PATH,\n    SNAP_PATH,\n]\nprint(f\"Running: {' '.join(diff_cmd)}\")\nprint()\n\nresult = subprocess.run(diff_cmd, capture_output=True, text=True)\nprint(result.stdout)\nif result.stderr:\n    print(\"STDERR:\", result.stderr)\n\n# ============================================================\n# External commands for reference\n# ============================================================\nprint(\"\\n\" + \"=\" * 60)\nprint(\"External commands (for terminal):\")\nprint(\"=\" * 60)\nprint(f\"  python scripts/check_mags_fp16.py {ORIG_PATH}\")\nprint(f\"  python scripts/debug_snap_difference.py {ORIG_PATH} {SNAP_PATH}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# [CELL 9c: Download KD cache (after model created)]\n# ============================================================\n# SYNC KD CACHE FROM GOOGLE DRIVE\n# ============================================================\n# Priority order:\n#   1. Folder (rsync) - fastest, no extraction needed\n#   2. .tar.lz4 - fast decompression (copy locally first!)\n#   3. .tgz - slowest but most compatible (copy locally first!)\n#\n# IMPORTANT: Copy archive to local disk BEFORE extracting!\n# Extracting directly from GDrive is extremely slow.\n\nimport os\nimport subprocess\nfrom pathlib import Path\n\nprint(f\"Syncing KD cache: {CACHE_NAME}\")\n\n# Verify drive is mounted\nif not os.path.exists('/content/drive/MyDrive'):\n    print('Google Drive not mounted! Mounting now...')\n    from google.colab import drive\n    drive.mount('/content/drive')\n\n# Create local cache directory\nos.makedirs(LOCAL_CACHES, exist_ok=True)\n\n# Define possible source paths\ngdrive_folder = f'{GD_CACHES}/{CACHE_NAME}'\ngdrive_lz4 = f'{GD_CACHES}/{CACHE_NAME}.tar.lz4'\ngdrive_tgz = f'{GD_CACHES}/{CACHE_NAME}.tgz'\n\n# Check if cache exists locally already\nif os.path.exists(cache_local_path) and list(Path(cache_local_path).glob('*.pt')):\n    print(f'Cache already exists at {cache_local_path}')\n    cache_files = list(Path(cache_local_path).glob('*.pt'))\n    print(f'  Found {len(cache_files)} .pt files')\n\n# Priority 1: Rsync from folder (fastest - no extraction)\nelif os.path.isdir(gdrive_folder):\n    print(f'Found folder: {gdrive_folder}')\n    print('Using rsync (fastest - no extraction needed)...')\n    os.makedirs(cache_local_path, exist_ok=True)\n    result = subprocess.run(\n        ['rsync', '-ah', '--progress', f'{gdrive_folder}/', f'{cache_local_path}/'],\n        capture_output=False\n    )\n    if result.returncode != 0:\n        raise RuntimeError(f'rsync failed with code {result.returncode}')\n\n# Priority 2: Copy .tar.lz4 locally, then extract (fast)\nelif os.path.exists(gdrive_lz4):\n    print(f'Found: {gdrive_lz4}')\n    size_gb = os.path.getsize(gdrive_lz4) / (1024**3)\n\n    # Install lz4 if needed\n    print('  Installing lz4 if needed...')\n    subprocess.run(['apt-get', 'install', '-y', '-qq', 'lz4'], capture_output=True)\n\n    # Copy to local first with rsync --progress (MUCH faster than extracting from GDrive)\n    local_archive = f'{LOCAL_CACHES}/{CACHE_NAME}.tar.lz4'\n    print(f'  Copying to local disk ({size_gb:.2f} GB)...')\n    result = subprocess.run(\n        ['rsync', '-ah', '--progress', gdrive_lz4, local_archive],\n        capture_output=False  # Show progress\n    )\n    if result.returncode != 0:\n        raise RuntimeError(f'rsync copy failed with code {result.returncode}')\n\n    # Extract from local disk\n    print(f'  Extracting from local disk...')\n    result = subprocess.run(\n        f'lz4 -d \"{local_archive}\" -c | tar -xf - -C \"{LOCAL_CACHES}\"',\n        shell=True,\n        capture_output=True,\n        text=True\n    )\n    if result.returncode != 0:\n        print(f'  STDERR: {result.stderr}')\n        raise RuntimeError(f'lz4 extraction failed with code {result.returncode}')\n\n    # Delete local archive to save space\n    print(f'  Cleaning up local archive...')\n    os.remove(local_archive)\n\n# Priority 3: Copy .tgz locally, then extract\nelif os.path.exists(gdrive_tgz):\n    print(f'Found: {gdrive_tgz}')\n    size_gb = os.path.getsize(gdrive_tgz) / (1024**3)\n\n    # Copy to local first with rsync --progress\n    local_archive = f'{LOCAL_CACHES}/{CACHE_NAME}.tgz'\n    print(f'  Copying to local disk ({size_gb:.2f} GB)...')\n    result = subprocess.run(\n        ['rsync', '-ah', '--progress', gdrive_tgz, local_archive],\n        capture_output=False  # Show progress\n    )\n    if result.returncode != 0:\n        raise RuntimeError(f'rsync copy failed with code {result.returncode}')\n\n    # Extract from local disk\n    print(f'  Extracting from local disk...')\n    result = subprocess.run(\n        ['tar', '-xzf', local_archive, '-C', LOCAL_CACHES],\n        capture_output=True,\n        text=True\n    )\n    if result.returncode != 0:\n        print(f'  STDERR: {result.stderr}')\n        raise RuntimeError(f'tar extraction failed with code {result.returncode}')\n\n    # Delete local archive to save space\n    print(f'  Cleaning up local archive...')\n    os.remove(local_archive)\n\nelse:\n    print(f'ERROR: Cache not found in Google Drive!')\n    print(f'  Checked:')\n    print(f'    - {gdrive_folder}/ (folder)')\n    print(f'    - {gdrive_lz4} (.tar.lz4)')\n    print(f'    - {gdrive_tgz} (.tgz)')\n    raise FileNotFoundError(f'Cache {CACHE_NAME} not found in {GD_CACHES}')\n\n# Verify cache exists\nassert os.path.exists(cache_local_path), f'Cache not found at {cache_local_path}'\ncache_files = list(Path(cache_local_path).glob('*.pt'))\nprint(f'\\n✓ Cache ready: {len(cache_files)} .pt files in {cache_local_path}')",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D_gOyY1qFCuX",
    "outputId": "844dd8ce-8ccb-4052-8f87-627c7539416c"
   },
   "outputs": [],
   "source": "# [CELL 10: Verify gradient flow]\n# ============================================================\n# VERIFY GRADIENT FLOW FOR V2\n# ============================================================\n\nfrom qat_lora import evaluate_kd_loss\n\nprint('Verifying V2 gradient flow...')\n\n# Find a V2 layer (use type name to avoid reload issues)\nlayer0 = model.model.layers[0]\ntest_module = None\nfor name, m in layer0.named_modules():\n    if type(m).__name__ == 'AnemllQATLinearV2':\n        test_module = m\n        break\n\nif test_module is None:\n    print(\"ERROR: No AnemllQATLinearV2 modules found! Replacement failed.\")\nelse:\n    # V2: weight is frozen, only scales are trained\n    print(f\"  weight.requires_grad: {test_module.weight.requires_grad} (should be False after freeze_Q)\")\n    print(f\"  scale_A.requires_grad: {test_module.scale_A.requires_grad}\")\n    print(f\"  scale_B.requires_grad: {test_module.scale_B.requires_grad}\")\n    print(f\"  rank_magnitude.requires_grad: {test_module.rank_magnitude.requires_grad}\")\n    print(f\"  Q frozen: {test_module._Q is not None}\")\n    \n    # Test gradient flow through scales\n    test_module.scale_A.requires_grad = True\n    test_module.scale_B.requires_grad = True\n    test_module.rank_magnitude.requires_grad = True\n    \n    x = torch.randn(1, 10, test_module.in_features, device=DEVICE, dtype=DTYPE)\n    y = test_module(x)\n    loss = y.sum()\n    try:\n        loss.backward()\n        if test_module.scale_A.grad is not None:\n            print(f\"  Gradient OK: scale_A.grad.shape = {test_module.scale_A.grad.shape}\")\n            print(f\"               scale_B.grad.shape = {test_module.scale_B.grad.shape}\")\n            print(f\"               rank_magnitude.grad.shape = {test_module.rank_magnitude.grad.shape}\")\n            # Clear for actual training\n            test_module.scale_A.grad = None\n            test_module.scale_B.grad = None\n            test_module.rank_magnitude.grad = None\n        else:\n            print(\"  ERROR: scale_A.grad is None after backward!\")\n    except Exception as e:\n        print(f\"  ERROR during backward: {e}\")\n\n# Compute initial KD loss\nprint('\\nComputing initial KD loss...')\ninitial_loss = evaluate_kd_loss(model, cache_local_path, DEVICE, num_samples=40, temperature=DISTILL_TEMP)\nprint(f'Initial KD Loss: {initial_loss:.4f}')"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9B4uAJDNfRgs"
   },
   "source": "# **V2 SCALE OPTIMIZATION** (Q and Weights Frozen)\n\nIn V2, we train only the scale parameters:\n- `scale_A`: [out, rank] - unit-norm columns\n- `scale_B`: [rank, in] - unit-norm rows  \n- `rank_magnitude`: [rank] - the ONLY magnitude\n\nThe frozen components:\n- `weight`: Original FP weights (frozen by `freeze_Q()`)\n- `_Q`: LUT values = `lut[indices]` (computed once by `freeze_Q()`)\n- `_indices`: Quantization indices (computed once)\n\n**Why this works:**\n- Q represents the normalized quantized weights in [-1, 1]\n- Scales modulate the contribution of each rank\n- Training adjusts how much each rank contributes to the output\n\n**Training strategy:** E2E training (all layers together) is more effective than layer-by-layer."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lxSBHcq6FCuX"
   },
   "outputs": [],
   "source": "# [CELL 11: Save initial checkpoint]\n# ============================================================\n# SAVE INITIAL V2 CHECKPOINT (BEFORE TRAINING)\n# ============================================================\n\nimport os\n\nRUN_NAME = f'SR-011_{QUAL}_from_scratch'\nSAVE_DIR = f'{LOCAL_RUNS}/{RUN_NAME}'\n\nos.makedirs(SAVE_DIR, exist_ok=True)\n\n# Save state dict\ntorch.save(model.state_dict(), f'{SAVE_DIR}/model_state_dict.pt')\n\n# Save config\nimport json\nconfig = {\n    'model_id': MODEL_ID,\n    'version': 'v2',  # Mark as V2\n    'lut_size': LUT_SIZE,\n    'scale_rank': SCALE_RANK,\n    'attn_lut_size': ATTN_LUT_SIZE,\n    'attn_scale_rank': ATTN_SCALE_RANK,\n    'initial_kd_loss': initial_loss,\n}\nwith open(f'{SAVE_DIR}/config.json', 'w') as f:\n    json.dump(config, f, indent=2)\n\nprint(f'Saved V2 checkpoint to {SAVE_DIR}')"
  },
  {
   "cell_type": "code",
   "source": "# [CELL 12: Sanity checks (CPU-only, before training)]\n# ============================================================\n# SANITY CHECKS FOR V2 INITIALIZATION\n# ============================================================\n# Run these checks BEFORE training to verify correct setup:\n# 1. Q is frozen (indices computed)\n# 2. LUT values are FP16-representable\n# 3. rank_magnitude stats look reasonable\n\nprint(\"=\" * 60)\nprint(\"SANITY CHECKS (Step 0 Verification)\")\nprint(\"=\" * 60)\n\n# Check 1: Q frozen\nq_frozen_count = 0\nq_not_frozen = []\nfor name, module in model.named_modules():\n    if type(module).__name__ == 'AnemllQATLinearV2':\n        if module._Q is not None:\n            q_frozen_count += 1\n        else:\n            q_not_frozen.append(name)\n\nprint(f\"\\n[Check 1] Q Frozen: {q_frozen_count} layers\")\nif q_not_frozen:\n    print(f\"  WARNING: {len(q_not_frozen)} layers have Q=None!\")\n    for n in q_not_frozen[:5]:\n        print(f\"    - {n}\")\nelse:\n    print(\"  ✓ All layers have frozen Q\")\n\n# Check 2: LUT FP16 representability\nlut_issues = []\nfor name, module in model.named_modules():\n    if type(module).__name__ == 'AnemllQATLinearV2':\n        lut = module.lut.data.cpu()\n        lut_fp16 = lut.half().float()\n        max_diff = (lut - lut_fp16).abs().max().item()\n        if max_diff > 1e-6:\n            lut_issues.append((name, max_diff))\n        break  # Just check one (they should all be the same)\n\nprint(f\"\\n[Check 2] LUT FP16 Representability:\")\nif lut_issues:\n    print(f\"  WARNING: {len(lut_issues)} layers have LUT precision issues\")\nelse:\n    print(\"  ✓ LUT values are FP16-representable\")\n\n# Check 3: rank_magnitude stats\nmag_stats = {'min': float('inf'), 'max': float('-inf'), 'mean': 0, 'count': 0}\nfor name, module in model.named_modules():\n    if type(module).__name__ == 'AnemllQATLinearV2':\n        mag = module.rank_magnitude.data.cpu()\n        mag_stats['min'] = min(mag_stats['min'], mag.min().item())\n        mag_stats['max'] = max(mag_stats['max'], mag.max().item())\n        mag_stats['mean'] += mag.mean().item()\n        mag_stats['count'] += 1\n\nif mag_stats['count'] > 0:\n    mag_stats['mean'] /= mag_stats['count']\n\nprint(f\"\\n[Check 3] rank_magnitude Stats:\")\nprint(f\"  min: {mag_stats['min']:.6f}\")\nprint(f\"  max: {mag_stats['max']:.6f}\")\nprint(f\"  mean: {mag_stats['mean']:.6f}\")\n\nif mag_stats['min'] < 0:\n    print(\"  WARNING: Negative rank_magnitude values detected!\")\nelse:\n    print(\"  ✓ All positive (softplus activation working)\")\n\n# Check 4: scale_A/scale_B norms\nnorm_issues = 0\nfor name, module in model.named_modules():\n    if type(module).__name__ == 'AnemllQATLinearV2':\n        A_norms = module.scale_A.data.norm(dim=0)  # Column norms\n        B_norms = module.scale_B.data.norm(dim=1)  # Row norms\n        if (A_norms - 1.0).abs().max() > 0.1:\n            norm_issues += 1\n        if (B_norms - 1.0).abs().max() > 0.1:\n            norm_issues += 1\n\nprint(f\"\\n[Check 4] Scale Normalization:\")\nif norm_issues > 0:\n    print(f\"  WARNING: {norm_issues} scale matrices not unit-norm\")\nelse:\n    print(\"  ✓ scale_A columns and scale_B rows are unit-norm\")\n\n# Check 5: Dtype verification\nprint(f\"\\n[Check 5] Dtype Verification:\")\nsample_module = None\nfor name, module in model.named_modules():\n    if type(module).__name__ == 'AnemllQATLinearV2':\n        sample_module = module\n        break\nif sample_module:\n    print(f\"  weight.dtype: {sample_module.weight.dtype}\")\n    print(f\"  scale_A.dtype: {sample_module.scale_A.dtype}\")\n    print(f\"  _Q.dtype: {sample_module._Q.dtype if sample_module._Q is not None else 'N/A'}\")\n    if sample_module.weight.dtype == torch.float32:\n        print(\"  ✓ FP32 (correct for Step 0)\")\n    else:\n        print(f\"  ⚠ Expected FP32 for Step 0, got {sample_module.weight.dtype}\")\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"SANITY CHECKS COMPLETE - Ready for Step 1 (MLP Training)\")\nprint(\"=\" * 60)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R4wh-UVDFCuX"
   },
   "outputs": [],
   "source": "# [CELL 13: Upload initial to Google Drive]\n# ============================================================\n# UPLOAD TO GOOGLE DRIVE\n# ============================================================\n\n!tar -czvf {RUN_NAME}.tgz -C {LOCAL_RUNS} {RUN_NAME}\n!cp {RUN_NAME}.tgz {GD_RUNS}/\nprint(f'Uploaded to {GD_RUNS}/{RUN_NAME}.tgz')"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SpN8WSKqD2hK"
   },
   "source": "# **V2 END-TO-END KD-QAT TRAINING**\n\nThis is the **primary training stage** for V2. Train all MLP scales together.\n\n**V2 Training Strategy:**\n\n| Stage | What's Trained | What's Frozen | Notes |\n|-------|---------------|---------------|-------|\n| Stage 1 | scale_A, scale_B, rank_magnitude | weight, Q, lut | Primary training |\n| Stage 2 | weight + scales | lut | Optional, recomputes Q |\n\n**Recommended approach:** Stay in Stage 1 (scales only) for most cases."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZrQA3CXHD2hK",
    "outputId": "c700ad21-feda-49c7-b895-919a613bcca6"
   },
   "outputs": [],
   "source": "# [CELL 14: Phase A - MLP-only training + AutoSnap (Terminal)]\n# ============================================================\n# STEP 1: MLP-ONLY TRAINING + AUTO-SNAP MAGS\n# ============================================================\n# This cell prints the terminal command for MLP-only training.\n# Run in terminal for better monitoring (nohup, logs, etc.)\n#\n# AutoSnap: Automatically snaps rank_magnitude to FP16 when stable,\n# then freezes mags for the rest of training.\n#\n# IMPORTANT FLAGS:\n#   --v2-checkpoint : Load V2 checkpoint (NOT --checkpoint which is for V1)\n#   --dtype fp32    : FP32 for scale/mag training (no BF16 rounding errors)\n#   --mlp-only      : Train only MLP layers, freeze attention\n#   --auto-snap-mags: Enable auto-snap of rank_magnitude when stable\n\nimport os\n\n# Checkpoint from Step 0\nINIT_CKPT = f'{SAVE_DIR}/model_state_dict.pt'\n\n# Training output dir\nMLP_RUN_NAME = f'SR-011_{QUAL}_mlp_autosnap'\nMLP_SAVE_DIR = f'{LOCAL_RUNS}/{MLP_RUN_NAME}'\n\n# Build command\ncmd = f'''python scripts/train_v2_simple.py \\\\\n    --v2-checkpoint {INIT_CKPT} \\\\\n    --cache-dir {cache_local_path} \\\\\n    --output-dir {MLP_SAVE_DIR} \\\\\n    --mlp-only \\\\\n    --auto-snap-mags \\\\\n    --auto-snap-target mlp \\\\\n    --auto-snap-threshold {AUTO_SNAP_THRESHOLD} \\\\\n    --auto-snap-patience {AUTO_SNAP_PATIENCE} \\\\\n    --auto-snap-start-step {AUTO_SNAP_START_STEP} \\\\\n    --max-steps 4000 \\\\\n    --batch-size {BATCH_SIZE} \\\\\n    --accumulation-steps {GRAD_ACCUM} \\\\\n    --lr 5e-4 \\\\\n    --warmup-steps 100 \\\\\n    --save-steps 200 \\\\\n    --eval-steps 100 \\\\\n    --temperature {DISTILL_TEMP} \\\\\n    --dtype fp32'''\n\nprint(\"=\" * 70)\nprint(\"STEP 1: MLP-ONLY TRAINING + AUTO-SNAP\")\nprint(\"=\" * 70)\nprint()\nprint(\"Copy this command to terminal:\")\nprint()\nprint(cmd)\nprint()\nprint(\"=\" * 70)\nprint(\"Expected behavior:\")\nprint(\"  - Trains MLP scales only (attention frozen)\")\nprint(\"  - AutoSnap monitors rank_magnitude stability at save checkpoints\")\nprint(\"  - When stable for 2 consecutive saves: snap mags to FP16 + freeze\")\nprint(\"  - After freeze: only scale_A, scale_B trained (fewer params)\")\nprint()\nprint(\"NOTE: Using --dtype fp32 to avoid BF16 rounding errors in mags.\")\nprint(\"      AutoSnap will snap to FP16 when stable, then freeze.\")\nprint(\"=\" * 70)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I0uILDU-OXLv"
   },
   "outputs": [],
   "source": "# [CELL 15: GC cleanup]\nimport gc\ngc.collect()\ntorch.cuda.empty_cache()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5UYzccZuHoQo",
    "outputId": "238cad01-8205-46fb-b81f-7932eb150c8d"
   },
   "outputs": [],
   "source": "# [CELL 16: E2E weight tuning (optional)]\n# ============================================================\n# V2 OPTIONAL: E2E GENTLE WEIGHT + SCALE TUNING (Stage 2)\n# ============================================================\n# Only run this if scale-only training isn't sufficient\n# Requires clearing _Q to recompute on-the-fly\n\nENABLE_E2E_WEIGHT_TUNING = False  # Set to True to enable\n\nif ENABLE_E2E_WEIGHT_TUNING:\n    from qat_lora import unfreeze_model_for_training_v2\n    \n    # Clear cached weights and frozen Q\n    unfreeze_model_for_training_v2(model)\n    \n    # Unfreeze weights and clear Q\n    for name, module in model.named_modules():\n        if isinstance(module, AnemllQATLinearV2):\n            module.weight.requires_grad = True\n            module._Q = None  # Will compute Q on-the-fly\n    \n    print('V2 E2E weight training (Stage 2)...')\n    print('WARNING: Q will be recomputed on-the-fly for each forward pass')\n    \n    e2e_weights_result = train_e2e(\n        model=model,\n        cache_dir=cache_local_path,\n        device=DEVICE,\n        max_steps=1000,\n        batch_size=64 if torch.cuda.is_available() else 32,\n        lr=1e-5,  # Very small LR for weights\n        use_cosine_schedule=True,\n        warmup_steps=100,\n        min_lr_ratio=0.1,\n        temperature=DISTILL_TEMP,\n        train_weights=True,\n        train_scales=True,  # Also train scales\n        hard_top1_weight=0.2,\n        hard_full_weight=0.0,\n        logging_steps=50,\n        eval_steps=500,\n        verbose=True,\n    )\n    \n    # Re-freeze Q after training\n    print('Re-freezing Q...')\n    freeze_Q_all(model, verbose=False)\nelse:\n    print('E2E weight tuning disabled. Using scale-only training.')\n    print('Set ENABLE_E2E_WEIGHT_TUNING = True above to enable.')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jYjQRat_D2hK",
    "outputId": "f33f0d7c-365d-4e65-933b-23dbf095a552"
   },
   "outputs": [],
   "source": "# [CELL 17: E2E MLP refinement]\n# ============================================================\n# V2 E2E: ADDITIONAL SCALE REFINEMENT (MLP ONLY)\n# ============================================================\n# Continue scale training for MLP layers\n\ne2e_mlp_scales_result = train_e2e(\n    model=model,\n    cache_dir=cache_local_path,\n    device=DEVICE,\n    max_steps=1000,\n    batch_size=64 if torch.cuda.is_available() else 32,\n    lr=1e-4,  # Lower LR for refinement\n    use_cosine_schedule=True,\n    warmup_steps=100,\n    min_lr_ratio=0.1,\n    temperature=DISTILL_TEMP,\n    train_weights=False,\n    train_scales=True,\n    hard_top1_weight=0.0,\n    hard_full_weight=0.0,\n    logging_steps=50,\n    eval_steps=500,\n    verbose=True,\n    train_mlp_only=True,\n)"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vBe_UGa1HtPl"
   },
   "source": [
    "# **V2 ATTENTION SCALE TRAINING**\n",
    "\n",
    "Train attention layer scales (Q, K, V, O projections) while keeping MLP frozen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 547
    },
    "id": "O9BaTY8MFrVA",
    "outputId": "193aabb5-c88d-43f5-c302-1ad38deb38c9"
   },
   "outputs": [],
   "source": "# [CELL 18: Phase B - Attention training (Python API)]\n# ============================================================\n# STEP 2: ATTENTION SCALE TRAINING (MLP FROZEN)\n# ============================================================\n# NOTE: The CLI doesn't have --attn-only flag.\n# Use Python API (train_e2e) with explicit attention-only config.\n#\n# Alternative CLI approach (trains all, MLP mags frozen):\n#   python scripts/train_v2_simple.py \\\n#       --v2-checkpoint {MLP_BEST_CKPT} \\\n#       --cache-dir {cache_local_path} \\\n#       --output-dir {ATTN_SAVE_DIR} \\\n#       --freeze-mags-mlp \\\n#       --max-steps 2000 --lr 1e-4 --dtype fp32\n\nfrom qat_lora import train_e2e, evaluate_kd_loss\n\n# Load best MLP checkpoint\nMLP_BEST_CKPT = f'{MLP_SAVE_DIR}/best_state_dict.pt'\n\nprint(\"=\" * 70)\nprint(\"STEP 2: ATTENTION SCALE TRAINING\")\nprint(\"=\" * 70)\n\n# Check if MLP checkpoint exists\nimport os\nif os.path.exists(MLP_BEST_CKPT):\n    print(f\"Loading MLP checkpoint: {MLP_BEST_CKPT}\")\n    model.load_state_dict(torch.load(MLP_BEST_CKPT, map_location=DEVICE))\n    print(\"Loaded successfully.\")\nelse:\n    print(f\"WARNING: MLP checkpoint not found at {MLP_BEST_CKPT}\")\n    print(\"Make sure to run Step 1 (MLP training) first!\")\n\n# Freeze MLP layers, enable attention layers only\nprint(\"\\nFreezing MLP layers, enabling attention only...\")\nfor name, module in model.named_modules():\n    if type(module).__name__ == 'AnemllQATLinearV2':\n        is_mlp = any(p in name for p in ['gate_proj', 'up_proj', 'down_proj'])\n        is_attn = any(p in name for p in ['q_proj', 'k_proj', 'v_proj', 'o_proj'])\n        \n        if is_mlp:\n            # Freeze ALL MLP params\n            module.scale_A.requires_grad = False\n            module.scale_B.requires_grad = False\n            module.rank_magnitude.requires_grad = False\n        elif is_attn:\n            # Train attention scales\n            module.scale_A.requires_grad = True\n            module.scale_B.requires_grad = True\n            module.rank_magnitude.requires_grad = True\n\n# Count trainable params\nattn_trainable = sum(p.numel() for n, p in model.named_parameters() \n                     if p.requires_grad and any(x in n for x in ['q_proj', 'k_proj', 'v_proj', 'o_proj']))\nmlp_trainable = sum(p.numel() for n, p in model.named_parameters()\n                    if p.requires_grad and any(x in n for x in ['gate_proj', 'up_proj', 'down_proj']))\nprint(f\"Trainable attention params: {attn_trainable:,}\")\nprint(f\"Trainable MLP params: {mlp_trainable:,} (should be 0)\")\n\n# Eval before attention training\nloss_before = evaluate_kd_loss(model, cache_local_path, DEVICE, num_samples=40, temperature=DISTILL_TEMP)\nprint(f\"\\nKD Loss before attention training: {loss_before:.4f}\")\n\n# Train attention scales\nATTN_RUN_NAME = f'SR-011_{QUAL}_attn'\nATTN_SAVE_DIR = f'{LOCAL_RUNS}/{ATTN_RUN_NAME}'\nos.makedirs(ATTN_SAVE_DIR, exist_ok=True)\n\nprint(\"\\nTraining attention scales...\")\nattn_result = train_e2e(\n    model=model,\n    cache_dir=cache_local_path,\n    device=DEVICE,\n    max_steps=2000,\n    batch_size=BATCH_SIZE,\n    lr=1e-4,\n    use_cosine_schedule=True,\n    warmup_steps=100,\n    min_lr_ratio=0.1,\n    temperature=DISTILL_TEMP,\n    train_weights=False,\n    train_scales=True,\n    hard_top1_weight=0.0,\n    hard_full_weight=0.0,\n    logging_steps=50,\n    eval_steps=100,\n    verbose=True,\n)\n\n# Save attention checkpoint\ntorch.save(model.state_dict(), f'{ATTN_SAVE_DIR}/best_state_dict.pt')\nprint(f\"\\nSaved attention checkpoint to {ATTN_SAVE_DIR}/best_state_dict.pt\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **V2 JOINT MLP + ATTENTION FINE-TUNING**\n",
    "\n",
    "After separate MLP and attention training, fine-tune both together for final polish.\n",
    "\n",
    "**Training Strategy:**\n",
    "- Stage 1: MLP scales only\n",
    "- Stage 2: Attention scales only (MLP frozen)\n",
    "- **Stage 3: Joint MLP + Attention** (this cell) ← co-adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# [CELL 19: Joint MLP + Attention fine-tuning]\n# ============================================================\n# V2 E2E: JOINT MLP + ATTENTION FINE-TUNING\n# ============================================================\n# Train both MLP and attention scales together for final polish\n# This helps the scales co-adapt after separate training\n\nfrom qat_lora import unfreeze_model_for_training_v2\n\nunfreeze_model_for_training_v2(model)\n\n# Enable ALL scales (both MLP and attention)\nfor name, module in model.named_modules():\n    if isinstance(module, AnemllQATLinearV2):\n        if hasattr(module, 'scale_A') and module.scale_A is not None:\n            module.scale_A.requires_grad = True\n            module.scale_B.requires_grad = True\n            module.rank_magnitude.requires_grad = True\n        module.weight.requires_grad = False  # Keep weights frozen\n\ntrainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\nprint(f'Trainable params (joint MLP+Attn): {trainable:,}')\n\n# Joint training with lower LR for fine-tuning\ne2e_joint_result = train_e2e(\n    model=model,\n    cache_dir=cache_local_path,\n    device=DEVICE,\n    max_steps=1000,  # Shorter since already trained\n    batch_size=32,\n    lr=5e-5,         # Lower LR for fine-tuning\n    use_cosine_schedule=True,\n    warmup_steps=50,\n    min_lr_ratio=0.1,\n    temperature=DISTILL_TEMP,\n    train_weights=False,\n    train_scales=True,\n    hard_top1_weight=0.0,\n    hard_full_weight=0.0,\n    logging_steps=20,\n    eval_steps=100,\n    verbose=True,\n    train_mlp_only=False,\n)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wh3twk6GD2hK",
    "outputId": "6ffdc08f-2681-42a3-cb58-ab951b7e76b9"
   },
   "outputs": [],
   "source": "# [CELL 20: Save final checkpoint + upload]\n# ============================================================\n# SAVE FINAL V2 CHECKPOINT\n# ============================================================\n\nfrom qat_lora import unfreeze_model_for_training_v2\n\nunfreeze_model_for_training_v2(model)\n\nE2E_RUN_NAME = f'SR-011_{QUAL}_e2e'\nE2E_SAVE_DIR = f'{LOCAL_RUNS}/{E2E_RUN_NAME}'\n\n# Save with config\nconfig = {\n    'model_id': MODEL_ID,\n    'version': 'v2',\n    'lut_size': LUT_SIZE,\n    'scale_rank': SCALE_RANK,\n    'attn_lut_size': ATTN_LUT_SIZE,\n    'attn_scale_rank': ATTN_SCALE_RANK,\n    'e2e_scales_result': e2e_scales_result,\n}\n\nsave_checkpoint(model, E2E_SAVE_DIR, config=config)\n\n# Upload to Google Drive\n!tar -czvf {E2E_RUN_NAME}.tgz -C {LOCAL_RUNS} {E2E_RUN_NAME}\n!cp {E2E_RUN_NAME}.tgz {GD_RUNS}/\nprint(f'\\nUploaded to {GD_RUNS}/{E2E_RUN_NAME}.tgz')"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fqafgf8KfRgs"
   },
   "source": [
    "# **INFERENCE OPTIMIZATION**\n",
    "\n",
    "Before running inference, freeze all layers to precompute quantized weights.\n",
    "This avoids recomputing `LUT[indices] * (scale_A @ scale_B)` on every forward pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lWZ2KP18fRgs",
    "outputId": "4d13eca7-c7ae-45b5-fe1b-4eb1ee7bc208"
   },
   "outputs": [],
   "source": "# [CELL 21: Freeze model for inference]\n# ============================================================\n# V2 FREEZE MODEL FOR FAST INFERENCE\n# ============================================================\n# Precompute full W_eff = Q * scales for all layers\n# This caches the effective weight to avoid rank-by-rank computation per token\n\nfrom qat_lora import freeze_model_for_inference_v2, unfreeze_model_for_training_v2\n\nprint('Freezing V2 model for inference...')\nnum_frozen = freeze_model_for_inference_v2(model, verbose=False)\nprint(f'Frozen {num_frozen} V2 layers')\nprint('Cached W_eff = Q * scales for fast inference')\n\n# To resume training later:\n# unfreeze_model_for_training_v2(model)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bIT_brkMCfrW"
   },
   "outputs": [],
   "source": "# [CELL 21: (empty)]\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ugmqo-MHFCuX",
    "outputId": "f2a176aa-f9fc-480e-decf-64c7edf911e0"
   },
   "outputs": [],
   "source": "# [CELL 22: Test inference (greedy)]\nimport torch\n\n# ============================================================\n# TEST INFERENCE\n# ============================================================\n\ndef run_inference(model, tokenizer, prompt, max_new_tokens=128):\n    messages = [\n        {'role': 'system', 'content': 'You are a helpful assistant.'},\n        {'role': 'user', 'content': prompt}\n    ]\n    text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n    inputs = tokenizer(text, return_tensors='pt').to(DEVICE)\n\n    with torch.no_grad():\n        output = model.generate(**inputs, max_new_tokens=max_new_tokens, do_sample=False)\n\n    return tokenizer.decode(output[0][inputs['input_ids'].shape[1]:], skip_special_tokens=True)\n\n# List of prompts to test\nprompts = [\n    'What is the capital of France?',\n    'What is Apple Neural Engine?',\n    'Explain quantum mechanics',\n    'What is speed of light'\n]\n\nmodel.eval() # Set model to evaluation mode once\n\nfor prompt in prompts:\n    response = run_inference(model, tokenizer, prompt,max_new_tokens=1024)\n    print(f'Prompt: {prompt}')\n    print(f'Response: {response}')\n    print('-' * 50) # Separator for readability"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UjaRRvbYDzhw",
    "outputId": "17d3301e-ce1a-4aa3-d257-49429e479975"
   },
   "outputs": [],
   "source": "# [CELL 23: Test inference (sampling)]\n# ============================================================\n# TEST INFERENCE\n# ============================================================\n\ndef run_inference(model, tokenizer, prompt, max_new_tokens=512):\n    messages = [\n        {'role': 'user', 'content': prompt}\n    ]\n    text = tokenizer.apply_chat_template(\n        messages,\n        tokenize=False,\n        add_generation_prompt=True,\n        enable_thinking=True\n    )\n    inputs = tokenizer(text, return_tensors='pt').to(DEVICE)\n\n    with torch.no_grad():\n        output = model.generate(\n            **inputs,\n            max_new_tokens=max_new_tokens,\n            do_sample=True,\n            temperature=0.6,\n            top_p=0.9,\n            repetition_penalty=1.1,\n        )\n\n    return tokenizer.decode(output[0][inputs['input_ids'].shape[1]:], skip_special_tokens=False)\n\n# List of prompts to test\nprompts = [\n    'What is the capital of France?',\n    'What is Apple Neural Engine?',\n    'Explain quantum mechanics',\n    'What is speed of light'\n]\n\nmodel.eval()\n\nfor prompt in prompts:\n    response = run_inference(model, tokenizer, prompt, max_new_tokens=512)\n    print(f'Prompt: {prompt}')\n    print(f'Response: {response}')\n    print('-' * 50)"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qKGYuTbyFCuX"
   },
   "source": "## Next Steps\n\nAfter E2E training, you can:\n\n1. **Additional refinement** - Continue training with lower LR\n2. **LoRA recovery** - Add LoRA adapters to recover quality\n3. **Export for ANE** - Use snap_for_export() to bake normalization"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rYhCJltqD2hL"
   },
   "source": [
    "# **V2 EXPORT FOR ANEMLL CONVERTER**\n",
    "\n",
    "Export V2 model for external tools.\n",
    "\n",
    "**V2 Export includes:**\n",
    "- `_Q`: Frozen LUT values [out, in]\n",
    "- `_indices`: Quantization indices [out, in]\n",
    "- `scale_A`, `scale_B`, `rank_magnitude`: Scale parameters\n",
    "- `lut`: LUT values\n",
    "\n",
    "**For inference optimization:**\n",
    "- Call `snap_for_export()` to bake normalization into parameters\n",
    "- This eliminates runtime norm computation in the exported model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "alJrTNGED2hL"
   },
   "outputs": [],
   "source": "# [CELL 24: Export for ANEMLL converter]\n# ============================================================\n# V2 EXPORT FOR ANEMLL CONVERTER\n# ============================================================\n\nfrom qat_lora import unfreeze_model_for_training_v2\n\n# First unfreeze to clear cached weights\nunfreeze_model_for_training_v2(model)\n\n# Export V2 model representation\nprint('Exporting V2 quantized model representation...')\n\nexport_dict = {}\nfor name, module in model.named_modules():\n    if isinstance(module, AnemllQATLinearV2):\n        layer_export = {\n            'indices': module._indices.cpu() if module._indices is not None else None,\n            'Q': module._Q.cpu() if module._Q is not None else None,\n            'scale_A': module.scale_A.data.cpu(),\n            'scale_B': module.scale_B.data.cpu(),\n            'rank_magnitude': module.rank_magnitude.data.cpu(),\n            'lut': module.lut.cpu(),\n            'bias': module.bias.data.cpu() if module.bias is not None else None,\n            'in_features': module.in_features,\n            'out_features': module.out_features,\n            'scale_rank': module.scale_rank,\n            'lut_bits': module.lut_bits,\n        }\n        export_dict[name] = layer_export\n\nprint(f'Exported {len(export_dict)} V2 layers')\n\n# Save export for ANEMLL converter\nEXPORT_DIR = f'{LOCAL_RUNS}/{E2E_RUN_NAME}_export'\nos.makedirs(EXPORT_DIR, exist_ok=True)\ntorch.save(export_dict, f'{EXPORT_DIR}/v2_quantized_model.pt')\nprint(f'\\nSaved V2 export to {EXPORT_DIR}/v2_quantized_model.pt')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ny_MXsYgD2hL"
   },
   "outputs": [],
   "source": "# [CELL 25: Snap for export + test]\n# ============================================================\n# V2 SNAP FOR EXPORT AND TEST\n# ============================================================\n# Bake normalization into parameters for CoreML-friendly export\n\nprint('Snapping V2 model for export (baking normalization)...')\n\nfor name, module in model.named_modules():\n    if isinstance(module, AnemllQATLinearV2):\n        module.snap_for_export()\n\nprint('V2 model snapped for export.')\nprint('Normalization baked into scale_A (no runtime norm computation)')\n\n# Test inference with snapped model\nmodel.eval()\nprint('\\nTesting V2 inference with snapped weights...')\nresponse = run_inference(model, tokenizer, 'What is 2+2?', max_new_tokens=256)\nprint(f'Prompt: What is 2+2?')\nprint(f'Response: {response}')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZUlMBHHEcQ0R"
   },
   "outputs": [],
   "source": "# [CELL 26: Backup checkpoint]\ntorch.save(model.state_dict(), '/tmp/backup_mlp_e2e_0.4613.pt')  # Local, fast"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tGydB-nzDEiM"
   },
   "source": [
    "torch.save(model.state_dict(), '/tmp/backup_mlp_e2e_w_0.3824.pt')  # Local, fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LzDrNrYEDKTE"
   },
   "outputs": [],
   "source": "# [CELL 27: Backup checkpoint]\ntorch.save(model.state_dict(), '/tmp/backup_mlp_e4e_4_4.pt')  # Local, fast"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6YdQUk9q3DbH",
    "outputId": "3292185a-6f75-4354-e3b8-8d991757445e"
   },
   "outputs": [],
   "source": "# [CELL 28: Load backup]\nmodel.load_state_dict(torch.load('/tmp/backup_initial.pt', map_location=DEVICE))"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AVGwV43BxCem"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hi2MkZnJ_pXq",
    "outputId": "84aefbbf-9c3a-4fda-e70f-4f2133d35063"
   },
   "outputs": [],
   "source": "# [CELL 29: Load backup]\nmodel.load_state_dict(torch.load('/tmp/backup_mlp_e2e_w_0.3824.pt', map_location=DEVICE))"
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "history_visible": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "02947099e48c465691d6d41dcd1e877b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "02f92b038c3942369d6bbda0b85561bd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "045937442f11451fae75cf71818f2771": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "06e9bae2da334bfe87877b18848fc0e0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a0dc69628c774dcab4fdc057d871c71e",
      "placeholder": "​",
      "style": "IPY_MODEL_c7550f00e5f5491e848cc033cb52d695",
      "value": " 11.4M/11.4M [00:00&lt;00:00, 39.8MB/s]"
     }
    },
    "09079f4c40b24d47b16b3a9d39eac18f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f10f6efb961f426dba0e85b4f4fc54ba",
      "placeholder": "​",
      "style": "IPY_MODEL_f029416c83fe4e1daf94c137e9b70038",
      "value": "tokenizer_config.json: "
     }
    },
    "1222d75ab8a34dd7b4bdb4e57403b74a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7f0f985b8ba44c80bd30840946cec59f",
      "placeholder": "​",
      "style": "IPY_MODEL_78f024244cfa4226bb3abbdba4611ac8",
      "value": "tokenizer.json: 100%"
     }
    },
    "13407d3e50f44934ba4cc8d125319a97": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1643098c16724226b2f135666c853021": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1a5a12de6a824d8784f0b5c8b39df05c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "1be8597c80774992b05b2b2a3db7e3ca": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1e61be30fd06489997bc1073cdf4b63f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2e1db963227241848378d59b903e9eac": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c9ed78eb0a274a4eaa5e9115ae344042",
      "placeholder": "​",
      "style": "IPY_MODEL_7d71667b5bf8458e846b371058fe0fca",
      "value": " 239/239 [00:00&lt;00:00, 28.2kB/s]"
     }
    },
    "31c50cde54ce455484d8959587b6761e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "32ddfc19754f4f3ba3fd05ceb443200b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "395b60bd9d62499ebdf4db8f98d6d060": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3f33d3f10a104364a08b5a972d868404": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e34e197865624c319e5c3efd61cec5f1",
       "IPY_MODEL_e1f9a8ad18a0404f91bd633266a987c1",
       "IPY_MODEL_7dafcef8629943bba8b552eb65cf4319"
      ],
      "layout": "IPY_MODEL_cd45240c029a4d89bf7856dfe692f487"
     }
    },
    "412c3035861a4d9fa384f8b8285415b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_434330f256ed46f384bf6fa47b423b80",
      "placeholder": "​",
      "style": "IPY_MODEL_5da05f1cfe8a4913b38c49789f367319",
      "value": " 1.50G/1.50G [00:01&lt;00:00, 766MB/s]"
     }
    },
    "434330f256ed46f384bf6fa47b423b80": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "44606bd8389a4dd7acec4c4e8b27236f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "458a362e07ef46fdab537612157215fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b8c783ede2f445dd8538a743155eb07d",
      "placeholder": "​",
      "style": "IPY_MODEL_d4c27e7c0c394e75b28c3a2da7233afd",
      "value": " 1.67M/? [00:00&lt;00:00, 66.1MB/s]"
     }
    },
    "58c6d1daf9dc4736ad8888fdd2e13051": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5da05f1cfe8a4913b38c49789f367319": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "60d59a18029944c48ec1fa1e667d6c8e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "61b4ff17161a4472983d9ae7c4038f4c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1be8597c80774992b05b2b2a3db7e3ca",
      "max": 726,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_58c6d1daf9dc4736ad8888fdd2e13051",
      "value": 726
     }
    },
    "6401e8dd76cf43c9bca85eafa9584072": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "650dce7e0dfe41c5a7aad9ab6fcb4b7f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "683cb5329ed749d593c4592d21095b03": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_44606bd8389a4dd7acec4c4e8b27236f",
      "max": 239,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_beadf9955191423587bc789d96b539b5",
      "value": 239
     }
    },
    "69988406b6fd406ca9a657ca1164b716": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6d34db691b8549708447dc4528918bd7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6f4a70c1d8b443019ce0db5845dbeabe",
       "IPY_MODEL_fbd65fe0ad714e719255caa92dc42988",
       "IPY_MODEL_458a362e07ef46fdab537612157215fc"
      ],
      "layout": "IPY_MODEL_6401e8dd76cf43c9bca85eafa9584072"
     }
    },
    "6f4a70c1d8b443019ce0db5845dbeabe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d28e621974114f798fa7f6f7147c18c1",
      "placeholder": "​",
      "style": "IPY_MODEL_c4f53cf052434846851f7bb9681f06f3",
      "value": "merges.txt: "
     }
    },
    "723cb77b570b43c780f7816ce9aa4f81": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "756e3d0cd08d444f974dbb4a0d03aeee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "78f024244cfa4226bb3abbdba4611ac8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "79dba7f9976e4d56ba95542576ad784e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cccaf0d3bbbc4d1fab88478bfde18570",
      "placeholder": "​",
      "style": "IPY_MODEL_9cfe70d1c90d4570a537ba3ba9af8758",
      "value": "config.json: 100%"
     }
    },
    "7c23ec2e04e04555bcc86795b8b98a6a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1222d75ab8a34dd7b4bdb4e57403b74a",
       "IPY_MODEL_dcfa4ead89b34a038cbbff240f802027",
       "IPY_MODEL_06e9bae2da334bfe87877b18848fc0e0"
      ],
      "layout": "IPY_MODEL_b8c1d61e8f7f40d0a2dfb0aa44d9e4b2"
     }
    },
    "7d71667b5bf8458e846b371058fe0fca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7dafcef8629943bba8b552eb65cf4319": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_32ddfc19754f4f3ba3fd05ceb443200b",
      "placeholder": "​",
      "style": "IPY_MODEL_9d78c3b445ae4b4b9255f381dbbbf297",
      "value": " 2.78M/? [00:00&lt;00:00, 32.9MB/s]"
     }
    },
    "7f0f985b8ba44c80bd30840946cec59f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "86ca268b812540e98715edec5bcfc312": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "97e02cb7cc054c76a2a236208bd39288": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_31c50cde54ce455484d8959587b6761e",
      "placeholder": "​",
      "style": "IPY_MODEL_756e3d0cd08d444f974dbb4a0d03aeee",
      "value": " 726/726 [00:00&lt;00:00, 100kB/s]"
     }
    },
    "99f53192c01e48d28edeaa60bcc93316": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_86ca268b812540e98715edec5bcfc312",
      "placeholder": "​",
      "style": "IPY_MODEL_650dce7e0dfe41c5a7aad9ab6fcb4b7f",
      "value": "model.safetensors: 100%"
     }
    },
    "9ceaade381e94c258a3c0ffe6b8993ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_09079f4c40b24d47b16b3a9d39eac18f",
       "IPY_MODEL_c1ca5e81b3884530acba75733f2b2ef3",
       "IPY_MODEL_b66e47d1dccd4aaa9053968667cfafe3"
      ],
      "layout": "IPY_MODEL_02947099e48c465691d6d41dcd1e877b"
     }
    },
    "9cfe70d1c90d4570a537ba3ba9af8758": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9d78c3b445ae4b4b9255f381dbbbf297": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9e9b3bbd2ed04af2983090df7fdfa860": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_79dba7f9976e4d56ba95542576ad784e",
       "IPY_MODEL_61b4ff17161a4472983d9ae7c4038f4c",
       "IPY_MODEL_97e02cb7cc054c76a2a236208bd39288"
      ],
      "layout": "IPY_MODEL_1e61be30fd06489997bc1073cdf4b63f"
     }
    },
    "a0dc69628c774dcab4fdc057d871c71e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a5c2c0a43dff4b78bd2dea20244a743b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ab4ff2b64d29443ba180766a384840b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ca7eb173d158416cbf10a5c6f485e9a1",
       "IPY_MODEL_683cb5329ed749d593c4592d21095b03",
       "IPY_MODEL_2e1db963227241848378d59b903e9eac"
      ],
      "layout": "IPY_MODEL_fe3be4ef1c22496091ec419cba32966f"
     }
    },
    "aebedea1c0aa48c996f59ceff3b7f59d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_99f53192c01e48d28edeaa60bcc93316",
       "IPY_MODEL_f8707033b6bc4ff39b211d9e79429d8f",
       "IPY_MODEL_412c3035861a4d9fa384f8b8285415b7"
      ],
      "layout": "IPY_MODEL_60d59a18029944c48ec1fa1e667d6c8e"
     }
    },
    "b66e47d1dccd4aaa9053968667cfafe3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_eab5f44c082e486cbfef722597968c27",
      "placeholder": "​",
      "style": "IPY_MODEL_c181cb34a1c44cff9f701fcb264f4639",
      "value": " 9.73k/? [00:00&lt;00:00, 1.05MB/s]"
     }
    },
    "b6a1ab44a70a43d3a6c3fe8be56ff1cb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b89e33aa337d495b9c5f0afa5c4e531f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b8c1d61e8f7f40d0a2dfb0aa44d9e4b2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b8c783ede2f445dd8538a743155eb07d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "beadf9955191423587bc789d96b539b5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c181cb34a1c44cff9f701fcb264f4639": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c1ca5e81b3884530acba75733f2b2ef3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_723cb77b570b43c780f7816ce9aa4f81",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_02f92b038c3942369d6bbda0b85561bd",
      "value": 1
     }
    },
    "c4f53cf052434846851f7bb9681f06f3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c7550f00e5f5491e848cc033cb52d695": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c9ed78eb0a274a4eaa5e9115ae344042": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ca7eb173d158416cbf10a5c6f485e9a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d4c07e275393496f8dee96dd3168a40f",
      "placeholder": "​",
      "style": "IPY_MODEL_b6a1ab44a70a43d3a6c3fe8be56ff1cb",
      "value": "generation_config.json: 100%"
     }
    },
    "cccaf0d3bbbc4d1fab88478bfde18570": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cd45240c029a4d89bf7856dfe692f487": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cdde30488ec24b2f8ff1ac50adf677c1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "d28e621974114f798fa7f6f7147c18c1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d4c07e275393496f8dee96dd3168a40f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d4c27e7c0c394e75b28c3a2da7233afd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "dcfa4ead89b34a038cbbff240f802027": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_13407d3e50f44934ba4cc8d125319a97",
      "max": 11422654,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_395b60bd9d62499ebdf4db8f98d6d060",
      "value": 11422654
     }
    },
    "e1f9a8ad18a0404f91bd633266a987c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cdde30488ec24b2f8ff1ac50adf677c1",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e4a9b6abc3bb4d72b33910184b8dee53",
      "value": 1
     }
    },
    "e34e197865624c319e5c3efd61cec5f1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1643098c16724226b2f135666c853021",
      "placeholder": "​",
      "style": "IPY_MODEL_b89e33aa337d495b9c5f0afa5c4e531f",
      "value": "vocab.json: "
     }
    },
    "e4a9b6abc3bb4d72b33910184b8dee53": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "eab5f44c082e486cbfef722597968c27": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f029416c83fe4e1daf94c137e9b70038": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f10f6efb961f426dba0e85b4f4fc54ba": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f8707033b6bc4ff39b211d9e79429d8f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_69988406b6fd406ca9a657ca1164b716",
      "max": 1503300328,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_045937442f11451fae75cf71818f2771",
      "value": 1503300328
     }
    },
    "fbd65fe0ad714e719255caa92dc42988": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1a5a12de6a824d8784f0b5c8b39df05c",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a5c2c0a43dff4b78bd2dea20244a743b",
      "value": 1
     }
    },
    "fe3be4ef1c22496091ec419cba32966f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}