{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Perplexity Measurement\n\n**Version:** 1.0 | **Build:** 2026-01-10\n\nMeasure perplexity of QAT checkpoints and compare with baseline Qwen model.\n\n**Perplexity** = exp(cross-entropy loss) on next-token prediction.\n- Lower is better\n- WikiText-2 baselines: GPT-2 ~22, good LLMs ~5-10\n\n## Setup (Colab)\n\nRun the setup cells below to clone the repository and mount Google Drive."
  },
  {
   "cell_type": "code",
   "source": "#@title Clone repository (run once)\nimport os\n\nREPO_URL = \"https://github.com/anemll/qwen3_apple_style_2bit_qat_lora.git\"  #@param {type:\"string\"}\nREPO_DIR = \"qwen3_apple_style_2bit_qat_lora\"\n\nif not os.path.exists(REPO_DIR):\n    !git clone {REPO_URL}\n    print(f\"✓ Cloned to {REPO_DIR}\")\nelse:\n    print(f\"✓ Repository already exists at {REPO_DIR}\")\n\n# Change to repo directory\nos.chdir(REPO_DIR)\nprint(f\"Working directory: {os.getcwd()}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "#@title Mount Google Drive (for checkpoints)\nMOUNT_DRIVE = True  #@param {type:\"boolean\"}\n\nif MOUNT_DRIVE:\n    from google.colab import drive\n    drive.mount('/content/drive')\n    print(\"✓ Google Drive mounted at /content/drive\")\n    print(\"  Use paths like: /content/drive/MyDrive/qat_checkpoints/model.pt\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "#@title Config\n# Checkpoint path (local or Google Drive)\n# Examples:\n#   \"runs/SR-011/checkpoint.pt\"  (local)\n#   \"/content/drive/MyDrive/qat_checkpoints/model.pt\"  (Google Drive)\nCHECKPOINT = \"runs/SR-011_q4_a4_r32_mlp_autosnap/v2_q4a4_r32_fp32_20260110_133950.pt\"  #@param {type:\"string\"}\nMODEL_NAME = \"Qwen/Qwen3-0.6B\"  #@param {type:\"string\"}\nLORA_R = 0  #@param {type:\"integer\"}\n\n# Evaluation settings\nMAX_LENGTH = 1024  #@param {type:\"integer\"}\nSTRIDE = 512  #@param {type:\"integer\"}\nVERBOSE = True  #@param {type:\"boolean\"}"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Install dependencies (run once)\n",
    "!pip install -q datasets transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Device setup\n",
    "import os\n",
    "import torch\n",
    "\n",
    "# Auto-detect device\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = 'cuda'\n",
    "    DTYPE = torch.bfloat16\n",
    "elif torch.backends.mps.is_available():\n",
    "    DEVICE = 'mps'\n",
    "    DTYPE = torch.float32\n",
    "else:\n",
    "    try:\n",
    "        import torch_xla.core.xla_model as xm\n",
    "        DEVICE = 'tpu'\n",
    "        DTYPE = torch.bfloat16\n",
    "    except ImportError:\n",
    "        DEVICE = 'cpu'\n",
    "        DTYPE = torch.float32\n",
    "\n",
    "print(f\"Device: {DEVICE}\")\n",
    "print(f\"Dtype: {DTYPE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Measure Baseline Model Perplexity\n",
    "\n",
    "Measure the original Qwen model (no QAT) to establish a baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Measure baseline perplexity\n",
    "!python scripts/measure_perplexity.py --baseline \\\n",
    "    --model {MODEL_NAME} \\\n",
    "    --max-length {MAX_LENGTH} \\\n",
    "    --stride {STRIDE} \\\n",
    "    --device {DEVICE} \\\n",
    "    {'--verbose' if VERBOSE else ''}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Measure QAT Checkpoint Perplexity\n",
    "\n",
    "Measure the quantized model checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Measure checkpoint perplexity\n",
    "lora_flag = f\"--lora-r {LORA_R}\" if LORA_R > 0 else \"\"\n",
    "verbose_flag = \"--verbose\" if VERBOSE else \"\"\n",
    "\n",
    "!python scripts/measure_perplexity.py \"{CHECKPOINT}\" \\\n",
    "    --model {MODEL_NAME} \\\n",
    "    --max-length {MAX_LENGTH} \\\n",
    "    --stride {STRIDE} \\\n",
    "    --device {DEVICE} \\\n",
    "    {lora_flag} \\\n",
    "    {verbose_flag}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Compare Multiple Checkpoints (Optional)\n",
    "\n",
    "Compare perplexity across training steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title List available checkpoints\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "checkpoint_dir = Path(CHECKPOINT).parent\n",
    "if checkpoint_dir.exists():\n",
    "    checkpoints = sorted(checkpoint_dir.glob(\"*.pt\"))\n",
    "    print(f\"Found {len(checkpoints)} checkpoints in {checkpoint_dir}:\")\n",
    "    for ckpt in checkpoints[-10:]:  # Show last 10\n",
    "        size_mb = ckpt.stat().st_size / 1024 / 1024\n",
    "        print(f\"  {ckpt.name:<50} {size_mb:.1f} MB\")\n",
    "else:\n",
    "    print(f\"Directory not found: {checkpoint_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Batch measure multiple checkpoints\n",
    "CHECKPOINTS_TO_MEASURE = [\n",
    "    # Add checkpoint paths here\n",
    "    # \"runs/SR-011/checkpoint_step1000.pt\",\n",
    "    # \"runs/SR-011/checkpoint_step2000.pt\",\n",
    "]\n",
    "\n",
    "results = []\n",
    "for ckpt in CHECKPOINTS_TO_MEASURE:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Measuring: {ckpt}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    !python scripts/measure_perplexity.py \"{ckpt}\" \\\n",
    "        --model {MODEL_NAME} \\\n",
    "        --max-length {MAX_LENGTH} \\\n",
    "        --stride {STRIDE} \\\n",
    "        --device {DEVICE}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Using Cache Data (Alternative)\n",
    "\n",
    "If WikiText-2 download fails, use existing KD cache."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Measure with KD cache\n",
    "CACHE_DIR = \"caches/alpaca_chat_think_both_L128_K128\"  #@param {type:\"string\"}\n",
    "NUM_SAMPLES = 100  #@param {type:\"integer\"}\n",
    "\n",
    "!python scripts/measure_perplexity.py \"{CHECKPOINT}\" \\\n",
    "    --cache-dir \"{CACHE_DIR}\" \\\n",
    "    --num-samples {NUM_SAMPLES} \\\n",
    "    --model {MODEL_NAME} \\\n",
    "    --max-length {MAX_LENGTH} \\\n",
    "    --stride {STRIDE} \\\n",
    "    --device {DEVICE}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}