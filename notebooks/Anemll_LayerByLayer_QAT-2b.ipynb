{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqWTWF5EFCuV"
      },
      "source": [
        "# Anemll-Style Layer-by-Layer QAT\n",
        "\n",
        "This notebook implements layer-by-layer QAT training using `AnemllQATLinear` with:\n",
        "- Groupwise LUT quantization\n",
        "- Low-rank scale factors (A @ B)\n",
        "- KD cache for distillation\n",
        "- **Hard label loss** for improved convergence\n",
        "\n",
        "## Pipeline:\n",
        "1. Load model and replace linears with AnemllQATLinear\n",
        "2. Layer-by-layer scale optimization (weights frozen)\n",
        "3. Layer-by-layer weight training (with hard label loss)\n",
        "4. End-to-end refinement\n",
        "5. (Optional) LoRA recovery\n",
        "\n",
        "## Distillation Options:\n",
        "- `temperature`: KL divergence temperature (default: 2.0)\n",
        "- `hard_top1_weight`: Hard label top-1 loss weight (recommended: 0.1 for weights, 0.0 for scales)\n",
        "- `hard_full_weight`: Hard label full vocab loss weight (optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Kfh54i9XFCuW"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# GOOGLE DRIVE PATHS (STANDARD)\n",
        "# ============================================================\n",
        "\n",
        "# Checkpoints/runs go here\n",
        "GD_RUNS = '/content/drive/MyDrive/qwen3_runs'\n",
        "\n",
        "# KD caches go here\n",
        "GD_CACHES = '/content/drive/MyDrive/qwen3_caches'\n",
        "\n",
        "# Local directories (on Colab VM)\n",
        "LOCAL_RUNS = 'runs'\n",
        "LOCAL_CACHES = 'caches'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Tw1k9-anFCuW",
        "outputId": "b1a45a15-3a86-42fa-dad5-8296004b4d79",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GITUB"
      ],
      "metadata": {
        "id": "7X9uxbCPPykd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "HtdvB50DFCuW",
        "outputId": "70a98c8c-0b2e-4035-f686-a621cbea5f18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'qwen3_apple_style_2bit_qat_lora'...\n",
            "remote: Enumerating objects: 437, done.\u001b[K\n",
            "remote: Counting objects: 100% (127/127), done.\u001b[K\n",
            "remote: Compressing objects: 100% (97/97), done.\u001b[K\n",
            "remote: Total 437 (delta 89), reused 58 (delta 30), pack-reused 310 (from 1)\u001b[K\n",
            "Receiving objects: 100% (437/437), 573.78 KiB | 6.52 MiB/s, done.\n",
            "Resolving deltas: 100% (280/280), done.\n",
            "/content/qwen3_apple_style_2bit_qat_lora/qwen3_apple_style_2bit_qat_lora/qwen3_apple_style_2bit_qat_lora\n",
            "Already up to date.\n",
            "HEAD is now at 998f33c Enhance AnemllQATLinear and training functions for improved memory management and learning rate scheduling\n"
          ]
        }
      ],
      "source": [
        "# Clone repo if needed\n",
        "!git clone https://github.com/anemll/qwen3_apple_style_2bit_qat_lora.git || (cd qwen3_apple_style_2bit_qat_lora && git pull)\n",
        "%cd qwen3_apple_style_2bit_qat_lora\n",
        "# to allow updates\n",
        "!git fetch\n",
        "!git pull\n",
        "!git reset --hard HEAD\n",
        "import sys\n",
        "[sys.modules.pop(k) for k in list(sys.modules) if k.startswith('qat_lora')]\n",
        "\n",
        "from qat_lora import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1dJ5vGK9FCuW"
      },
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "!pip install -q transformers accelerate safetensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "hgqQOvUpFCuW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d221f49-31a0-4ff1-bacc-b7f9c42ad317"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting alpaca_chat_think_both_L128_K128_R1024.tgz from Google Drive...\n",
            "total 17157672\n",
            "drwx------ 2 root root      4096 Dec 26 02:45 .\n",
            "drwxr-xr-x 3 root root      4096 Dec 27 00:09 ..\n",
            "-rw------- 1 root root       423 Dec 26 02:45 meta.json\n",
            "-rw------- 1 root root 899550149 Dec 26 02:46 shard_00000.pt\n",
            "-rw------- 1 root root 899550149 Dec 26 02:43 shard_00001.pt\n",
            "-rw------- 1 root root 899550149 Dec 26 02:44 shard_00002.pt\n",
            "-rw------- 1 root root 899550149 Dec 26 02:44 shard_00003.pt\n",
            "-rw------- 1 root root 899550149 Dec 26 02:44 shard_00004.pt\n",
            "-rw------- 1 root root 899550149 Dec 26 02:43 shard_00005.pt\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# LOAD KD CACHE FROM GOOGLE DRIVE\n",
        "# ============================================================\n",
        "\n",
        "#CACHE_NAME = 'alpaca_chat_think_both_L128_K32_R256'\n",
        "#CACHE_NAME = 'alpaca_chat_think_both_L128_K64_R512'\n",
        "CACHE_NAME = 'alpaca_chat_think_both_L128_K128_R1024'\n",
        "\n",
        "\n",
        "CACHE_TGZ = f'{CACHE_NAME}.tgz'\n",
        "\n",
        "!mkdir -p {LOCAL_CACHES}\n",
        "\n",
        "# Check if cache exists locally\n",
        "import os\n",
        "cache_local_path = f'{LOCAL_CACHES}/{CACHE_NAME}'\n",
        "if not os.path.exists(cache_local_path):\n",
        "    print(f'Extracting {CACHE_TGZ} from Google Drive...')\n",
        "    !tar -xzf {GD_CACHES}/{CACHE_TGZ} -C {LOCAL_CACHES}/\n",
        "else:\n",
        "    print(f'Cache already exists at {cache_local_path}')\n",
        "\n",
        "!ls -la {cache_local_path}/ | head -10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "EJ239_eUFCuW",
        "outputId": "797d2a4f-623f-47c2-efca-2700048c2388",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quality: q2_a4\n",
            "Device: cuda, dtype: torch.bfloat16\n",
            "Quant config: lut=4, group=16, rank=32\n",
            "Distillation: temp=2.0, hard_top1=0.2, hard_full=5e-05\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# CONFIGURATION\n",
        "# ============================================================\n",
        "\n",
        "import torch\n",
        "\n",
        "# Model\n",
        "MODEL_ID = 'Qwen/Qwen3-0.6B'\n",
        "\n",
        "# Quantization config (4-bit with groupwise LUT)\n",
        "LUT_BITS = 2\n",
        "LUT_SIZE = 2**LUT_BITS\n",
        "GROUP_SIZE = 16      # Group size for scales\n",
        "SCALE_RANK = 32       # Low-rank for A @ B scales\n",
        "\n",
        "# Attention quantization (same params)\n",
        "ATTN_LUT_BITS = 4\n",
        "ATTN_LUT_SIZE = 2**ATTN_LUT_BITS\n",
        "ATTN_GROUP_SIZE = 16\n",
        "ATTN_SCALE_RANK = 8\n",
        "\n",
        "# Training\n",
        "BATCH_SIZE = 4\n",
        "GRAD_ACCUM = 4\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    BATCH_SIZE=32\n",
        "    GRAD_ACCUM=1\n",
        "\n",
        "LR = 2e-5\n",
        "EPOCHS_PER_LAYER = 1\n",
        "\n",
        "# KD / Distillation params\n",
        "DISTILL_TEMP = 2.0\n",
        "HARD_TOP1_WEIGHT = 0.2    # Hard label top-1 loss (helps convergence)\n",
        "HARD_FULL_WEIGHT = 0.00005    # Hard label full vocab loss (optional)\n",
        "\n",
        "# Device\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "DTYPE = torch.bfloat16\n",
        "\n",
        "\n",
        "QUAL = f'q{LUT_BITS}_a{ATTN_LUT_BITS}'\n",
        "\n",
        "print(f'Quality: {QUAL}')\n",
        "\n",
        "print(f'Device: {DEVICE}, dtype: {DTYPE}')\n",
        "print(f'Quant config: lut={LUT_SIZE}, group={GROUP_SIZE}, rank={SCALE_RANK}')\n",
        "print(f'Distillation: temp={DISTILL_TEMP}, hard_top1={HARD_TOP1_WEIGHT}, hard_full={HARD_FULL_WEIGHT}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# Extracting LOCAL CACHE\n",
        "# ============================================================\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Verify drive is mounted and cache exists\n",
        "if not os.path.exists('/content/drive/MyDrive'):\n",
        "    print('Google Drive not mounted! Mounting now...')\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "if not os.path.exists(cache_local_path):\n",
        "    print(f'Cache not found at {cache_local_path}')\n",
        "    print(f'Extracting from Google Drive...')\n",
        "    os.makedirs(LOCAL_CACHES, exist_ok=True)\n",
        "    !tar -xzf {GD_CACHES}/{CACHE_TGZ} -C {LOCAL_CACHES}/\n",
        "\n",
        "# Verify cache exists now\n",
        "assert os.path.exists(cache_local_path), f'Cache still not found at {cache_local_path}'\n",
        "cache_files = list(Path(cache_local_path).glob('*.pt'))\n",
        "print(f'Cache ready: {len(cache_files)} files in {cache_local_path}')"
      ],
      "metadata": {
        "id": "r-V8ZhsWGl1d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e5b0211-da16-4b4f-9f84-b8d646560c58"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cache ready: 20 files in caches/alpaca_chat_think_both_L128_K128_R1024\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "5e5kQrkxFCuX",
        "outputId": "d6e3437a-8446-463d-aa00-4b00f7db13e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Qwen/Qwen3-0.6B...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded. Parameters: 596,049,920\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# LOAD MODEL\n",
        "# ============================================================\n",
        "\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "print(f'Loading {MODEL_ID}...')\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, trust_remote_code=True)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_ID,\n",
        "    torch_dtype=DTYPE,\n",
        "    trust_remote_code=True,\n",
        ")\n",
        "model.to(DEVICE)\n",
        "model.eval()\n",
        "print(f'Loaded. Parameters: {sum(p.numel() for p in model.parameters()):,}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "n29f0NexFCuX",
        "outputId": "d4f6ab93-6d9e-4fdf-bfdf-fd98eab30de4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking model structure...\n",
            "  Found Linear: model.layers.0.self_attn.q_proj\n",
            "  Found Linear: model.layers.0.self_attn.k_proj\n",
            "  Found Linear: model.layers.0.self_attn.v_proj\n",
            "  Found Linear: model.layers.0.self_attn.o_proj\n",
            "  Found Linear: model.layers.0.mlp.gate_proj\n",
            "Total Linear modules: 197\n",
            "\n",
            "Replacing linear layers...\n",
            "  [replaced] model.layers.0.self_attn.q_proj\n",
            "  [replaced] model.layers.0.self_attn.k_proj\n",
            "  [replaced] model.layers.0.self_attn.v_proj\n",
            "  [replaced] model.layers.0.self_attn.o_proj\n",
            "  [replaced] model.layers.0.mlp.gate_proj\n",
            "  [replaced] model.layers.0.mlp.up_proj\n",
            "  [replaced] model.layers.0.mlp.down_proj\n",
            "  [replaced] model.layers.1.self_attn.q_proj\n",
            "  [replaced] model.layers.1.self_attn.k_proj\n",
            "  [replaced] model.layers.1.self_attn.v_proj\n",
            "  [replaced] model.layers.1.self_attn.o_proj\n",
            "  [replaced] model.layers.1.mlp.gate_proj\n",
            "  [replaced] model.layers.1.mlp.up_proj\n",
            "  [replaced] model.layers.1.mlp.down_proj\n",
            "  [replaced] model.layers.2.self_attn.q_proj\n",
            "  [replaced] model.layers.2.self_attn.k_proj\n",
            "  [replaced] model.layers.2.self_attn.v_proj\n",
            "  [replaced] model.layers.2.self_attn.o_proj\n",
            "  [replaced] model.layers.2.mlp.gate_proj\n",
            "  [replaced] model.layers.2.mlp.up_proj\n",
            "  [replaced] model.layers.2.mlp.down_proj\n",
            "  [replaced] model.layers.3.self_attn.q_proj\n",
            "  [replaced] model.layers.3.self_attn.k_proj\n",
            "  [replaced] model.layers.3.self_attn.v_proj\n",
            "  [replaced] model.layers.3.self_attn.o_proj\n",
            "  [replaced] model.layers.3.mlp.gate_proj\n",
            "  [replaced] model.layers.3.mlp.up_proj\n",
            "  [replaced] model.layers.3.mlp.down_proj\n",
            "  [replaced] model.layers.4.self_attn.q_proj\n",
            "  [replaced] model.layers.4.self_attn.k_proj\n",
            "  [replaced] model.layers.4.self_attn.v_proj\n",
            "  [replaced] model.layers.4.self_attn.o_proj\n",
            "  [replaced] model.layers.4.mlp.gate_proj\n",
            "  [replaced] model.layers.4.mlp.up_proj\n",
            "  [replaced] model.layers.4.mlp.down_proj\n",
            "  [replaced] model.layers.5.self_attn.q_proj\n",
            "  [replaced] model.layers.5.self_attn.k_proj\n",
            "  [replaced] model.layers.5.self_attn.v_proj\n",
            "  [replaced] model.layers.5.self_attn.o_proj\n",
            "  [replaced] model.layers.5.mlp.gate_proj\n",
            "  [replaced] model.layers.5.mlp.up_proj\n",
            "  [replaced] model.layers.5.mlp.down_proj\n",
            "  [replaced] model.layers.6.self_attn.q_proj\n",
            "  [replaced] model.layers.6.self_attn.k_proj\n",
            "  [replaced] model.layers.6.self_attn.v_proj\n",
            "  [replaced] model.layers.6.self_attn.o_proj\n",
            "  [replaced] model.layers.6.mlp.gate_proj\n",
            "  [replaced] model.layers.6.mlp.up_proj\n",
            "  [replaced] model.layers.6.mlp.down_proj\n",
            "  [replaced] model.layers.7.self_attn.q_proj\n",
            "  [replaced] model.layers.7.self_attn.k_proj\n",
            "  [replaced] model.layers.7.self_attn.v_proj\n",
            "  [replaced] model.layers.7.self_attn.o_proj\n",
            "  [replaced] model.layers.7.mlp.gate_proj\n",
            "  [replaced] model.layers.7.mlp.up_proj\n",
            "  [replaced] model.layers.7.mlp.down_proj\n",
            "  [replaced] model.layers.8.self_attn.q_proj\n",
            "  [replaced] model.layers.8.self_attn.k_proj\n",
            "  [replaced] model.layers.8.self_attn.v_proj\n",
            "  [replaced] model.layers.8.self_attn.o_proj\n",
            "  [replaced] model.layers.8.mlp.gate_proj\n",
            "  [replaced] model.layers.8.mlp.up_proj\n",
            "  [replaced] model.layers.8.mlp.down_proj\n",
            "  [replaced] model.layers.9.self_attn.q_proj\n",
            "  [replaced] model.layers.9.self_attn.k_proj\n",
            "  [replaced] model.layers.9.self_attn.v_proj\n",
            "  [replaced] model.layers.9.self_attn.o_proj\n",
            "  [replaced] model.layers.9.mlp.gate_proj\n",
            "  [replaced] model.layers.9.mlp.up_proj\n",
            "  [replaced] model.layers.9.mlp.down_proj\n",
            "  [replaced] model.layers.10.self_attn.q_proj\n",
            "  [replaced] model.layers.10.self_attn.k_proj\n",
            "  [replaced] model.layers.10.self_attn.v_proj\n",
            "  [replaced] model.layers.10.self_attn.o_proj\n",
            "  [replaced] model.layers.10.mlp.gate_proj\n",
            "  [replaced] model.layers.10.mlp.up_proj\n",
            "  [replaced] model.layers.10.mlp.down_proj\n",
            "  [replaced] model.layers.11.self_attn.q_proj\n",
            "  [replaced] model.layers.11.self_attn.k_proj\n",
            "  [replaced] model.layers.11.self_attn.v_proj\n",
            "  [replaced] model.layers.11.self_attn.o_proj\n",
            "  [replaced] model.layers.11.mlp.gate_proj\n",
            "  [replaced] model.layers.11.mlp.up_proj\n",
            "  [replaced] model.layers.11.mlp.down_proj\n",
            "  [replaced] model.layers.12.self_attn.q_proj\n",
            "  [replaced] model.layers.12.self_attn.k_proj\n",
            "  [replaced] model.layers.12.self_attn.v_proj\n",
            "  [replaced] model.layers.12.self_attn.o_proj\n",
            "  [replaced] model.layers.12.mlp.gate_proj\n",
            "  [replaced] model.layers.12.mlp.up_proj\n",
            "  [replaced] model.layers.12.mlp.down_proj\n",
            "  [replaced] model.layers.13.self_attn.q_proj\n",
            "  [replaced] model.layers.13.self_attn.k_proj\n",
            "  [replaced] model.layers.13.self_attn.v_proj\n",
            "  [replaced] model.layers.13.self_attn.o_proj\n",
            "  [replaced] model.layers.13.mlp.gate_proj\n",
            "  [replaced] model.layers.13.mlp.up_proj\n",
            "  [replaced] model.layers.13.mlp.down_proj\n",
            "  [replaced] model.layers.14.self_attn.q_proj\n",
            "  [replaced] model.layers.14.self_attn.k_proj\n",
            "  [replaced] model.layers.14.self_attn.v_proj\n",
            "  [replaced] model.layers.14.self_attn.o_proj\n",
            "  [replaced] model.layers.14.mlp.gate_proj\n",
            "  [replaced] model.layers.14.mlp.up_proj\n",
            "  [replaced] model.layers.14.mlp.down_proj\n",
            "  [replaced] model.layers.15.self_attn.q_proj\n",
            "  [replaced] model.layers.15.self_attn.k_proj\n",
            "  [replaced] model.layers.15.self_attn.v_proj\n",
            "  [replaced] model.layers.15.self_attn.o_proj\n",
            "  [replaced] model.layers.15.mlp.gate_proj\n",
            "  [replaced] model.layers.15.mlp.up_proj\n",
            "  [replaced] model.layers.15.mlp.down_proj\n",
            "  [replaced] model.layers.16.self_attn.q_proj\n",
            "  [replaced] model.layers.16.self_attn.k_proj\n",
            "  [replaced] model.layers.16.self_attn.v_proj\n",
            "  [replaced] model.layers.16.self_attn.o_proj\n",
            "  [replaced] model.layers.16.mlp.gate_proj\n",
            "  [replaced] model.layers.16.mlp.up_proj\n",
            "  [replaced] model.layers.16.mlp.down_proj\n",
            "  [replaced] model.layers.17.self_attn.q_proj\n",
            "  [replaced] model.layers.17.self_attn.k_proj\n",
            "  [replaced] model.layers.17.self_attn.v_proj\n",
            "  [replaced] model.layers.17.self_attn.o_proj\n",
            "  [replaced] model.layers.17.mlp.gate_proj\n",
            "  [replaced] model.layers.17.mlp.up_proj\n",
            "  [replaced] model.layers.17.mlp.down_proj\n",
            "  [replaced] model.layers.18.self_attn.q_proj\n",
            "  [replaced] model.layers.18.self_attn.k_proj\n",
            "  [replaced] model.layers.18.self_attn.v_proj\n",
            "  [replaced] model.layers.18.self_attn.o_proj\n",
            "  [replaced] model.layers.18.mlp.gate_proj\n",
            "  [replaced] model.layers.18.mlp.up_proj\n",
            "  [replaced] model.layers.18.mlp.down_proj\n",
            "  [replaced] model.layers.19.self_attn.q_proj\n",
            "  [replaced] model.layers.19.self_attn.k_proj\n",
            "  [replaced] model.layers.19.self_attn.v_proj\n",
            "  [replaced] model.layers.19.self_attn.o_proj\n",
            "  [replaced] model.layers.19.mlp.gate_proj\n",
            "  [replaced] model.layers.19.mlp.up_proj\n",
            "  [replaced] model.layers.19.mlp.down_proj\n",
            "  [replaced] model.layers.20.self_attn.q_proj\n",
            "  [replaced] model.layers.20.self_attn.k_proj\n",
            "  [replaced] model.layers.20.self_attn.v_proj\n",
            "  [replaced] model.layers.20.self_attn.o_proj\n",
            "  [replaced] model.layers.20.mlp.gate_proj\n",
            "  [replaced] model.layers.20.mlp.up_proj\n",
            "  [replaced] model.layers.20.mlp.down_proj\n",
            "  [replaced] model.layers.21.self_attn.q_proj\n",
            "  [replaced] model.layers.21.self_attn.k_proj\n",
            "  [replaced] model.layers.21.self_attn.v_proj\n",
            "  [replaced] model.layers.21.self_attn.o_proj\n",
            "  [replaced] model.layers.21.mlp.gate_proj\n",
            "  [replaced] model.layers.21.mlp.up_proj\n",
            "  [replaced] model.layers.21.mlp.down_proj\n",
            "  [replaced] model.layers.22.self_attn.q_proj\n",
            "  [replaced] model.layers.22.self_attn.k_proj\n",
            "  [replaced] model.layers.22.self_attn.v_proj\n",
            "  [replaced] model.layers.22.self_attn.o_proj\n",
            "  [replaced] model.layers.22.mlp.gate_proj\n",
            "  [replaced] model.layers.22.mlp.up_proj\n",
            "  [replaced] model.layers.22.mlp.down_proj\n",
            "  [replaced] model.layers.23.self_attn.q_proj\n",
            "  [replaced] model.layers.23.self_attn.k_proj\n",
            "  [replaced] model.layers.23.self_attn.v_proj\n",
            "  [replaced] model.layers.23.self_attn.o_proj\n",
            "  [replaced] model.layers.23.mlp.gate_proj\n",
            "  [replaced] model.layers.23.mlp.up_proj\n",
            "  [replaced] model.layers.23.mlp.down_proj\n",
            "  [replaced] model.layers.24.self_attn.q_proj\n",
            "  [replaced] model.layers.24.self_attn.k_proj\n",
            "  [replaced] model.layers.24.self_attn.v_proj\n",
            "  [replaced] model.layers.24.self_attn.o_proj\n",
            "  [replaced] model.layers.24.mlp.gate_proj\n",
            "  [replaced] model.layers.24.mlp.up_proj\n",
            "  [replaced] model.layers.24.mlp.down_proj\n",
            "  [replaced] model.layers.25.self_attn.q_proj\n",
            "  [replaced] model.layers.25.self_attn.k_proj\n",
            "  [replaced] model.layers.25.self_attn.v_proj\n",
            "  [replaced] model.layers.25.self_attn.o_proj\n",
            "  [replaced] model.layers.25.mlp.gate_proj\n",
            "  [replaced] model.layers.25.mlp.up_proj\n",
            "  [replaced] model.layers.25.mlp.down_proj\n",
            "  [replaced] model.layers.26.self_attn.q_proj\n",
            "  [replaced] model.layers.26.self_attn.k_proj\n",
            "  [replaced] model.layers.26.self_attn.v_proj\n",
            "  [replaced] model.layers.26.self_attn.o_proj\n",
            "  [replaced] model.layers.26.mlp.gate_proj\n",
            "  [replaced] model.layers.26.mlp.up_proj\n",
            "  [replaced] model.layers.26.mlp.down_proj\n",
            "  [replaced] model.layers.27.self_attn.q_proj\n",
            "  [replaced] model.layers.27.self_attn.k_proj\n",
            "  [replaced] model.layers.27.self_attn.v_proj\n",
            "  [replaced] model.layers.27.self_attn.o_proj\n",
            "  [replaced] model.layers.27.mlp.gate_proj\n",
            "  [replaced] model.layers.27.mlp.up_proj\n",
            "  [replaced] model.layers.27.mlp.down_proj\n",
            "\n",
            "Replaced 196 layers\n",
            "\n",
            "Verification: 0 AnemllQATLinear modules in model\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# REPLACE LINEARS WITH AnemllQATLinear\n",
        "# ============================================================\n",
        "\n",
        "import sys\n",
        "sys.path.insert(0, '.')\n",
        "\n",
        "# Force reimport to get latest code\n",
        "import importlib\n",
        "import qat_lora\n",
        "importlib.reload(qat_lora)\n",
        "import qat_lora.ane_qat_linear as ane_module\n",
        "importlib.reload(ane_module)\n",
        "import qat_lora.layer_qat as layer_module\n",
        "importlib.reload(layer_module)\n",
        "\n",
        "from qat_lora import AnemllQuantConfig, replace_linear_with_anemll\n",
        "\n",
        "# Debug: Check what modules exist in the model\n",
        "print(\"Checking model structure...\")\n",
        "import torch.nn as nn\n",
        "linear_count = 0\n",
        "for name, m in model.named_modules():\n",
        "    if isinstance(m, nn.Linear):\n",
        "        linear_count += 1\n",
        "        if linear_count <= 5:\n",
        "            print(f\"  Found Linear: {name}\")\n",
        "print(f\"Total Linear modules: {linear_count}\")\n",
        "\n",
        "# Create configs\n",
        "mlp_config = AnemllQuantConfig(\n",
        "    lut_size=LUT_SIZE,\n",
        "    group_size=GROUP_SIZE,\n",
        "    scale_rank=SCALE_RANK,\n",
        "    learnable_lut=False,\n",
        ")\n",
        "\n",
        "attn_config = AnemllQuantConfig(\n",
        "    lut_size=ATTN_LUT_SIZE,\n",
        "    group_size=ATTN_GROUP_SIZE,\n",
        "    scale_rank=ATTN_SCALE_RANK,\n",
        "    learnable_lut=False,\n",
        ")\n",
        "\n",
        "print('\\nReplacing linear layers...')\n",
        "count = replace_linear_with_anemll(\n",
        "    model,\n",
        "    mlp_config=mlp_config,\n",
        "    attn_config=attn_config,\n",
        "    quantize_attn=True,\n",
        "    quantize_lm_head=False,\n",
        ")\n",
        "\n",
        "# Verify replacement worked\n",
        "from qat_lora import AnemllQATLinear\n",
        "qat_count = sum(1 for _, m in model.named_modules() if isinstance(m, AnemllQATLinear))\n",
        "print(f\"\\nVerification: {qat_count} AnemllQATLinear modules in model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "D_gOyY1qFCuX",
        "outputId": "95240408-edf3-47bc-aa64-c29d387e06e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer QAT utilities imported from qat_lora\n",
            "\n",
            "Verifying gradient flow...\n",
            "ERROR: No AnemllQATLinear modules found! Replacement failed.\n",
            "\n",
            "Computing initial KD loss...\n",
            "Initial KD Loss: 0.0000\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# IMPORT LAYER-BY-LAYER QAT UTILITIES & VERIFY GRADIENTS\n",
        "# ============================================================\n",
        "\n",
        "from qat_lora import (\n",
        "    evaluate_kd_loss,\n",
        "    train_all_layers,\n",
        "    AnemllQATLinear,\n",
        ")\n",
        "\n",
        "print('Layer QAT utilities imported from qat_lora')\n",
        "\n",
        "# Verify gradient flow works\n",
        "print('\\nVerifying gradient flow...')\n",
        "layer0 = model.model.layers[0]\n",
        "test_module = None\n",
        "for name, m in layer0.named_modules():\n",
        "    if isinstance(m, AnemllQATLinear):\n",
        "        test_module = m\n",
        "        break\n",
        "\n",
        "if test_module is None:\n",
        "    print(\"ERROR: No AnemllQATLinear modules found! Replacement failed.\")\n",
        "else:\n",
        "    # Test gradient flow\n",
        "    test_module.weight.requires_grad = True\n",
        "    x = torch.randn(1, 10, test_module.in_features, device=DEVICE, dtype=DTYPE)\n",
        "    y = test_module(x)\n",
        "    loss = y.sum()\n",
        "    try:\n",
        "        loss.backward()\n",
        "        if test_module.weight.grad is not None:\n",
        "            print(f\"  Gradient OK: weight.grad.shape = {test_module.weight.grad.shape}\")\n",
        "            test_module.weight.grad = None  # Clear for actual training\n",
        "        else:\n",
        "            print(\"  ERROR: weight.grad is None after backward!\")\n",
        "    except Exception as e:\n",
        "        print(f\"  ERROR during backward: {e}\")\n",
        "\n",
        "# Compute initial KD loss\n",
        "print('\\nComputing initial KD loss...')\n",
        "initial_loss = evaluate_kd_loss(model, cache_local_path, DEVICE, num_samples=40, temperature=DISTILL_TEMP)\n",
        "print(f'Initial KD Loss: {initial_loss:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **SCALE OPTIMIZATION** (Weights Frozen)\n",
        "\n",
        "After layer-by-layer QAT on weights, optimize the per-weight scales (A @ B) to further reduce quantization error.\n",
        "\n",
        "- Weights are **frozen**\n",
        "- Only `scale_A` and `scale_B` are trained\n",
        "- Much fewer parameters → can use higher learning rate"
      ],
      "metadata": {
        "id": "9B4uAJDNfRgs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# LAYER-BY-LAYER SCALE OPTIMIZATION\n",
        "# ============================================================\n",
        "# Freeze weights, only train scale_A and scale_B tensors\n",
        "# Higher LR since fewer parameters\n",
        "# Note: Hard label loss not needed for scale optimization\n",
        "\n",
        "SCALE_LR = 1e-3  # Higher LR for scales (fewer params)\n",
        "SCALE_EPOCHS = 2  # More epochs since scales have less capacity\n",
        "\n",
        "\n",
        "print('Starting scale-only layer-by-layer optimization...')\n",
        "print(f'LR: {SCALE_LR}, Epochs per layer: {SCALE_EPOCHS}')\n",
        "\n",
        "# Get loss before scale optimization\n",
        "pre_scale_loss = evaluate_kd_loss(model, cache_local_path, DEVICE, num_samples=40)\n",
        "print(f'KD Loss before scale optimization: {pre_scale_loss:.4f}')\n",
        "\n",
        "# Train scales layer-by-layer (no hard label needed for scales)\n",
        "scale_losses = train_all_layers(\n",
        "    model=model,\n",
        "    cache_dir=cache_local_path,\n",
        "    device=DEVICE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    lr=SCALE_LR,\n",
        "    epochs_per_layer=SCALE_EPOCHS,\n",
        "    grad_accum=GRAD_ACCUM,\n",
        "    temperature=DISTILL_TEMP,\n",
        "    train_weights=False,  # Freeze weights\n",
        "    train_scales=True,    # Train scales only\n",
        "    local_weight=0.5,\n",
        "    global_weight=0.5,\n",
        "    hard_top1_weight=0.0,  # Not needed for scale optimization\n",
        "    hard_full_weight=0.0,\n",
        "    verbose=True,\n",
        "    steps_per_layer=100,\n",
        ")\n",
        "\n",
        "# Evaluate after scale optimization\n",
        "post_scale_loss = evaluate_kd_loss(model, cache_local_path, DEVICE, num_samples=40)\n",
        "print(f'\\n=== Scale Optimization Results ===')\n",
        "print(f'Before: {pre_scale_loss:.4f}')\n",
        "print(f'After:  {post_scale_loss:.4f}')\n",
        "print(f'Improvement: {pre_scale_loss - post_scale_loss:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQ1kq2a9fRgs",
        "outputId": "af689de1-18ea-4b98-fc28-b1dc70d86399"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting scale-only layer-by-layer optimization...\n",
            "LR: 0.001, Epochs per layer: 2\n",
            "KD Loss before scale optimization: 1.0885\n",
            "Training 28 layers (mode=scales only)...\n",
            "Cache: caches/alpaca_chat_think_both_L128_K32_R256\n",
            "Batch size: 64, Grad accum: 1\n",
            "LR: 0.001, Steps per layer: 100\n",
            "\n",
            "[Initial Global KD Loss]: 1.0885\n",
            "\n",
            "=== Layer 0 === (131,072 trainable params, mode=scales only)\n",
            "  [Global KD Loss BEFORE]: 1.0345\n",
            "  step 10: local=0.0439 global=0.8089 (3.9s)\n",
            "  step 20: local=0.0710 global=0.7905 (7.2s)\n",
            "  step 30: local=0.0724 global=0.7238 (10.4s)\n",
            "  step 40: local=0.0671 global=0.6626 (13.7s)\n",
            "  step 50: local=0.0641 global=0.6703 (17.0s)\n",
            "  step 60: local=0.0619 global=0.6684 (20.3s)\n",
            "  step 70: local=0.0622 global=0.6874 (23.5s)\n",
            "  step 80: local=0.0609 global=0.6786 (26.8s)\n",
            "  step 90: local=0.0638 global=0.6774 (30.1s)\n",
            "  step 100: local=0.0646 global=0.6453 (33.3s)\n",
            "  ---\n",
            "  [Local Loss]:   0.0283 -> 0.0646 (Δ=-0.0364)\n",
            "  [Global Loss]:  1.0063 -> 0.6453 (Δ=0.3609)\n",
            "  [Eval KD]:      1.0345 -> 0.6752 (Δ=0.3593, 34.7%)\n",
            "  [Time]:         37.5s\n",
            "\n",
            "[Progress: 1/28] Elapsed: 0:37, ETA: 16:53\n",
            "\n",
            "=== Layer 1 === (131,072 trainable params, mode=scales only)\n",
            "  [Global KD Loss BEFORE]: 0.6752\n",
            "  step 10: local=0.0380 global=0.6859 (3.2s)\n",
            "  step 20: local=0.0483 global=0.6290 (6.4s)\n",
            "  step 30: local=0.0527 global=0.5934 (9.6s)\n",
            "  step 40: local=0.0531 global=0.6164 (12.8s)\n",
            "  step 50: local=0.0551 global=0.6172 (16.1s)\n",
            "  step 60: local=0.0539 global=0.6212 (19.3s)\n",
            "  step 70: local=0.0559 global=0.5707 (22.5s)\n",
            "  step 80: local=0.0558 global=0.5681 (25.7s)\n",
            "  step 90: local=0.0577 global=0.5852 (29.0s)\n",
            "  step 100: local=0.0577 global=0.6061 (32.2s)\n",
            "  ---\n",
            "  [Local Loss]:   0.0361 -> 0.0577 (Δ=-0.0216)\n",
            "  [Global Loss]:  0.6449 -> 0.6061 (Δ=0.0387)\n",
            "  [Eval KD]:      0.6752 -> 0.6098 (Δ=0.0654, 9.7%)\n",
            "  [Time]:         36.4s\n",
            "\n",
            "[Progress: 2/28] Elapsed: 1:13, ETA: 16:00\n",
            "\n",
            "=== Layer 2 === (131,072 trainable params, mode=scales only)\n",
            "  [Global KD Loss BEFORE]: 0.6098\n",
            "  step 10: local=0.0383 global=0.5008 (3.2s)\n",
            "  step 20: local=0.0424 global=0.4773 (6.4s)\n",
            "  step 30: local=0.0415 global=0.4672 (9.5s)\n",
            "  step 40: local=0.0526 global=0.4773 (12.6s)\n",
            "  step 50: local=0.0420 global=0.4630 (15.8s)\n",
            "  step 60: local=0.0430 global=0.4878 (19.0s)\n",
            "  step 70: local=0.0533 global=0.4442 (22.1s)\n",
            "  step 80: local=0.0463 global=0.4616 (25.3s)\n",
            "  step 90: local=0.0436 global=0.4422 (28.5s)\n",
            "  step 100: local=0.0544 global=0.4350 (31.6s)\n",
            "  ---\n",
            "  [Local Loss]:   0.0448 -> 0.0544 (Δ=-0.0096)\n",
            "  [Global Loss]:  0.5574 -> 0.4350 (Δ=0.1223)\n",
            "  [Eval KD]:      0.6098 -> 0.4489 (Δ=0.1609, 26.4%)\n",
            "  [Time]:         35.8s\n",
            "\n",
            "[Progress: 3/28] Elapsed: 1:49, ETA: 15:14\n",
            "\n",
            "=== Layer 3 === (131,072 trainable params, mode=scales only)\n",
            "  [Global KD Loss BEFORE]: 0.4489\n",
            "  step 10: local=0.0394 global=0.4675 (3.1s)\n",
            "  step 20: local=0.0424 global=0.4523 (6.2s)\n",
            "  step 30: local=0.0445 global=0.4119 (9.3s)\n",
            "  step 40: local=0.0440 global=0.4193 (12.4s)\n",
            "  step 50: local=0.0440 global=0.4768 (15.5s)\n",
            "  step 60: local=0.0435 global=0.4366 (18.6s)\n",
            "  step 70: local=0.0434 global=0.4620 (21.7s)\n",
            "  step 80: local=0.0439 global=0.4263 (24.8s)\n",
            "  step 90: local=0.0436 global=0.4285 (27.9s)\n",
            "  step 100: local=0.0445 global=0.4316 (31.0s)\n",
            "  ---\n",
            "  [Local Loss]:   0.0367 -> 0.0445 (Δ=-0.0079)\n",
            "  [Global Loss]:  0.4586 -> 0.4316 (Δ=0.0269)\n",
            "  [Eval KD]:      0.4489 -> 0.4297 (Δ=0.0192, 4.3%)\n",
            "  [Time]:         35.3s\n",
            "\n",
            "[Progress: 4/28] Elapsed: 2:25, ETA: 14:30\n",
            "\n",
            "=== Layer 4 === (131,072 trainable params, mode=scales only)\n",
            "  [Global KD Loss BEFORE]: 0.4297\n",
            "  step 10: local=0.0364 global=0.4295 (3.1s)\n",
            "  step 20: local=0.0417 global=0.4231 (6.1s)\n",
            "  step 30: local=0.0409 global=0.4144 (9.1s)\n",
            "  step 40: local=0.0424 global=0.4126 (12.1s)\n",
            "  step 50: local=0.0432 global=0.4402 (15.2s)\n",
            "  step 60: local=0.0413 global=0.4160 (18.2s)\n",
            "  step 70: local=0.0433 global=0.4308 (21.3s)\n",
            "  step 80: local=0.0445 global=0.4893 (24.3s)\n",
            "  step 90: local=0.0420 global=0.4068 (27.4s)\n",
            "  step 100: local=0.0436 global=0.4269 (30.4s)\n",
            "  ---\n",
            "  [Local Loss]:   0.0356 -> 0.0436 (Δ=-0.0081)\n",
            "  [Global Loss]:  0.4524 -> 0.4269 (Δ=0.0255)\n",
            "  [Eval KD]:      0.4297 -> 0.4256 (Δ=0.0041, 1.0%)\n",
            "  [Time]:         34.6s\n",
            "\n",
            "[Progress: 5/28] Elapsed: 2:59, ETA: 13:46\n",
            "\n",
            "=== Layer 5 === (131,072 trainable params, mode=scales only)\n",
            "  [Global KD Loss BEFORE]: 0.4256\n",
            "  step 10: local=0.0386 global=0.4183 (3.0s)\n",
            "  step 20: local=0.0419 global=0.4437 (6.0s)\n",
            "  step 30: local=0.0415 global=0.4241 (8.9s)\n",
            "  step 40: local=0.0421 global=0.3941 (11.9s)\n",
            "  step 50: local=0.0412 global=0.4294 (14.9s)\n",
            "  step 60: local=0.0416 global=0.4155 (17.9s)\n",
            "  step 70: local=0.0425 global=0.4051 (20.8s)\n",
            "  step 80: local=0.0439 global=0.4351 (23.8s)\n",
            "  step 90: local=0.0435 global=0.4405 (26.8s)\n",
            "  step 100: local=0.0443 global=0.4145 (29.8s)\n",
            "  ---\n",
            "  [Local Loss]:   0.0376 -> 0.0443 (Δ=-0.0067)\n",
            "  [Global Loss]:  0.4082 -> 0.4145 (Δ=-0.0063)\n",
            "  [Eval KD]:      0.4256 -> 0.4201 (Δ=0.0054, 1.3%)\n",
            "  [Time]:         33.9s\n",
            "\n",
            "[Progress: 6/28] Elapsed: 3:33, ETA: 13:02\n",
            "\n",
            "=== Layer 6 === (131,072 trainable params, mode=scales only)\n",
            "  [Global KD Loss BEFORE]: 0.4201\n",
            "  step 10: local=0.0392 global=0.4483 (3.0s)\n",
            "  step 20: local=0.0413 global=0.4209 (5.9s)\n",
            "  step 30: local=0.0419 global=0.4205 (8.8s)\n",
            "  step 40: local=0.0430 global=0.3988 (11.7s)\n",
            "  step 50: local=0.0430 global=0.4110 (14.6s)\n",
            "  step 60: local=0.0435 global=0.4117 (17.5s)\n",
            "  step 70: local=0.0426 global=0.3807 (20.4s)\n",
            "  step 80: local=0.0427 global=0.3822 (23.3s)\n",
            "  step 90: local=0.0437 global=0.4076 (26.3s)\n",
            "  step 100: local=0.0443 global=0.3718 (29.1s)\n",
            "  ---\n",
            "  [Local Loss]:   0.0377 -> 0.0443 (Δ=-0.0066)\n",
            "  [Global Loss]:  0.4128 -> 0.3718 (Δ=0.0411)\n",
            "  [Eval KD]:      0.4201 -> 0.4092 (Δ=0.0109, 2.6%)\n",
            "  [Time]:         33.3s\n",
            "\n",
            "[Progress: 7/28] Elapsed: 4:06, ETA: 12:20\n",
            "\n",
            "=== Layer 7 === (131,072 trainable params, mode=scales only)\n",
            "  [Global KD Loss BEFORE]: 0.4092\n",
            "  step 10: local=0.0390 global=0.4105 (2.9s)\n",
            "  step 20: local=0.0418 global=0.4070 (5.7s)\n",
            "  step 30: local=0.0420 global=0.4088 (8.6s)\n",
            "  step 40: local=0.0435 global=0.4099 (11.4s)\n",
            "  step 50: local=0.0419 global=0.4070 (14.3s)\n",
            "  step 60: local=0.0434 global=0.4256 (17.1s)\n",
            "  step 70: local=0.0431 global=0.4108 (19.9s)\n",
            "  step 80: local=0.0428 global=0.3842 (22.8s)\n",
            "  step 90: local=0.0434 global=0.4037 (25.7s)\n",
            "  step 100: local=0.0455 global=0.4226 (28.5s)\n",
            "  ---\n",
            "  [Local Loss]:   0.0369 -> 0.0455 (Δ=-0.0086)\n",
            "  [Global Loss]:  0.3982 -> 0.4226 (Δ=-0.0244)\n",
            "  [Eval KD]:      0.4092 -> 0.4059 (Δ=0.0033, 0.8%)\n",
            "  [Time]:         32.7s\n",
            "\n",
            "[Progress: 8/28] Elapsed: 4:39, ETA: 11:38\n",
            "\n",
            "=== Layer 8 === (131,072 trainable params, mode=scales only)\n",
            "  [Global KD Loss BEFORE]: 0.4059\n",
            "  step 10: local=0.0444 global=0.4181 (2.8s)\n",
            "  step 20: local=0.0458 global=0.4321 (5.6s)\n",
            "  step 30: local=0.0470 global=0.3875 (8.4s)\n",
            "  step 40: local=0.0471 global=0.3996 (11.1s)\n",
            "  step 50: local=0.0478 global=0.4057 (14.0s)\n",
            "  step 60: local=0.0478 global=0.4392 (16.7s)\n",
            "  step 70: local=0.0478 global=0.4060 (19.5s)\n",
            "  step 80: local=0.0475 global=0.3875 (22.3s)\n",
            "  step 90: local=0.0483 global=0.3991 (25.1s)\n",
            "  step 100: local=0.0485 global=0.3911 (27.9s)\n",
            "  ---\n",
            "  [Local Loss]:   0.0414 -> 0.0485 (Δ=-0.0071)\n",
            "  [Global Loss]:  0.3829 -> 0.3911 (Δ=-0.0082)\n",
            "  [Eval KD]:      0.4059 -> 0.3999 (Δ=0.0060, 1.5%)\n",
            "  [Time]:         32.0s\n",
            "\n",
            "[Progress: 9/28] Elapsed: 5:11, ETA: 10:57\n",
            "\n",
            "=== Layer 9 === (131,072 trainable params, mode=scales only)\n",
            "  [Global KD Loss BEFORE]: 0.3999\n",
            "  step 10: local=0.0398 global=0.4011 (2.8s)\n",
            "  step 20: local=0.0460 global=0.3609 (5.5s)\n",
            "  step 30: local=0.0434 global=0.4148 (8.2s)\n",
            "  step 40: local=0.0454 global=0.3827 (10.9s)\n",
            "  step 50: local=0.0454 global=0.4101 (13.6s)\n",
            "  step 60: local=0.0459 global=0.4279 (16.4s)\n",
            "  step 70: local=0.0466 global=0.4120 (19.1s)\n",
            "  step 80: local=0.0464 global=0.3785 (21.8s)\n",
            "  step 90: local=0.0467 global=0.3589 (24.5s)\n",
            "  step 100: local=0.0458 global=0.4044 (27.2s)\n",
            "  ---\n",
            "  [Local Loss]:   0.0393 -> 0.0458 (Δ=-0.0064)\n",
            "  [Global Loss]:  0.3810 -> 0.4044 (Δ=-0.0234)\n",
            "  [Eval KD]:      0.3999 -> 0.4011 (Δ=-0.0012, -0.3%)\n",
            "  [Time]:         31.4s\n",
            "\n",
            "[Progress: 10/28] Elapsed: 5:42, ETA: 10:17\n",
            "\n",
            "=== Layer 10 === (131,072 trainable params, mode=scales only)\n",
            "  [Global KD Loss BEFORE]: 0.4011\n",
            "  step 10: local=0.0464 global=0.3992 (2.7s)\n",
            "  step 20: local=0.0482 global=0.4156 (5.3s)\n",
            "  step 30: local=0.0459 global=0.3901 (8.0s)\n",
            "  step 40: local=0.0437 global=0.4109 (10.6s)\n",
            "  step 50: local=0.0450 global=0.3781 (13.3s)\n",
            "  step 60: local=0.0465 global=0.4103 (16.0s)\n",
            "  step 70: local=0.0447 global=0.4159 (18.6s)\n",
            "  step 80: local=0.0448 global=0.3835 (21.3s)\n",
            "  step 90: local=0.0444 global=0.4037 (24.0s)\n",
            "  step 100: local=0.0458 global=0.3773 (26.6s)\n",
            "  ---\n",
            "  [Local Loss]:   0.0528 -> 0.0458 (Δ=0.0070)\n",
            "  [Global Loss]:  0.4027 -> 0.3773 (Δ=0.0254)\n",
            "  [Eval KD]:      0.4011 -> 0.3996 (Δ=0.0015, 0.4%)\n",
            "  [Time]:         30.8s\n",
            "\n",
            "[Progress: 11/28] Elapsed: 6:13, ETA: 9:37\n",
            "\n",
            "=== Layer 11 === (131,072 trainable params, mode=scales only)\n",
            "  [Global KD Loss BEFORE]: 0.3996\n",
            "  step 10: local=0.0441 global=0.4036 (2.6s)\n",
            "  step 20: local=0.0484 global=0.3956 (5.2s)\n",
            "  step 30: local=0.0461 global=0.3774 (7.8s)\n",
            "  step 40: local=0.0464 global=0.4256 (10.4s)\n",
            "  step 50: local=0.0452 global=0.3918 (13.0s)\n",
            "  step 60: local=0.0469 global=0.3694 (15.6s)\n",
            "  step 70: local=0.0460 global=0.3693 (18.2s)\n",
            "  step 80: local=0.0472 global=0.3828 (20.8s)\n",
            "  step 90: local=0.0469 global=0.4139 (23.4s)\n",
            "  step 100: local=0.0474 global=0.4128 (26.0s)\n",
            "  ---\n",
            "  [Local Loss]:   0.0443 -> 0.0474 (Δ=-0.0031)\n",
            "  [Global Loss]:  0.3739 -> 0.4128 (Δ=-0.0389)\n",
            "  [Eval KD]:      0.3996 -> 0.3990 (Δ=0.0006, 0.2%)\n",
            "  [Time]:         30.2s\n",
            "\n",
            "[Progress: 12/28] Elapsed: 6:43, ETA: 8:58\n",
            "\n",
            "=== Layer 12 === (131,072 trainable params, mode=scales only)\n",
            "  [Global KD Loss BEFORE]: 0.3990\n",
            "  step 10: local=0.0482 global=0.4283 (2.6s)\n",
            "  step 20: local=0.0503 global=0.3942 (5.1s)\n",
            "  step 30: local=0.0511 global=0.3910 (7.6s)\n",
            "  step 40: local=0.0484 global=0.3914 (10.1s)\n",
            "  step 50: local=0.0497 global=0.4073 (12.7s)\n",
            "  step 60: local=0.0495 global=0.4022 (15.2s)\n",
            "  step 70: local=0.0491 global=0.3807 (17.8s)\n",
            "  step 80: local=0.0488 global=0.3865 (20.3s)\n",
            "  step 90: local=0.0513 global=0.3423 (22.9s)\n",
            "  step 100: local=0.0508 global=0.4036 (25.4s)\n",
            "  ---\n",
            "  [Local Loss]:   0.0466 -> 0.0508 (Δ=-0.0042)\n",
            "  [Global Loss]:  0.3938 -> 0.4036 (Δ=-0.0098)\n",
            "  [Eval KD]:      0.3990 -> 0.4033 (Δ=-0.0043, -1.1%)\n",
            "  [Time]:         29.6s\n",
            "\n",
            "[Progress: 13/28] Elapsed: 7:13, ETA: 8:20\n",
            "\n",
            "=== Layer 13 === (131,072 trainable params, mode=scales only)\n",
            "  [Global KD Loss BEFORE]: 0.4033\n",
            "  step 10: local=0.0449 global=0.3988 (2.5s)\n",
            "  step 20: local=0.0496 global=0.4156 (5.0s)\n",
            "  step 30: local=0.0491 global=0.4032 (7.4s)\n",
            "  step 40: local=0.0484 global=0.3805 (9.9s)\n",
            "  step 50: local=0.0506 global=0.4095 (12.4s)\n",
            "  step 60: local=0.0504 global=0.4034 (14.9s)\n",
            "  step 70: local=0.0507 global=0.3932 (17.3s)\n",
            "  step 80: local=0.0515 global=0.4001 (19.8s)\n",
            "  step 90: local=0.0495 global=0.3985 (22.3s)\n",
            "  step 100: local=0.0511 global=0.3926 (24.8s)\n",
            "  ---\n",
            "  [Local Loss]:   0.0439 -> 0.0511 (Δ=-0.0071)\n",
            "  [Global Loss]:  0.3729 -> 0.3926 (Δ=-0.0197)\n",
            "  [Eval KD]:      0.4033 -> 0.4012 (Δ=0.0021, 0.5%)\n",
            "  [Time]:         28.9s\n",
            "\n",
            "[Progress: 14/28] Elapsed: 7:42, ETA: 7:42\n",
            "\n",
            "=== Layer 14 === (131,072 trainable params, mode=scales only)\n",
            "  [Global KD Loss BEFORE]: 0.4012\n",
            "  step 10: local=0.0469 global=0.4614 (2.4s)\n",
            "  step 20: local=0.0504 global=0.3899 (4.8s)\n",
            "  step 30: local=0.0492 global=0.3817 (7.2s)\n",
            "  step 40: local=0.0499 global=0.4059 (9.6s)\n",
            "  step 50: local=0.0505 global=0.4009 (12.1s)\n",
            "  step 60: local=0.0515 global=0.3924 (14.5s)\n",
            "  step 70: local=0.0502 global=0.4141 (16.9s)\n",
            "  step 80: local=0.0500 global=0.3959 (19.3s)\n",
            "  step 90: local=0.0510 global=0.3761 (21.7s)\n",
            "  step 100: local=0.0510 global=0.4029 (24.1s)\n",
            "  ---\n",
            "  [Local Loss]:   0.0479 -> 0.0510 (Δ=-0.0031)\n",
            "  [Global Loss]:  0.3984 -> 0.4029 (Δ=-0.0045)\n",
            "  [Eval KD]:      0.4012 -> 0.4015 (Δ=-0.0003, -0.1%)\n",
            "  [Time]:         28.3s\n",
            "\n",
            "[Progress: 15/28] Elapsed: 8:10, ETA: 7:05\n",
            "\n",
            "=== Layer 15 === (131,072 trainable params, mode=scales only)\n",
            "  [Global KD Loss BEFORE]: 0.4015\n",
            "  step 10: local=0.0480 global=0.4255 (2.4s)\n",
            "  step 20: local=0.0535 global=0.4036 (4.7s)\n",
            "  step 30: local=0.0526 global=0.4007 (7.0s)\n",
            "  step 40: local=0.0516 global=0.3920 (9.4s)\n",
            "  step 50: local=0.0532 global=0.3971 (11.8s)\n",
            "  step 60: local=0.0531 global=0.3869 (14.1s)\n",
            "  step 70: local=0.0530 global=0.3764 (16.4s)\n",
            "  step 80: local=0.0537 global=0.3812 (18.8s)\n",
            "  step 90: local=0.0513 global=0.3694 (21.2s)\n",
            "  step 100: local=0.0519 global=0.4010 (23.5s)\n",
            "  ---\n",
            "  [Local Loss]:   0.0533 -> 0.0519 (Δ=0.0014)\n",
            "  [Global Loss]:  0.3957 -> 0.4010 (Δ=-0.0053)\n",
            "  [Eval KD]:      0.4015 -> 0.3964 (Δ=0.0051, 1.3%)\n",
            "  [Time]:         27.7s\n",
            "\n",
            "[Progress: 16/28] Elapsed: 8:38, ETA: 6:28\n",
            "\n",
            "=== Layer 16 === (131,072 trainable params, mode=scales only)\n",
            "  [Global KD Loss BEFORE]: 0.3964\n",
            "  step 10: local=0.0549 global=0.4024 (2.3s)\n",
            "  step 20: local=0.0542 global=0.4000 (4.6s)\n",
            "  step 30: local=0.0527 global=0.3753 (6.9s)\n",
            "  step 40: local=0.0519 global=0.3929 (9.1s)\n",
            "  step 50: local=0.0532 global=0.3691 (11.5s)\n",
            "  step 60: local=0.0510 global=0.3804 (13.7s)\n",
            "  step 70: local=0.0527 global=0.3963 (16.0s)\n",
            "  step 80: local=0.0523 global=0.3834 (18.3s)\n",
            "  step 90: local=0.0523 global=0.4048 (20.6s)\n",
            "  step 100: local=0.0517 global=0.4153 (22.9s)\n",
            "  ---\n",
            "  [Local Loss]:   0.0620 -> 0.0517 (Δ=0.0103)\n",
            "  [Global Loss]:  0.3670 -> 0.4153 (Δ=-0.0483)\n",
            "  [Eval KD]:      0.3964 -> 0.4005 (Δ=-0.0041, -1.0%)\n",
            "  [Time]:         27.1s\n",
            "\n",
            "[Progress: 17/28] Elapsed: 9:05, ETA: 5:52\n",
            "\n",
            "=== Layer 17 === (131,072 trainable params, mode=scales only)\n",
            "  [Global KD Loss BEFORE]: 0.4005\n",
            "  step 10: local=0.0439 global=0.3989 (2.3s)\n",
            "  step 20: local=0.0490 global=0.3921 (4.5s)\n",
            "  step 30: local=0.0491 global=0.3882 (6.7s)\n",
            "  step 40: local=0.0501 global=0.3966 (8.9s)\n",
            "  step 50: local=0.0501 global=0.3714 (11.2s)\n",
            "  step 60: local=0.0496 global=0.3967 (13.4s)\n",
            "  step 70: local=0.0508 global=0.3904 (15.6s)\n",
            "  step 80: local=0.0509 global=0.3733 (17.8s)\n",
            "  step 90: local=0.0513 global=0.3964 (20.1s)\n",
            "  step 100: local=0.0534 global=0.3936 (22.3s)\n",
            "  ---\n",
            "  [Local Loss]:   0.0435 -> 0.0534 (Δ=-0.0099)\n",
            "  [Global Loss]:  0.3993 -> 0.3936 (Δ=0.0057)\n",
            "  [Eval KD]:      0.4005 -> 0.3996 (Δ=0.0009, 0.2%)\n",
            "  [Time]:         26.5s\n",
            "\n",
            "[Progress: 18/28] Elapsed: 9:32, ETA: 5:17\n",
            "\n",
            "=== Layer 18 === (131,072 trainable params, mode=scales only)\n",
            "  [Global KD Loss BEFORE]: 0.3996\n",
            "  step 10: local=0.0446 global=0.4014 (2.2s)\n",
            "  step 20: local=0.0504 global=0.3866 (4.3s)\n",
            "  step 30: local=0.0516 global=0.3782 (6.5s)\n",
            "  step 40: local=0.0504 global=0.3990 (8.6s)\n",
            "  step 50: local=0.0521 global=0.3961 (10.8s)\n",
            "  step 60: local=0.0505 global=0.4079 (13.0s)\n",
            "  step 70: local=0.0488 global=0.4276 (15.1s)\n",
            "  step 80: local=0.0500 global=0.3839 (17.3s)\n",
            "  step 90: local=0.0497 global=0.3731 (19.5s)\n",
            "  step 100: local=0.0504 global=0.3942 (21.6s)\n",
            "  ---\n",
            "  [Local Loss]:   0.0452 -> 0.0504 (Δ=-0.0052)\n",
            "  [Global Loss]:  0.3890 -> 0.3942 (Δ=-0.0052)\n",
            "  [Eval KD]:      0.3996 -> 0.3979 (Δ=0.0017, 0.4%)\n",
            "  [Time]:         25.8s\n",
            "\n",
            "[Progress: 19/28] Elapsed: 9:57, ETA: 4:43\n",
            "\n",
            "=== Layer 19 === (131,072 trainable params, mode=scales only)\n",
            "  [Global KD Loss BEFORE]: 0.3979\n",
            "  step 10: local=0.0497 global=0.3648 (2.1s)\n",
            "  step 20: local=0.0520 global=0.3744 (4.2s)\n",
            "  step 30: local=0.0525 global=0.4100 (6.3s)\n",
            "  step 40: local=0.0553 global=0.3958 (8.4s)\n",
            "  step 50: local=0.0514 global=0.3916 (10.5s)\n",
            "  step 60: local=0.0528 global=0.4071 (12.6s)\n",
            "  step 70: local=0.0521 global=0.3992 (14.7s)\n",
            "  step 80: local=0.0533 global=0.3901 (16.8s)\n",
            "  step 90: local=0.0521 global=0.3947 (18.9s)\n",
            "  step 100: local=0.0518 global=0.3798 (21.0s)\n",
            "  ---\n",
            "  [Local Loss]:   0.0585 -> 0.0518 (Δ=0.0067)\n",
            "  [Global Loss]:  0.3848 -> 0.3798 (Δ=0.0049)\n",
            "  [Eval KD]:      0.3979 -> 0.3992 (Δ=-0.0013, -0.3%)\n",
            "  [Time]:         25.2s\n",
            "\n",
            "[Progress: 20/28] Elapsed: 10:22, ETA: 4:09\n",
            "\n",
            "=== Layer 20 === (131,072 trainable params, mode=scales only)\n",
            "  [Global KD Loss BEFORE]: 0.3992\n",
            "  step 10: local=0.0424 global=0.3869 (2.1s)\n",
            "  step 20: local=0.0456 global=0.4080 (4.1s)\n",
            "  step 30: local=0.0455 global=0.3656 (6.1s)\n",
            "  step 40: local=0.0445 global=0.3866 (8.1s)\n",
            "  step 50: local=0.0441 global=0.3411 (10.2s)\n",
            "  step 60: local=0.0472 global=0.4015 (12.2s)\n",
            "  step 70: local=0.0464 global=0.3926 (14.3s)\n",
            "  step 80: local=0.0449 global=0.3708 (16.3s)\n",
            "  step 90: local=0.0447 global=0.3941 (18.4s)\n",
            "  step 100: local=0.0454 global=0.3748 (20.4s)\n",
            "  ---\n",
            "  [Local Loss]:   0.0428 -> 0.0454 (Δ=-0.0026)\n",
            "  [Global Loss]:  0.3659 -> 0.3748 (Δ=-0.0089)\n",
            "  [Eval KD]:      0.3992 -> 0.3921 (Δ=0.0071, 1.8%)\n",
            "  [Time]:         24.6s\n",
            "\n",
            "[Progress: 21/28] Elapsed: 10:47, ETA: 3:35\n",
            "\n",
            "=== Layer 21 === (131,072 trainable params, mode=scales only)\n",
            "  [Global KD Loss BEFORE]: 0.3921\n",
            "  step 10: local=0.0389 global=0.3916 (2.0s)\n",
            "  step 20: local=0.0429 global=0.4035 (4.0s)\n",
            "  step 30: local=0.0419 global=0.3789 (5.9s)\n",
            "  step 40: local=0.0420 global=0.4310 (7.9s)\n",
            "  step 50: local=0.0433 global=0.3690 (9.9s)\n",
            "  step 60: local=0.0418 global=0.3853 (11.9s)\n",
            "  step 70: local=0.0411 global=0.3737 (13.8s)\n",
            "  step 80: local=0.0440 global=0.3801 (15.8s)\n",
            "  step 90: local=0.0442 global=0.3912 (17.8s)\n",
            "  step 100: local=0.0430 global=0.3823 (19.8s)\n",
            "  ---\n",
            "  [Local Loss]:   0.0376 -> 0.0430 (Δ=-0.0054)\n",
            "  [Global Loss]:  0.3819 -> 0.3823 (Δ=-0.0004)\n",
            "  [Eval KD]:      0.3921 -> 0.3905 (Δ=0.0016, 0.4%)\n",
            "  [Time]:         23.9s\n",
            "\n",
            "[Progress: 22/28] Elapsed: 11:11, ETA: 3:03\n",
            "\n",
            "=== Layer 22 === (131,072 trainable params, mode=scales only)\n",
            "  [Global KD Loss BEFORE]: 0.3905\n",
            "  step 10: local=0.0363 global=0.4043 (1.9s)\n",
            "  step 20: local=0.0367 global=0.3715 (3.8s)\n",
            "  step 30: local=0.0397 global=0.3771 (5.7s)\n",
            "  step 40: local=0.0394 global=0.3500 (7.6s)\n",
            "  step 50: local=0.0376 global=0.3909 (9.6s)\n",
            "  step 60: local=0.0386 global=0.3823 (11.5s)\n",
            "  step 70: local=0.0391 global=0.3534 (13.4s)\n",
            "  step 80: local=0.0389 global=0.3662 (15.3s)\n",
            "  step 90: local=0.0373 global=0.3883 (17.2s)\n",
            "  step 100: local=0.0397 global=0.4168 (19.2s)\n",
            "  ---\n",
            "  [Local Loss]:   0.0311 -> 0.0397 (Δ=-0.0086)\n",
            "  [Global Loss]:  0.3445 -> 0.4168 (Δ=-0.0723)\n",
            "  [Eval KD]:      0.3905 -> 0.3901 (Δ=0.0003, 0.1%)\n",
            "  [Time]:         23.4s\n",
            "\n",
            "[Progress: 23/28] Elapsed: 11:34, ETA: 2:31\n",
            "\n",
            "=== Layer 23 === (131,072 trainable params, mode=scales only)\n",
            "  [Global KD Loss BEFORE]: 0.3901\n",
            "  step 10: local=0.0352 global=0.3850 (1.9s)\n",
            "  step 20: local=0.0399 global=0.4081 (3.7s)\n",
            "  step 30: local=0.0376 global=0.3747 (5.6s)\n",
            "  step 40: local=0.0388 global=0.3808 (7.4s)\n",
            "  step 50: local=0.0419 global=0.4146 (9.3s)\n",
            "  step 60: local=0.0382 global=0.3976 (11.1s)\n",
            "  step 70: local=0.0404 global=0.3932 (13.0s)\n",
            "  step 80: local=0.0382 global=0.3842 (14.8s)\n",
            "  step 90: local=0.0406 global=0.3960 (16.7s)\n",
            "  step 100: local=0.0390 global=0.3872 (18.6s)\n",
            "  ---\n",
            "  [Local Loss]:   0.0325 -> 0.0390 (Δ=-0.0065)\n",
            "  [Global Loss]:  0.3795 -> 0.3872 (Δ=-0.0077)\n",
            "  [Eval KD]:      0.3901 -> 0.3845 (Δ=0.0056, 1.4%)\n",
            "  [Time]:         22.7s\n",
            "\n",
            "[Progress: 24/28] Elapsed: 11:57, ETA: 1:59\n",
            "\n",
            "=== Layer 24 === (131,072 trainable params, mode=scales only)\n",
            "  [Global KD Loss BEFORE]: 0.3845\n",
            "  step 10: local=0.0275 global=0.3953 (1.8s)\n",
            "  step 20: local=0.0306 global=0.3849 (3.6s)\n",
            "  step 30: local=0.0328 global=0.3967 (5.4s)\n",
            "  step 40: local=0.0300 global=0.3734 (7.2s)\n",
            "  step 50: local=0.0293 global=0.3894 (9.0s)\n",
            "  step 60: local=0.0332 global=0.3924 (10.8s)\n",
            "  step 70: local=0.0309 global=0.3838 (12.5s)\n",
            "  step 80: local=0.0313 global=0.3876 (14.3s)\n",
            "  step 90: local=0.0344 global=0.3726 (16.1s)\n",
            "  step 100: local=0.0316 global=0.3697 (17.9s)\n",
            "  ---\n",
            "  [Local Loss]:   0.0265 -> 0.0316 (Δ=-0.0051)\n",
            "  [Global Loss]:  0.3890 -> 0.3697 (Δ=0.0193)\n",
            "  [Eval KD]:      0.3845 -> 0.3887 (Δ=-0.0042, -1.1%)\n",
            "  [Time]:         22.1s\n",
            "\n",
            "[Progress: 25/28] Elapsed: 12:19, ETA: 1:28\n",
            "\n",
            "=== Layer 25 === (131,072 trainable params, mode=scales only)\n",
            "  [Global KD Loss BEFORE]: 0.3887\n",
            "  step 10: local=0.0368 global=0.3739 (1.8s)\n",
            "  step 20: local=0.0382 global=0.4018 (3.5s)\n",
            "  step 30: local=0.0364 global=0.3738 (5.2s)\n",
            "  step 40: local=0.0393 global=0.4403 (6.9s)\n",
            "  step 50: local=0.0375 global=0.3791 (8.7s)\n",
            "  step 60: local=0.0382 global=0.3724 (10.4s)\n",
            "  step 70: local=0.0322 global=0.3828 (12.1s)\n",
            "  step 80: local=0.0372 global=0.3951 (13.8s)\n",
            "  step 90: local=0.0378 global=0.3999 (15.6s)\n",
            "  step 100: local=0.0380 global=0.3847 (17.3s)\n",
            "  ---\n",
            "  [Local Loss]:   0.0437 -> 0.0380 (Δ=0.0058)\n",
            "  [Global Loss]:  0.3632 -> 0.3847 (Δ=-0.0216)\n",
            "  [Eval KD]:      0.3887 -> 0.3869 (Δ=0.0018, 0.5%)\n",
            "  [Time]:         21.4s\n",
            "\n",
            "[Progress: 26/28] Elapsed: 12:41, ETA: 0:58\n",
            "\n",
            "=== Layer 26 === (131,072 trainable params, mode=scales only)\n",
            "  [Global KD Loss BEFORE]: 0.3869\n",
            "  step 10: local=0.0479 global=0.3769 (1.7s)\n",
            "  step 20: local=0.0494 global=0.4103 (3.3s)\n",
            "  step 30: local=0.0491 global=0.3748 (5.0s)\n",
            "  step 40: local=0.0434 global=0.3635 (6.6s)\n",
            "  step 50: local=0.0455 global=0.3959 (8.4s)\n",
            "  step 60: local=0.0450 global=0.3768 (10.0s)\n",
            "  step 70: local=0.0425 global=0.3735 (11.6s)\n",
            "  step 80: local=0.0478 global=0.3676 (13.3s)\n",
            "  step 90: local=0.0460 global=0.3729 (15.0s)\n",
            "  step 100: local=0.0498 global=0.4006 (16.7s)\n",
            "  ---\n",
            "  [Local Loss]:   0.0432 -> 0.0498 (Δ=-0.0066)\n",
            "  [Global Loss]:  0.4038 -> 0.4006 (Δ=0.0033)\n",
            "  [Eval KD]:      0.3869 -> 0.3801 (Δ=0.0068, 1.8%)\n",
            "  [Time]:         20.9s\n",
            "\n",
            "[Progress: 27/28] Elapsed: 13:01, ETA: 0:28\n",
            "\n",
            "=== Layer 27 === (131,072 trainable params, mode=scales only)\n",
            "  [Global KD Loss BEFORE]: 0.3801\n",
            "  step 10: local=0.4101 global=0.4024 (1.6s)\n",
            "  step 20: local=0.0272 global=0.3775 (3.2s)\n",
            "  step 30: local=0.0585 global=0.3966 (4.8s)\n",
            "  step 40: local=0.0673 global=0.3981 (6.4s)\n",
            "  step 50: local=0.0543 global=0.3866 (8.0s)\n",
            "  step 60: local=0.0227 global=0.3654 (9.6s)\n",
            "  step 70: local=0.0314 global=0.3664 (11.2s)\n",
            "  step 80: local=0.0284 global=0.3755 (12.8s)\n",
            "  step 90: local=0.0249 global=0.3682 (14.4s)\n",
            "  step 100: local=0.0231 global=0.3840 (16.0s)\n",
            "  ---\n",
            "  [Local Loss]:   0.7723 -> 0.0231 (Δ=0.7491)\n",
            "  [Global Loss]:  0.3736 -> 0.3840 (Δ=-0.0104)\n",
            "  [Eval KD]:      0.3801 -> 0.3757 (Δ=0.0044, 1.1%)\n",
            "  [Time]:         20.2s\n",
            "\n",
            "============================================================\n",
            "LAYER-BY-LAYER TRAINING COMPLETE\n",
            "============================================================\n",
            "Total time:    13:26 (806.3s)\n",
            "Avg per layer: 28.6s\n",
            "\n",
            "[Initial Global KD Loss]: 1.0885\n",
            "[Final Global KD Loss]:   0.3553\n",
            "[Total Improvement]:      0.7332 (67.4%)\n",
            "\n",
            "Per-layer summary:\n",
            " Layer  Eval Before   Eval After     Eval Δ  Local 1st Local Last  Global 1st  Global Last     Time\n",
            "---------------------------------------------------------------------------------------------------------\n",
            "     0       1.0345       0.6752    +0.3593     0.0283     0.0646      1.0063       0.6453    37.5s\n",
            "     1       0.6752       0.6098    +0.0654     0.0361     0.0577      0.6449       0.6061    36.4s\n",
            "     2       0.6098       0.4489    +0.1609     0.0448     0.0544      0.5574       0.4350    35.8s\n",
            "     3       0.4489       0.4297    +0.0192     0.0367     0.0445      0.4586       0.4316    35.3s\n",
            "     4       0.4297       0.4256    +0.0041     0.0356     0.0436      0.4524       0.4269    34.6s\n",
            "     5       0.4256       0.4201    +0.0054     0.0376     0.0443      0.4082       0.4145    33.9s\n",
            "     6       0.4201       0.4092    +0.0109     0.0377     0.0443      0.4128       0.3718    33.3s\n",
            "     7       0.4092       0.4059    +0.0033     0.0369     0.0455      0.3982       0.4226    32.7s\n",
            "     8       0.4059       0.3999    +0.0060     0.0414     0.0485      0.3829       0.3911    32.0s\n",
            "     9       0.3999       0.4011    -0.0012     0.0393     0.0458      0.3810       0.4044    31.4s\n",
            "    10       0.4011       0.3996    +0.0015     0.0528     0.0458      0.4027       0.3773    30.8s\n",
            "    11       0.3996       0.3990    +0.0006     0.0443     0.0474      0.3739       0.4128    30.2s\n",
            "    12       0.3990       0.4033    -0.0043     0.0466     0.0508      0.3938       0.4036    29.6s\n",
            "    13       0.4033       0.4012    +0.0021     0.0439     0.0511      0.3729       0.3926    28.9s\n",
            "    14       0.4012       0.4015    -0.0003     0.0479     0.0510      0.3984       0.4029    28.3s\n",
            "    15       0.4015       0.3964    +0.0051     0.0533     0.0519      0.3957       0.4010    27.7s\n",
            "    16       0.3964       0.4005    -0.0041     0.0620     0.0517      0.3670       0.4153    27.1s\n",
            "    17       0.4005       0.3996    +0.0009     0.0435     0.0534      0.3993       0.3936    26.5s\n",
            "    18       0.3996       0.3979    +0.0017     0.0452     0.0504      0.3890       0.3942    25.8s\n",
            "    19       0.3979       0.3992    -0.0013     0.0585     0.0518      0.3848       0.3798    25.2s\n",
            "    20       0.3992       0.3921    +0.0071     0.0428     0.0454      0.3659       0.3748    24.6s\n",
            "    21       0.3921       0.3905    +0.0016     0.0376     0.0430      0.3819       0.3823    23.9s\n",
            "    22       0.3905       0.3901    +0.0003     0.0311     0.0397      0.3445       0.4168    23.4s\n",
            "    23       0.3901       0.3845    +0.0056     0.0325     0.0390      0.3795       0.3872    22.7s\n",
            "    24       0.3845       0.3887    -0.0042     0.0265     0.0316      0.3890       0.3697    22.1s\n",
            "    25       0.3887       0.3869    +0.0018     0.0437     0.0380      0.3632       0.3847    21.4s\n",
            "    26       0.3869       0.3801    +0.0068     0.0432     0.0498      0.4038       0.4006    20.9s\n",
            "    27       0.3801       0.3757    +0.0044     0.7723     0.0231      0.3736       0.3840    20.2s\n",
            "\n",
            "=== Scale Optimization Results ===\n",
            "Before: 1.0885\n",
            "After:  0.3553\n",
            "Improvement: 0.7332\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **RUN** LAYER-BY-LAYER TRAINING"
      ],
      "metadata": {
        "id": "o2veFRWaQEkB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "gupQzmm5FCuX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "14d0886b-fc70-4a65-b650-c03f411fa2c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting layer-by-layer weight training...\n",
            "LR: 2e-05, Hard label: top1=0.2, full=5e-05\n",
            "Training 28 layers (mode=weights)...\n",
            "Cache: caches/alpaca_chat_think_both_L128_K128_R1024\n",
            "Batch size: 32, Grad accum: 1\n",
            "LR: 2e-05, Steps per layer: 100\n",
            "Hard label: top1=0.2, full=5e-05\n",
            "\n",
            "[Initial Global KD Loss]: 0.5927\n",
            "\n",
            "=== Layer 0 === (15,728,640 trainable params, mode=weights)\n",
            "  Hard label: top1=0.2, full=5e-05\n",
            "  [Global KD Loss BEFORE]: 0.6361\n",
            "  step 10: local=0.0000 global=0.7199 (2.4s)\n",
            "  step 20: local=0.0000 global=0.7089 (4.1s)\n",
            "  step 30: local=0.0000 global=0.8131 (5.8s)\n",
            "  step 40: local=0.0000 global=0.7799 (8.0s)\n",
            "  step 50: local=0.0000 global=0.7745 (9.7s)\n",
            "  step 60: local=0.0000 global=0.6737 (11.4s)\n",
            "  step 70: local=0.0000 global=0.7553 (13.6s)\n",
            "  step 80: local=0.0000 global=0.8080 (15.4s)\n",
            "  step 90: local=0.0000 global=0.7113 (17.1s)\n",
            "  step 100: local=0.0000 global=0.7533 (19.2s)\n",
            "  ---\n",
            "  [Local Loss]:   0.0000 -> 0.0000 (Δ=-0.0000)\n",
            "  [Global Loss]:  0.8142 -> 0.7533 (Δ=0.0609)\n",
            "  [Eval KD]:      0.6361 -> 0.6363 (Δ=-0.0001, -0.0%)\n",
            "  [Time]:         21.6s\n",
            "\n",
            "[Progress: 1/28] Elapsed: 0:21, ETA: 9:43\n",
            "\n",
            "=== Layer 1 === (15,728,640 trainable params, mode=weights)\n",
            "  Hard label: top1=0.2, full=5e-05\n",
            "  [Global KD Loss BEFORE]: 0.6363\n",
            "  step 10: local=0.0000 global=0.7909 (2.1s)\n",
            "  step 20: local=0.0001 global=0.8599 (3.8s)\n",
            "  step 30: local=0.0001 global=0.8277 (5.4s)\n",
            "  step 40: local=0.0001 global=0.7788 (7.6s)\n",
            "  step 50: local=0.0001 global=0.7725 (9.3s)\n",
            "  step 60: local=0.0001 global=0.6721 (11.0s)\n",
            "  step 70: local=0.0000 global=0.8244 (13.1s)\n",
            "  step 80: local=0.0001 global=0.7669 (14.8s)\n",
            "  step 90: local=0.0001 global=0.7790 (16.5s)\n",
            "  step 100: local=0.0001 global=0.7030 (18.5s)\n",
            "  ---\n",
            "  [Local Loss]:   0.0000 -> 0.0001 (Δ=-0.0000)\n",
            "  [Global Loss]:  0.7500 -> 0.7030 (Δ=0.0471)\n",
            "  [Eval KD]:      0.6363 -> 0.6350 (Δ=0.0012, 0.2%)\n",
            "  [Time]:         21.0s\n",
            "\n",
            "[Progress: 2/28] Elapsed: 0:42, ETA: 9:13\n",
            "\n",
            "=== Layer 2 === (15,728,640 trainable params, mode=weights)\n",
            "  Hard label: top1=0.2, full=5e-05\n",
            "  [Global KD Loss BEFORE]: 0.6350\n",
            "  step 10: local=0.0001 global=0.7707 (2.0s)\n",
            "  step 20: local=0.0001 global=0.8067 (3.7s)\n",
            "  step 30: local=0.0001 global=0.7857 (5.3s)\n",
            "  step 40: local=0.0001 global=0.8869 (7.5s)\n",
            "  step 50: local=0.0001 global=0.8742 (9.1s)\n",
            "  step 60: local=0.0001 global=0.8814 (10.7s)\n",
            "  step 70: local=0.0001 global=0.7795 (12.9s)\n",
            "  step 80: local=0.0001 global=0.7748 (14.5s)\n",
            "  step 90: local=0.0001 global=0.8600 (16.2s)\n",
            "  step 100: local=0.0001 global=0.7640 (18.2s)\n",
            "  ---\n",
            "  [Local Loss]:   0.0000 -> 0.0001 (Δ=-0.0001)\n",
            "  [Global Loss]:  0.8467 -> 0.7640 (Δ=0.0827)\n",
            "  [Eval KD]:      0.6350 -> 0.6316 (Δ=0.0034, 0.5%)\n",
            "  [Time]:         20.6s\n",
            "\n",
            "[Progress: 3/28] Elapsed: 1:03, ETA: 8:46\n",
            "\n",
            "=== Layer 3 === (15,728,640 trainable params, mode=weights)\n",
            "  Hard label: top1=0.2, full=5e-05\n",
            "  [Global KD Loss BEFORE]: 0.6316\n",
            "  step 10: local=0.0001 global=0.7968 (2.0s)\n",
            "  step 20: local=0.0001 global=0.7415 (3.6s)\n",
            "  step 30: local=0.0001 global=0.8426 (5.2s)\n",
            "  step 40: local=0.0001 global=0.7896 (7.3s)\n",
            "  step 50: local=0.0001 global=0.7273 (8.9s)\n",
            "  step 60: local=0.0001 global=0.7021 (10.5s)\n",
            "  step 70: local=0.0001 global=0.7576 (12.6s)\n",
            "  step 80: local=0.0001 global=0.7855 (14.2s)\n",
            "  step 90: local=0.0001 global=0.8410 (15.9s)\n",
            "  step 100: local=0.0001 global=0.7395 (17.9s)\n",
            "  ---\n",
            "  [Local Loss]:   0.0000 -> 0.0001 (Δ=-0.0001)\n",
            "  [Global Loss]:  0.8021 -> 0.7395 (Δ=0.0627)\n",
            "  [Eval KD]:      0.6316 -> 0.6314 (Δ=0.0002, 0.0%)\n",
            "  [Time]:         20.3s\n",
            "\n",
            "[Progress: 4/28] Elapsed: 1:23, ETA: 8:20\n",
            "\n",
            "=== Layer 4 === (15,728,640 trainable params, mode=weights)\n",
            "  Hard label: top1=0.2, full=5e-05\n",
            "  [Global KD Loss BEFORE]: 0.6314\n",
            "  step 10: local=0.0000 global=0.8164 (2.0s)\n",
            "  step 20: local=0.0000 global=0.7754 (3.6s)\n",
            "  step 30: local=0.0000 global=0.8406 (5.1s)\n",
            "  step 40: local=0.0001 global=0.6737 (7.2s)\n",
            "  step 50: local=0.0001 global=0.6906 (8.8s)\n",
            "  step 60: local=0.0001 global=0.7604 (10.4s)\n",
            "  step 70: local=0.0001 global=0.7751 (12.4s)\n",
            "  step 80: local=0.0001 global=0.7123 (14.0s)\n",
            "  step 90: local=0.0001 global=0.6810 (15.6s)\n",
            "  step 100: local=0.0001 global=0.8022 (17.6s)\n",
            "  ---\n",
            "  [Local Loss]:   0.0000 -> 0.0001 (Δ=-0.0000)\n",
            "  [Global Loss]:  0.7536 -> 0.8022 (Δ=-0.0486)\n",
            "  [Eval KD]:      0.6314 -> 0.6316 (Δ=-0.0002, -0.0%)\n",
            "  [Time]:         20.0s\n",
            "\n",
            "[Progress: 5/28] Elapsed: 1:43, ETA: 7:55\n",
            "\n",
            "=== Layer 5 === (15,728,640 trainable params, mode=weights)\n",
            "  Hard label: top1=0.2, full=5e-05\n",
            "  [Global KD Loss BEFORE]: 0.6316\n",
            "  step 10: local=0.0000 global=0.7858 (1.7s)\n",
            "  step 20: local=0.0000 global=0.7763 (3.7s)\n",
            "  step 30: local=0.0000 global=0.8198 (5.2s)\n",
            "  step 40: local=0.0000 global=0.8552 (6.8s)\n",
            "  step 50: local=0.0000 global=0.7428 (8.7s)\n",
            "  step 60: local=0.0000 global=0.8686 (10.3s)\n",
            "  step 70: local=0.0000 global=0.8469 (11.8s)\n",
            "  step 80: local=0.0000 global=0.7920 (13.4s)\n",
            "  step 90: local=0.0000 global=0.7922 (15.4s)\n",
            "  step 100: local=0.0000 global=0.7913 (16.9s)\n",
            "  ---\n",
            "  [Local Loss]:   0.0000 -> 0.0000 (Δ=-0.0000)\n",
            "  [Global Loss]:  0.7636 -> 0.7913 (Δ=-0.0277)\n",
            "  [Eval KD]:      0.6316 -> 0.6318 (Δ=-0.0002, -0.0%)\n",
            "  [Time]:         19.3s\n",
            "\n",
            "[Progress: 6/28] Elapsed: 2:02, ETA: 7:30\n",
            "\n",
            "=== Layer 6 === (15,728,640 trainable params, mode=weights)\n",
            "  Hard label: top1=0.2, full=5e-05\n",
            "  [Global KD Loss BEFORE]: 0.6318\n",
            "  step 10: local=0.0000 global=0.8228 (2.0s)\n",
            "  step 20: local=0.0000 global=0.7709 (3.5s)\n",
            "  step 30: local=0.0000 global=0.7964 (5.0s)\n",
            "  step 40: local=0.0000 global=0.7599 (6.9s)\n",
            "  step 50: local=0.0000 global=0.7589 (8.5s)\n",
            "  step 60: local=0.0000 global=0.8108 (10.0s)\n",
            "  step 70: local=0.0000 global=0.7526 (12.0s)\n",
            "  step 80: local=0.0000 global=0.8032 (13.5s)\n",
            "  step 90: local=0.0000 global=0.7084 (15.0s)\n",
            "  step 100: local=0.0000 global=0.7377 (16.9s)\n",
            "  ---\n",
            "  [Local Loss]:   0.0000 -> 0.0000 (Δ=-0.0000)\n",
            "  [Global Loss]:  0.8276 -> 0.7377 (Δ=0.0899)\n",
            "  [Eval KD]:      0.6318 -> 0.6319 (Δ=-0.0002, -0.0%)\n",
            "  [Time]:         19.4s\n",
            "\n",
            "[Progress: 7/28] Elapsed: 2:22, ETA: 7:06\n",
            "\n",
            "=== Layer 7 === (15,728,640 trainable params, mode=weights)\n",
            "  Hard label: top1=0.2, full=5e-05\n",
            "  [Global KD Loss BEFORE]: 0.6319\n",
            "  step 10: local=0.0000 global=0.8922 (1.9s)\n",
            "  step 20: local=0.0000 global=0.7821 (3.4s)\n",
            "  step 30: local=0.0000 global=0.7817 (4.8s)\n",
            "  step 40: local=0.0000 global=0.8793 (6.8s)\n",
            "  step 50: local=0.0000 global=0.8698 (8.3s)\n",
            "  step 60: local=0.0000 global=0.8754 (9.8s)\n",
            "  step 70: local=0.0000 global=0.6952 (11.7s)\n",
            "  step 80: local=0.0000 global=0.7739 (13.2s)\n",
            "  step 90: local=0.0000 global=0.7598 (14.7s)\n",
            "  step 100: local=0.0000 global=0.7672 (16.3s)\n",
            "  ---\n",
            "  [Local Loss]:   0.0000 -> 0.0000 (Δ=-0.0000)\n",
            "  [Global Loss]:  0.8199 -> 0.7672 (Δ=0.0527)\n",
            "  [Eval KD]:      0.6319 -> 0.6219 (Δ=0.0101, 1.6%)\n",
            "  [Time]:         18.8s\n",
            "\n",
            "[Progress: 8/28] Elapsed: 2:40, ETA: 6:42\n",
            "\n",
            "=== Layer 8 === (15,728,640 trainable params, mode=weights)\n",
            "  Hard label: top1=0.2, full=5e-05\n",
            "  [Global KD Loss BEFORE]: 0.6219\n",
            "  step 10: local=0.0000 global=0.7784 (1.9s)\n",
            "  step 20: local=0.0000 global=0.8044 (3.3s)\n",
            "  step 30: local=0.0000 global=0.7456 (4.7s)\n",
            "  step 40: local=0.0000 global=0.7947 (6.7s)\n",
            "  step 50: local=0.0000 global=0.8787 (8.1s)\n",
            "  step 60: local=0.0000 global=0.8072 (9.6s)\n",
            "  step 70: local=0.0000 global=0.8154 (11.5s)\n",
            "  step 80: local=0.0000 global=0.7581 (13.0s)\n",
            "  step 90: local=0.0000 global=0.7723 (14.4s)\n",
            "  step 100: local=0.0000 global=0.7464 (16.3s)\n",
            "  ---\n",
            "  [Local Loss]:   0.0000 -> 0.0000 (Δ=-0.0000)\n",
            "  [Global Loss]:  0.7406 -> 0.7464 (Δ=-0.0058)\n",
            "  [Eval KD]:      0.6219 -> 0.6234 (Δ=-0.0015, -0.2%)\n",
            "  [Time]:         18.7s\n",
            "\n",
            "[Progress: 9/28] Elapsed: 2:59, ETA: 6:19\n",
            "\n",
            "=== Layer 9 === (15,728,640 trainable params, mode=weights)\n",
            "  Hard label: top1=0.2, full=5e-05\n",
            "  [Global KD Loss BEFORE]: 0.6234\n",
            "  step 10: local=0.0000 global=0.7678 (1.8s)\n",
            "  step 20: local=0.0000 global=0.8468 (3.2s)\n",
            "  step 30: local=0.0000 global=0.7814 (4.7s)\n",
            "  step 40: local=0.0000 global=0.6536 (6.6s)\n",
            "  step 50: local=0.0000 global=0.7415 (8.0s)\n",
            "  step 60: local=0.0000 global=0.7902 (9.4s)\n",
            "  step 70: local=0.0000 global=0.6930 (11.3s)\n",
            "  step 80: local=0.0000 global=0.7729 (12.7s)\n",
            "  step 90: local=0.0000 global=0.7588 (14.1s)\n",
            "  step 100: local=0.0000 global=0.7381 (16.0s)\n",
            "  ---\n",
            "  [Local Loss]:   0.0000 -> 0.0000 (Δ=-0.0000)\n",
            "  [Global Loss]:  0.7382 -> 0.7381 (Δ=0.0002)\n",
            "  [Eval KD]:      0.6234 -> 0.6220 (Δ=0.0014, 0.2%)\n",
            "  [Time]:         18.5s\n",
            "\n",
            "[Progress: 10/28] Elapsed: 3:18, ETA: 5:56\n",
            "\n",
            "=== Layer 10 === (15,728,640 trainable params, mode=weights)\n",
            "  Hard label: top1=0.2, full=5e-05\n",
            "  [Global KD Loss BEFORE]: 0.6220\n",
            "  step 10: local=0.0000 global=0.7878 (1.8s)\n",
            "  step 20: local=0.0000 global=0.8589 (3.2s)\n",
            "  step 30: local=0.0000 global=0.8269 (4.5s)\n",
            "  step 40: local=0.0000 global=0.8745 (6.4s)\n",
            "  step 50: local=0.0001 global=0.7465 (7.8s)\n",
            "  step 60: local=0.0001 global=0.7526 (9.2s)\n",
            "  step 70: local=0.0001 global=0.7942 (11.1s)\n",
            "  step 80: local=0.0001 global=0.7880 (12.4s)\n",
            "  step 90: local=0.0001 global=0.7428 (13.8s)\n",
            "  step 100: local=0.0001 global=0.7468 (15.6s)\n",
            "  ---\n",
            "  [Local Loss]:   0.0000 -> 0.0001 (Δ=-0.0000)\n",
            "  [Global Loss]:  0.7408 -> 0.7468 (Δ=-0.0060)\n",
            "  [Eval KD]:      0.6220 -> 0.6230 (Δ=-0.0010, -0.2%)\n",
            "  [Time]:         18.0s\n",
            "\n",
            "[Progress: 11/28] Elapsed: 3:36, ETA: 5:33\n",
            "\n",
            "=== Layer 11 === (15,728,640 trainable params, mode=weights)\n",
            "  Hard label: top1=0.2, full=5e-05\n",
            "  [Global KD Loss BEFORE]: 0.6230\n",
            "  step 10: local=0.0000 global=0.8124 (1.7s)\n",
            "  step 20: local=0.0000 global=0.7711 (3.1s)\n",
            "  step 30: local=0.0000 global=0.8363 (4.4s)\n",
            "  step 40: local=0.0000 global=0.8032 (6.3s)\n",
            "  step 50: local=0.0000 global=0.7662 (7.6s)\n",
            "  step 60: local=0.0000 global=0.8534 (9.0s)\n",
            "  step 70: local=0.0000 global=0.7484 (10.8s)\n",
            "  step 80: local=0.0000 global=0.8016 (12.2s)\n",
            "  step 90: local=0.0000 global=0.7064 (13.5s)\n",
            "  step 100: local=0.0000 global=0.7778 (15.3s)\n",
            "  ---\n",
            "  [Local Loss]:   0.0000 -> 0.0000 (Δ=-0.0000)\n",
            "  [Global Loss]:  0.7409 -> 0.7778 (Δ=-0.0368)\n",
            "  [Eval KD]:      0.6230 -> 0.6226 (Δ=0.0004, 0.1%)\n",
            "  [Time]:         17.7s\n",
            "\n",
            "[Progress: 12/28] Elapsed: 3:53, ETA: 5:11\n",
            "\n",
            "=== Layer 12 === (15,728,640 trainable params, mode=weights)\n",
            "  Hard label: top1=0.2, full=5e-05\n",
            "  [Global KD Loss BEFORE]: 0.6226\n",
            "  step 10: local=0.0000 global=0.8229 (1.7s)\n",
            "  step 20: local=0.0000 global=0.7098 (3.0s)\n",
            "  step 30: local=0.0000 global=0.7774 (4.3s)\n",
            "  step 40: local=0.0000 global=0.8543 (6.1s)\n",
            "  step 50: local=0.0000 global=0.8176 (7.5s)\n",
            "  step 60: local=0.0000 global=0.7745 (8.8s)\n",
            "  step 70: local=0.0000 global=0.7719 (10.6s)\n",
            "  step 80: local=0.0000 global=0.7700 (11.9s)\n",
            "  step 90: local=0.0000 global=0.8565 (13.2s)\n",
            "  step 100: local=0.0000 global=0.8815 (14.9s)\n",
            "  ---\n",
            "  [Local Loss]:   0.0000 -> 0.0000 (Δ=-0.0000)\n",
            "  [Global Loss]:  0.7577 -> 0.8815 (Δ=-0.1238)\n",
            "  [Eval KD]:      0.6226 -> 0.6222 (Δ=0.0004, 0.1%)\n",
            "  [Time]:         17.3s\n",
            "\n",
            "[Progress: 13/28] Elapsed: 4:11, ETA: 4:49\n",
            "\n",
            "=== Layer 13 === (15,728,640 trainable params, mode=weights)\n",
            "  Hard label: top1=0.2, full=5e-05\n",
            "  [Global KD Loss BEFORE]: 0.6222\n",
            "  step 10: local=0.0000 global=0.7656 (1.7s)\n",
            "  step 20: local=0.0000 global=0.8001 (2.9s)\n",
            "  step 30: local=0.0000 global=0.7838 (4.2s)\n",
            "  step 40: local=0.0000 global=0.6486 (6.0s)\n",
            "  step 50: local=0.0000 global=0.7362 (7.3s)\n",
            "  step 60: local=0.0000 global=0.7846 (8.6s)\n",
            "  step 70: local=0.0000 global=0.7522 (10.4s)\n",
            "  step 80: local=0.0000 global=0.7808 (11.6s)\n",
            "  step 90: local=0.0000 global=0.8346 (12.9s)\n",
            "  step 100: local=0.0000 global=0.7366 (14.6s)\n",
            "  ---\n",
            "  [Local Loss]:   0.0000 -> 0.0000 (Δ=-0.0000)\n",
            "  [Global Loss]:  0.8347 -> 0.7366 (Δ=0.0981)\n",
            "  [Eval KD]:      0.6222 -> 0.6219 (Δ=0.0002, 0.0%)\n",
            "  [Time]:         17.0s\n",
            "\n",
            "[Progress: 14/28] Elapsed: 4:28, ETA: 4:28\n",
            "\n",
            "=== Layer 14 === (15,728,640 trainable params, mode=weights)\n",
            "  Hard label: top1=0.2, full=5e-05\n",
            "  [Global KD Loss BEFORE]: 0.6219\n",
            "  step 10: local=0.0000 global=0.8400 (1.7s)\n",
            "  step 20: local=0.0000 global=0.7550 (3.0s)\n",
            "  step 30: local=0.0000 global=1.0735 (4.2s)\n",
            "  step 40: local=0.0000 global=0.7957 (5.9s)\n",
            "  step 50: local=0.0000 global=0.7486 (7.1s)\n",
            "  step 60: local=0.0000 global=0.7889 (8.4s)\n",
            "  step 70: local=0.0000 global=0.7926 (10.1s)\n",
            "  step 80: local=0.0000 global=0.7851 (11.4s)\n",
            "  step 90: local=0.0000 global=0.7424 (12.6s)\n",
            "  step 100: local=0.0000 global=0.7924 (14.3s)\n",
            "  ---\n",
            "  [Local Loss]:   0.0000 -> 0.0000 (Δ=-0.0000)\n",
            "  [Global Loss]:  0.8437 -> 0.7924 (Δ=0.0513)\n",
            "  [Eval KD]:      0.6219 -> 0.6209 (Δ=0.0011, 0.2%)\n",
            "  [Time]:         16.7s\n",
            "\n",
            "[Progress: 15/28] Elapsed: 4:44, ETA: 4:06\n",
            "\n",
            "=== Layer 15 === (15,728,640 trainable params, mode=weights)\n",
            "  Hard label: top1=0.2, full=5e-05\n",
            "  [Global KD Loss BEFORE]: 0.6209\n",
            "  step 10: local=0.0000 global=0.7752 (1.6s)\n",
            "  step 20: local=0.0000 global=0.8010 (2.8s)\n",
            "  step 30: local=0.0000 global=0.7421 (4.1s)\n",
            "  step 40: local=0.0000 global=0.6709 (5.8s)\n",
            "  step 50: local=0.0000 global=0.6886 (7.0s)\n",
            "  step 60: local=0.0000 global=0.7603 (8.2s)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-407930376.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Train all layers using the imported function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m layer_losses = train_all_layers(\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_local_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/qwen3_apple_style_2bit_qat_lora/qat_lora/layer_qat.py\u001b[0m in \u001b[0;36mtrain_all_layers\u001b[0;34m(model, cache_dir, device, batch_size, lr, epochs_per_layer, steps_per_layer, grad_accum, temperature, train_weights, train_scales, verbose, eval_before, local_weight, global_weight, local_tokens, hard_top1_weight, hard_full_weight)\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'\\n[Progress: {layer_idx}/{num_layers}] Elapsed: {format_time(elapsed)}, ETA: {format_time(eta_seconds)}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 874\u001b[0;31m         result = train_layer(\n\u001b[0m\u001b[1;32m    875\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/qwen3_apple_style_2bit_qat_lora/qat_lora/layer_qat.py\u001b[0m in \u001b[0;36mtrain_layer\u001b[0;34m(model, layer_idx, cache_dir, device, batch_size, lr, epochs, max_steps, grad_accum, temperature, train_weights, train_scales, verbose, eval_before, local_weight, global_weight, local_tokens, hard_top1_weight, hard_full_weight)\u001b[0m\n\u001b[1;32m    664\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m             \u001b[0;31m# Global KD loss (forward pass also captures MLP I/O via hook)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 666\u001b[0;31m             global_loss = compute_kd_loss_batch(\n\u001b[0m\u001b[1;32m    667\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemperature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m                 \u001b[0mno_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/qwen3_apple_style_2bit_qat_lora/qat_lora/layer_qat.py\u001b[0m in \u001b[0;36mcompute_kd_loss_batch\u001b[0;34m(model, batch, device, temperature, no_grad, hard_top1_weight, hard_full_weight)\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m         \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/qwen3_apple_style_2bit_qat_lora/qat_lora/layer_qat.py\u001b[0m in \u001b[0;36mforward_pass\u001b[0;34m()\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;31m# Get hidden states (not full logits)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m         out = model.model(\n\u001b[0m\u001b[1;32m    252\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/generic.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1070\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1072\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1073\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moriginal_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m                 \u001b[0;31m# If we get a TypeError, it's possible that the model is not receiving the recordable kwargs correctly.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/qwen3/modeling_qwen3.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdecoder_layer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m             hidden_states = decoder_layer(\n\u001b[0m\u001b[1;32m    411\u001b[0m                 \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m                 \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcausal_mask_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdecoder_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/modeling_layers.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gradient_checkpointing_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/deprecation.py\u001b[0m in \u001b[0;36mwrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/qwen3/modeling_qwen3.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_values, use_cache, cache_position, position_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_layernorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;31m# Self Attention\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m         hidden_states, _ = self.self_attn(\n\u001b[0m\u001b[1;32m    261\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/utils/deprecation.py\u001b[0m in \u001b[0;36mwrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/transformers/models/qwen3/modeling_qwen3.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, position_embeddings, attention_mask, past_key_values, cache_position, **kwargs)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m         \u001b[0mattn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattn_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m         \u001b[0mattn_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mo_proj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mattn_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1778\u001b[0m     \u001b[0;31m# fmt: off\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1779\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1780\u001b[0;31m         \u001b[0mforward_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1781\u001b[0m         \u001b[0;31m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1782\u001b[0m         \u001b[0;31m# this function, and just call forward.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# LAYER-BY-LAYER WEIGHT TRAINING\n",
        "# ============================================================\n",
        "# Train weights with hard label loss for better convergence\n",
        "\n",
        "print('Starting layer-by-layer weight training...')\n",
        "print(f'LR: {LR}, Hard label: top1={HARD_TOP1_WEIGHT}, full={HARD_FULL_WEIGHT}')\n",
        "\n",
        "# Train all layers using the imported function\n",
        "layer_losses = train_all_layers(\n",
        "    model=model,\n",
        "    cache_dir=cache_local_path,\n",
        "    device=DEVICE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    lr=LR,\n",
        "    epochs_per_layer=EPOCHS_PER_LAYER,\n",
        "    grad_accum=GRAD_ACCUM,\n",
        "    temperature=DISTILL_TEMP,\n",
        "    train_weights=True,   # Train weights\n",
        "    train_scales=False,   # Keep scales frozen for now\n",
        "    local_weight=0.5,\n",
        "    global_weight=0.5,\n",
        "    hard_top1_weight=HARD_TOP1_WEIGHT,  # Helps convergence\n",
        "    hard_full_weight=HARD_FULL_WEIGHT,\n",
        "    verbose=True,\n",
        "    steps_per_layer=100,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "uv6rcQvuFCuX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f6597c5-cdb7-427f-ddfe-29e49ce6aeda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial KD Loss: 1.0885\n",
            "After Layer-by-Layer: 0.2810\n",
            "Improvement: 0.8074\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# EVALUATE AFTER LAYER-BY-LAYER\n",
        "# ============================================================\n",
        "\n",
        "model.eval()\n",
        "post_layer_loss = evaluate_kd_loss(model, cache_local_path, DEVICE, num_samples=40)\n",
        "print(f'Initial KD Loss: {initial_loss:.4f}')\n",
        "print(f'After Layer-by-Layer: {post_layer_loss:.4f}')\n",
        "print(f'Improvement: {initial_loss - post_layer_loss:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "lxSBHcq6FCuX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "392e915e-0fbe-41ac-b638-31ec69a3b42f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved to runs/anemll_q4_a4_layer_by_layer_v1\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# SAVE CHECKPOINT\n",
        "# ============================================================\n",
        "\n",
        "import os\n",
        "\n",
        "RUN_NAME = f'anemll_{QUAL}_layer_by_layer_v1'\n",
        "SAVE_DIR = f'{LOCAL_RUNS}/{RUN_NAME}'\n",
        "\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "\n",
        "# Save state dict\n",
        "torch.save(model.state_dict(), f'{SAVE_DIR}/model_state_dict.pt')\n",
        "\n",
        "# Save config\n",
        "import json\n",
        "config = {\n",
        "    'model_id': MODEL_ID,\n",
        "    'lut_size': LUT_SIZE,\n",
        "    'group_size': GROUP_SIZE,\n",
        "    'scale_rank': SCALE_RANK,\n",
        "    'attn_lut_size': ATTN_LUT_SIZE,\n",
        "    'attn_group_size': ATTN_GROUP_SIZE,\n",
        "    'attn_scale_rank': ATTN_SCALE_RANK,\n",
        "    'initial_kd_loss': initial_loss,\n",
        "    'post_layer_loss': post_layer_loss,\n",
        "    'layer_losses': layer_losses,\n",
        "}\n",
        "with open(f'{SAVE_DIR}/config.json', 'w') as f:\n",
        "    json.dump(config, f, indent=2)\n",
        "\n",
        "print(f'Saved to {SAVE_DIR}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "R4wh-UVDFCuX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96184967-5ee7-4afb-d100-013d2d56c2ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "anemll_q4_a4_layer_by_layer_v1/\n",
            "anemll_q4_a4_layer_by_layer_v1/config.json\n",
            "anemll_q4_a4_layer_by_layer_v1/model_state_dict.pt\n",
            "Uploaded to /content/drive/MyDrive/qwen3_runs/anemll_q4_a4_layer_by_layer_v1.tgz\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# UPLOAD TO GOOGLE DRIVE\n",
        "# ============================================================\n",
        "\n",
        "!tar -czvf {RUN_NAME}.tgz -C {LOCAL_RUNS} {RUN_NAME}\n",
        "!cp {RUN_NAME}.tgz {GD_RUNS}/\n",
        "print(f'Uploaded to {GD_RUNS}/{RUN_NAME}.tgz')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **END-TO-END KD-QAT REFINEMENT**\n",
        "\n",
        "After layer-by-layer training, refine the model with all layers unfrozen.\n",
        "\n",
        "Two modes:\n",
        "1. **Train weights** (scales frozen) - Fine-tune weights globally with hard label loss\n",
        "2. **Train scales** (weights frozen) - Optimize scales for better quantization\n",
        "\n",
        "## Distillation Options\n",
        "\n",
        "| Parameter | Weight Training | Scale Training |\n",
        "|-----------|----------------|----------------|\n",
        "| `temperature` | 2.0 | 2.0 |\n",
        "| `hard_top1_weight` | 0.1 (recommended) | 0.0 |\n",
        "| `hard_full_weight` | 0.0 | 0.0 |\n",
        "\n",
        "Hard label loss helps prevent divergence during weight training."
      ],
      "metadata": {
        "id": "SpN8WSKqD2hK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# END-TO-END KD-QAT: TRAIN SCALES (WEIGHTS FROZEN)\n",
        "# ============================================================\n",
        "# Scale training doesn't need hard label loss\n",
        "\n",
        "# Train scales (weights frozen) - higher LR since fewer params\n",
        "e2e_scales_result = train_e2e(\n",
        "    model=model,\n",
        "    cache_dir=cache_local_path,\n",
        "    device=DEVICE,\n",
        "    max_steps=2000,\n",
        "    batch_size=64 if torch.cuda.is_available() else 32,\n",
        "    lr=5e-4,  # Higher LR for scales\n",
        "    use_cosine_schedule=True,\n",
        "    warmup_steps=100,          # Linear warmup\n",
        "    min_lr_ratio=0.1,      # End at 5e-5\n",
        "    temperature=DISTILL_TEMP,\n",
        "    train_weights=False,\n",
        "    train_scales=True,\n",
        "    hard_top1_weight=0.0,  # Not needed for scale training\n",
        "    hard_full_weight=0.0,\n",
        "    logging_steps=20,\n",
        "    eval_steps=100,\n",
        "    verbose=True,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrQA3CXHD2hK",
        "outputId": "c3c42e60-71fe-4f6a-9436-2cca5a1bd7ae"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== End-to-End KD-QAT ===\n",
            "Mode: scales\n",
            "Trainable params: 13,303,808\n",
            "Steps: 2000, LR: 0.0005, Batch: 64\n",
            "\n",
            "Initial KD Loss: 10.1585\n",
            "[20/2000] loss=6.8576 (13s, ETA 1330s)\n",
            "[40/2000] loss=5.0527 (21s, ETA 1042s)\n",
            "[60/2000] loss=3.2987 (29s, ETA 941s)\n",
            "[80/2000] loss=2.3769 (37s, ETA 886s)\n",
            "[100/2000] loss=1.9908 (45s, ETA 860s)\n",
            "  [Eval] KD Loss: 1.8185 (best: 10.1585)\n",
            "[120/2000] loss=1.7580 (59s, ETA 919s)\n",
            "[140/2000] loss=1.6288 (66s, ETA 883s)\n",
            "[160/2000] loss=1.5216 (74s, ETA 854s)\n",
            "[180/2000] loss=1.4983 (82s, ETA 833s)\n",
            "[200/2000] loss=1.3948 (90s, ETA 812s)\n",
            "  [Eval] KD Loss: 1.3068 (best: 1.8185)\n",
            "[220/2000] loss=1.3684 (104s, ETA 842s)\n",
            "[240/2000] loss=1.3460 (112s, ETA 820s)\n",
            "[260/2000] loss=1.2889 (120s, ETA 801s)\n",
            "[280/2000] loss=1.2834 (127s, ETA 783s)\n",
            "[300/2000] loss=1.2119 (136s, ETA 769s)\n",
            "  [Eval] KD Loss: 1.1732 (best: 1.3068)\n",
            "[320/2000] loss=1.2199 (149s, ETA 780s)\n",
            "[340/2000] loss=1.2266 (156s, ETA 764s)\n",
            "[360/2000] loss=1.1805 (164s, ETA 748s)\n",
            "[380/2000] loss=1.1151 (172s, ETA 735s)\n",
            "[400/2000] loss=1.1056 (180s, ETA 721s)\n",
            "  [Eval] KD Loss: 1.0861 (best: 1.1732)\n",
            "[420/2000] loss=1.0819 (193s, ETA 727s)\n",
            "[440/2000] loss=1.0798 (201s, ETA 713s)\n",
            "[460/2000] loss=1.0709 (209s, ETA 701s)\n",
            "[480/2000] loss=1.0800 (217s, ETA 687s)\n",
            "[500/2000] loss=1.0783 (225s, ETA 674s)\n",
            "  [Eval] KD Loss: 0.9742 (best: 1.0861)\n",
            "[520/2000] loss=1.0468 (238s, ETA 678s)\n",
            "[540/2000] loss=1.0528 (246s, ETA 665s)\n",
            "[560/2000] loss=1.0287 (254s, ETA 652s)\n",
            "[580/2000] loss=1.0355 (262s, ETA 641s)\n",
            "[600/2000] loss=1.0146 (270s, ETA 629s)\n",
            "  [Eval] KD Loss: 0.9548 (best: 0.9742)\n",
            "[620/2000] loss=1.0080 (283s, ETA 629s)\n",
            "[640/2000] loss=0.9576 (290s, ETA 617s)\n",
            "[660/2000] loss=0.9565 (299s, ETA 606s)\n",
            "[680/2000] loss=0.9721 (306s, ETA 595s)\n",
            "[700/2000] loss=0.9562 (314s, ETA 583s)\n",
            "  [Eval] KD Loss: 0.8505 (best: 0.9548)\n",
            "[720/2000] loss=0.9442 (327s, ETA 582s)\n",
            "[740/2000] loss=0.9305 (335s, ETA 571s)\n",
            "[760/2000] loss=0.9343 (343s, ETA 560s)\n",
            "[780/2000] loss=0.9227 (351s, ETA 549s)\n",
            "[800/2000] loss=0.9303 (359s, ETA 538s)\n",
            "  [Eval] KD Loss: 0.8573 (best: 0.8505)\n",
            "[820/2000] loss=0.9244 (371s, ETA 534s)\n",
            "[840/2000] loss=0.9213 (379s, ETA 524s)\n",
            "[860/2000] loss=0.9158 (387s, ETA 513s)\n",
            "[880/2000] loss=0.8964 (395s, ETA 502s)\n",
            "[900/2000] loss=0.8954 (403s, ETA 492s)\n",
            "  [Eval] KD Loss: 0.8583 (best: 0.8505)\n",
            "[920/2000] loss=0.9261 (415s, ETA 487s)\n",
            "[940/2000] loss=0.8703 (423s, ETA 477s)\n",
            "[960/2000] loss=0.8442 (431s, ETA 467s)\n",
            "[980/2000] loss=0.8268 (439s, ETA 456s)\n",
            "[1000/2000] loss=0.8682 (446s, ETA 446s)\n",
            "  [Eval] KD Loss: 0.7803 (best: 0.8505)\n",
            "[1020/2000] loss=0.8546 (460s, ETA 442s)\n",
            "[1040/2000] loss=0.8587 (468s, ETA 432s)\n",
            "[1060/2000] loss=0.8318 (475s, ETA 422s)\n",
            "[1080/2000] loss=0.8415 (483s, ETA 412s)\n",
            "[1100/2000] loss=0.8520 (491s, ETA 402s)\n",
            "  [Eval] KD Loss: 0.7946 (best: 0.7803)\n",
            "[1120/2000] loss=0.8425 (504s, ETA 396s)\n",
            "[1140/2000] loss=0.8404 (512s, ETA 386s)\n",
            "[1160/2000] loss=0.8095 (519s, ETA 376s)\n",
            "[1180/2000] loss=0.8127 (528s, ETA 367s)\n",
            "[1200/2000] loss=0.8250 (535s, ETA 357s)\n",
            "  [Eval] KD Loss: 0.7793 (best: 0.7803)\n",
            "[1220/2000] loss=0.8169 (549s, ETA 351s)\n",
            "[1240/2000] loss=0.8411 (557s, ETA 341s)\n",
            "[1260/2000] loss=0.8309 (564s, ETA 331s)\n",
            "[1280/2000] loss=0.7808 (572s, ETA 322s)\n",
            "[1300/2000] loss=0.7779 (580s, ETA 312s)\n",
            "  [Eval] KD Loss: 0.7810 (best: 0.7793)\n",
            "[1320/2000] loss=0.7764 (592s, ETA 305s)\n",
            "[1340/2000] loss=0.7733 (600s, ETA 296s)\n",
            "[1360/2000] loss=0.7741 (608s, ETA 286s)\n",
            "[1380/2000] loss=0.7769 (616s, ETA 277s)\n",
            "[1400/2000] loss=0.7829 (624s, ETA 267s)\n",
            "  [Eval] KD Loss: 0.7717 (best: 0.7793)\n",
            "[1420/2000] loss=0.7759 (637s, ETA 260s)\n",
            "[1440/2000] loss=0.7842 (645s, ETA 251s)\n",
            "[1460/2000] loss=0.7582 (653s, ETA 242s)\n",
            "[1480/2000] loss=0.7622 (661s, ETA 232s)\n",
            "[1500/2000] loss=0.7701 (669s, ETA 223s)\n",
            "  [Eval] KD Loss: 0.7046 (best: 0.7717)\n",
            "[1520/2000] loss=0.7563 (682s, ETA 215s)\n",
            "[1540/2000] loss=0.7664 (690s, ETA 206s)\n",
            "[1560/2000] loss=0.7717 (698s, ETA 197s)\n",
            "[1580/2000] loss=0.7432 (706s, ETA 188s)\n",
            "[1600/2000] loss=0.7441 (713s, ETA 178s)\n",
            "  [Eval] KD Loss: 0.7062 (best: 0.7046)\n",
            "[1620/2000] loss=0.7363 (726s, ETA 170s)\n",
            "[1640/2000] loss=0.7145 (734s, ETA 161s)\n",
            "[1660/2000] loss=0.7358 (742s, ETA 152s)\n",
            "[1680/2000] loss=0.7238 (750s, ETA 143s)\n",
            "[1700/2000] loss=0.7373 (757s, ETA 134s)\n",
            "  [Eval] KD Loss: 0.7104 (best: 0.7046)\n",
            "[1720/2000] loss=0.7093 (770s, ETA 125s)\n",
            "[1740/2000] loss=0.7156 (778s, ETA 116s)\n",
            "[1760/2000] loss=0.7279 (786s, ETA 107s)\n",
            "[1780/2000] loss=0.7202 (794s, ETA 98s)\n",
            "[1800/2000] loss=0.7331 (802s, ETA 89s)\n",
            "  [Eval] KD Loss: 0.6710 (best: 0.7046)\n",
            "[1820/2000] loss=0.7328 (815s, ETA 81s)\n",
            "[1840/2000] loss=0.7244 (823s, ETA 72s)\n",
            "[1860/2000] loss=0.7296 (831s, ETA 63s)\n",
            "[1880/2000] loss=0.7144 (839s, ETA 54s)\n",
            "[1900/2000] loss=0.6819 (846s, ETA 45s)\n",
            "  [Eval] KD Loss: 0.6245 (best: 0.6710)\n",
            "[1920/2000] loss=0.6924 (859s, ETA 36s)\n",
            "[1940/2000] loss=0.7006 (867s, ETA 27s)\n",
            "[1960/2000] loss=0.6985 (875s, ETA 18s)\n",
            "[1980/2000] loss=0.6930 (883s, ETA 9s)\n",
            "[2000/2000] loss=0.7012 (891s, ETA 0s)\n",
            "  [Eval] KD Loss: 0.6403 (best: 0.6245)\n",
            "\n",
            "=== Results ===\n",
            "Initial: 10.1585\n",
            "Final:   0.6403\n",
            "Best:    0.6245\n",
            "Improvement: 9.5182\n",
            "Time: 900.4s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "I0uILDU-OXLv"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# FINE-TUNE END-TO-END KD-QAT: TRAIN WEIGHTS (SCALES FROZEN)\n",
        "# ============================================================\n",
        "# Use hard label loss for stable weight training\n",
        "\n",
        "from qat_lora import train_e2e, save_checkpoint, load_checkpoint, unfreeze_model_for_training\n",
        "\n",
        "# Unfreeze for training (clear any cached weights)\n",
        "unfreeze_model_for_training(model)\n",
        "\n",
        "print('E2E weight training with hard label loss...')\n",
        "print(f'Hard label: top1={HARD_TOP1_WEIGHT}, full={HARD_FULL_WEIGHT}')\n",
        "\n",
        "# Train weights (scales frozen)\n",
        "e2e_weights_result = train_e2e(\n",
        "    model=model,\n",
        "    cache_dir=cache_local_path,\n",
        "    device=DEVICE,\n",
        "    max_steps=1000,\n",
        "    batch_size=64 if torch.cuda.is_available() else 32,\n",
        "    lr=1e-4,  # 5x lower for polish\n",
        "    use_cosine_schedule=True,\n",
        "    warmup_steps=0,        # Skip - LR already gentle\n",
        "    min_lr_ratio=0.1,      # End at 1e-5\n",
        "    temperature=DISTILL_TEMP,\n",
        "    train_weights=True,\n",
        "    train_scales=False,\n",
        "    hard_top1_weight=0.2,  # Helps prevent divergence\n",
        "    hard_full_weight=HARD_FULL_WEIGHT,\n",
        "    logging_steps=50,\n",
        "    eval_steps=500,\n",
        "    verbose=True,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5UYzccZuHoQo",
        "outputId": "e4e5af90-72b6-4aff-f635-ea015ffbeed4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E2E weight training with hard label loss...\n",
            "Hard label: top1=0.2, full=5e-05\n",
            "=== End-to-End KD-QAT ===\n",
            "Mode: weights\n",
            "Trainable params: 440,401,920\n",
            "Steps: 1000, LR: 0.0001, Batch: 64\n",
            "Hard label: top1=0.2, full=5e-05\n",
            "\n",
            "Initial KD Loss: 0.6396\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# END-TO-END KD-QAT: TRAIN WEIGHTS (SCALES FROZEN)\n",
        "# ============================================================\n",
        "# Use hard label loss for stable weight training\n",
        "\n",
        "from qat_lora import train_e2e, save_checkpoint, load_checkpoint, unfreeze_model_for_training\n",
        "\n",
        "# Unfreeze for training (clear any cached weights)\n",
        "unfreeze_model_for_training(model)\n",
        "\n",
        "print('E2E weight training with hard label loss...')\n",
        "print(f'Hard label: top1={HARD_TOP1_WEIGHT}, full={HARD_FULL_WEIGHT}')\n",
        "\n",
        "# Train weights (scales frozen)\n",
        "e2e_weights_result = train_e2e(\n",
        "    model=model,\n",
        "    cache_dir=cache_local_path,\n",
        "    device=DEVICE,\n",
        "    max_steps=2000,\n",
        "    batch_size=64 if torch.cuda.is_available() else 32,\n",
        "    lr=5e-7,\n",
        "    temperature=DISTILL_TEMP,\n",
        "    train_weights=True,\n",
        "    train_scales=False,\n",
        "    hard_top1_weight=0.2,  # Helps prevent divergence\n",
        "    hard_full_weight=HARD_FULL_WEIGHT,\n",
        "    logging_steps=50,\n",
        "    eval_steps=500,\n",
        "    verbose=True,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYjQRat_D2hK",
        "outputId": "e44b3658-687a-4ae5-8e6f-3747c66353b2"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "E2E weight training with hard label loss...\n",
            "Hard label: top1=0.2, full=5e-05\n",
            "=== End-to-End KD-QAT ===\n",
            "Mode: weights\n",
            "Trainable params: 440,401,920\n",
            "Steps: 2000, LR: 1e-06, Batch: 64\n",
            "Hard label: top1=0.2, full=5e-05\n",
            "\n",
            "Initial KD Loss: 0.6547\n",
            "[50/2000] loss=0.8903 (27s, ETA 1066s)\n",
            "[100/2000] loss=0.8553 (49s, ETA 938s)\n",
            "[150/2000] loss=0.8465 (71s, ETA 881s)\n",
            "[200/2000] loss=0.8545 (93s, ETA 839s)\n",
            "[250/2000] loss=0.8477 (116s, ETA 811s)\n",
            "[300/2000] loss=0.8571 (138s, ETA 781s)\n",
            "[350/2000] loss=0.8432 (160s, ETA 753s)\n",
            "[400/2000] loss=0.8444 (182s, ETA 726s)\n",
            "[450/2000] loss=0.8565 (204s, ETA 703s)\n",
            "[500/2000] loss=0.8385 (226s, ETA 678s)\n",
            "  [Eval] KD Loss: 0.6324 (best: 0.6547)\n",
            "[550/2000] loss=0.8398 (254s, ETA 669s)\n",
            "[600/2000] loss=0.8162 (276s, ETA 644s)\n",
            "[650/2000] loss=0.8234 (298s, ETA 619s)\n",
            "[700/2000] loss=0.8082 (320s, ETA 594s)\n",
            "[750/2000] loss=0.8313 (342s, ETA 570s)\n",
            "[800/2000] loss=0.8517 (364s, ETA 546s)\n",
            "[850/2000] loss=0.8297 (387s, ETA 523s)\n",
            "[900/2000] loss=0.7969 (409s, ETA 500s)\n",
            "[950/2000] loss=0.8180 (431s, ETA 476s)\n",
            "[1000/2000] loss=0.7945 (453s, ETA 453s)\n",
            "  [Eval] KD Loss: 0.5995 (best: 0.6324)\n",
            "[1050/2000] loss=0.8055 (481s, ETA 435s)\n",
            "[1100/2000] loss=0.8193 (503s, ETA 412s)\n",
            "[1150/2000] loss=0.8017 (525s, ETA 388s)\n",
            "[1200/2000] loss=0.8252 (547s, ETA 365s)\n",
            "[1250/2000] loss=0.8307 (570s, ETA 342s)\n",
            "[1300/2000] loss=0.8082 (592s, ETA 319s)\n",
            "[1350/2000] loss=0.8078 (614s, ETA 296s)\n",
            "[1400/2000] loss=0.8325 (636s, ETA 273s)\n",
            "[1450/2000] loss=0.7947 (659s, ETA 250s)\n",
            "[1500/2000] loss=0.7992 (680s, ETA 227s)\n",
            "  [Eval] KD Loss: 0.5930 (best: 0.5995)\n",
            "[1550/2000] loss=0.8038 (709s, ETA 206s)\n",
            "[1600/2000] loss=0.7918 (730s, ETA 183s)\n",
            "[1650/2000] loss=0.7993 (752s, ETA 160s)\n",
            "[1700/2000] loss=0.7784 (774s, ETA 137s)\n",
            "[1750/2000] loss=0.8076 (796s, ETA 114s)\n",
            "[1800/2000] loss=0.8090 (818s, ETA 91s)\n",
            "[1850/2000] loss=0.8044 (840s, ETA 68s)\n",
            "[1900/2000] loss=0.8091 (862s, ETA 45s)\n",
            "[1950/2000] loss=0.7758 (884s, ETA 23s)\n",
            "[2000/2000] loss=0.7923 (906s, ETA 0s)\n",
            "  [Eval] KD Loss: 0.5936 (best: 0.5930)\n",
            "\n",
            "=== Results ===\n",
            "Initial: 0.6547\n",
            "Final:   0.5936\n",
            "Best:    0.5930\n",
            "Improvement: 0.0610\n",
            "Time: 915.5s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# SAVE FINAL CHECKPOINT\n",
        "# ============================================================\n",
        "\n",
        "unfreeze_model_for_training(model)\n",
        "E2E_RUN_NAME = f'anemll_{QUAL}_e2e_v2_scales_only'\n",
        "E2E_SAVE_DIR = f'{LOCAL_RUNS}/{E2E_RUN_NAME}'\n",
        "\n",
        "# Save with config\n",
        "config = {\n",
        "    'model_id': MODEL_ID,\n",
        "    'lut_size': LUT_SIZE,\n",
        "    'group_size': GROUP_SIZE,\n",
        "    'scale_rank': SCALE_RANK,\n",
        "    'attn_lut_size': ATTN_LUT_SIZE,\n",
        "    'attn_group_size': ATTN_GROUP_SIZE,\n",
        "    'attn_scale_rank': ATTN_SCALE_RANK,\n",
        "    #'e2e_weights_result': e2e_weights_result,\n",
        "    'e2e_scales_result': e2e_scales_result,\n",
        "}\n",
        "\n",
        "save_checkpoint(model, E2E_SAVE_DIR, config=config)\n",
        "\n",
        "# Upload to Google Drive\n",
        "!tar -czvf {E2E_RUN_NAME}.tgz -C {LOCAL_RUNS} {E2E_RUN_NAME}\n",
        "!cp {E2E_RUN_NAME}.tgz {GD_RUNS}/\n",
        "print(f'\\nUploaded to {GD_RUNS}/{E2E_RUN_NAME}.tgz')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wh3twk6GD2hK",
        "outputId": "48c52cfa-74d1-4d97-e0b2-466774dd1e3e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved checkpoint to runs/anemll_q2_a4_e2e_v2_scales_only/\n",
            "  - model_state_dict.pt\n",
            "  - indices.pt (196 layers, 420.0 MB)\n",
            "  - config.json\n",
            "anemll_q2_a4_e2e_v2_scales_only/\n",
            "anemll_q2_a4_e2e_v2_scales_only/config.json\n",
            "anemll_q2_a4_e2e_v2_scales_only/indices.pt\n",
            "anemll_q2_a4_e2e_v2_scales_only/model_state_dict.pt\n",
            "\n",
            "Uploaded to /content/drive/MyDrive/qwen3_runs/anemll_q2_a4_e2e_v2_scales_only.tgz\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **INFERENCE OPTIMIZATION**\n",
        "\n",
        "Before running inference, freeze all layers to precompute quantized weights.\n",
        "This avoids recomputing `LUT[indices] * (scale_A @ scale_B)` on every forward pass."
      ],
      "metadata": {
        "id": "fqafgf8KfRgs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# FREEZE MODEL FOR FAST INFERENCE\n",
        "# ============================================================\n",
        "# Precompute quantized weights once for all layers\n",
        "# This caches LUT[idx] * scale to avoid recomputation per token\n",
        "\n",
        "from qat_lora import freeze_model_for_inference, unfreeze_model_for_training\n",
        "\n",
        "\n",
        "print('Freezing model for inference...')\n",
        "num_frozen = freeze_model_for_inference(model, verbose=False)\n",
        "print(f'Frozen {num_frozen} layers')\n",
        "\n",
        "# To resume training later:\n",
        "# unfreeze_model_for_training(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "lWZ2KP18fRgs",
        "outputId": "d7428f9e-6a80-4d21-fc22-c2bd27726bdb"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Freezing model for inference...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\"attribute '_cached_weight_q' already exists\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2228407737.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Freezing model for inference...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mnum_frozen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfreeze_model_for_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Frozen {num_frozen} layers'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/qwen3_apple_style_2bit_qat_lora/qat_lora/ane_qat_linear.py\u001b[0m in \u001b[0;36mfreeze_model_for_inference\u001b[0;34m(model, verbose)\u001b[0m\n\u001b[1;32m    739\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_modules\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'AnemllQATLinear'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 741\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfreeze_for_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    742\u001b[0m             \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/qwen3_apple_style_2bit_qat_lora/qat_lora/ane_qat_linear.py\u001b[0m in \u001b[0;36mfreeze_for_inference\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;31m# Store as buffer (not parameter) - no gradients needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_cached_weight_q'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_q\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0;31m# Optionally delete original weight to save memory (commented for safety)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mregister_buffer\u001b[0;34m(self, name, tensor, persistent)\u001b[0m\n\u001b[1;32m    568\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'buffer name can\\'t be empty string \"\"'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"attribute '{name}' already exists\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m         elif tensor is not None and not (\n\u001b[1;32m    572\u001b[0m             \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__torch_function__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"attribute '_cached_weight_q' already exists\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bIT_brkMCfrW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "Ugmqo-MHFCuX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efb3184e-8186-482e-e460-de4377d600ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: What is the capital of France?\n",
            "Response: <think>\n",
            "<think>\n",
            "</think>\n",
            "\n",
            "The capital of France is **Paris**.\n",
            "--------------------------------------------------\n",
            "Prompt: What is Apple Neural Engine?\n",
            "Response: <think>\n",
            "<think>\n",
            "</think>\n",
            "\n",
            "Apple Neural Engine is a system of neural processing technology developed by Apple. It is designed to enable the development of neural networks and to support the development of artificial intelligence. The system is used to create and train neural networks for various applications, including machine learning, natural language processing, and other AI systems.\n",
            "--------------------------------------------------\n",
            "Prompt: Explain quantum mechanics\n",
            "Response: <think>\n",
            "<think>\n",
            "Okay, I'm a helpful assistant. Let me explain quantum mechanics in a simple way. It's the study of how particles behave at the quantum level. In the early days, people thought that particles are particles, but they also found that they can behave like waves. This is called quantum mechanics. It's a field that includes things like wave function, wave number, and the concept of superposition. \n",
            "\n",
            "So, here's a simple explanation:\n",
            "\n",
            "- **Quantum Mechanics**: It's the study of how particles behave at the quantum level. It's about how particles can behave like waves, and how they can exist in multiple states at the same time.\n",
            "\n",
            "- **Wave Function**: A wave function is a mathematical model that describes how particles can move and behave in different states. It's like a wave that can move in different directions.\n",
            "\n",
            "- **Wave Number**: The number of waves that a particle can exist in a particular state is called the wave number. It's a measure of the probability of finding a particle in a particular state.\n",
            "\n",
            "- **Superposition**: When a particle is in a state that is both a wave and a particle, it can exist in multiple states at the same time. This is called superposition.\n",
            "\n",
            "So, in summary, quantum mechanics is the study of how particles behave at the quantum level, and it includes concepts like wave function, wave number, and superposition. I'm glad to learn this! �\n",
            "\n",
            "--------------------------------------------------\n",
            "Prompt: What is speed of light\n",
            "Response: <think>\n",
            "<think>\n",
            "</think>\n",
            "\n",
            "The speed of light is a fundamental concept in physics, and it is the speed at which light travels in space. It is approximately 299,792, miles (or about 430,000 kilometers) in one second. This is a constant value in the universe, and it is important for understanding the behavior of light and the universe.\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# ============================================================\n",
        "# TEST INFERENCE\n",
        "# ============================================================\n",
        "\n",
        "def run_inference(model, tokenizer, prompt, max_new_tokens=128):\n",
        "    messages = [\n",
        "        {'role': 'system', 'content': 'You are a helpful assistant.'},\n",
        "        {'role': 'user', 'content': prompt}\n",
        "    ]\n",
        "    text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "    inputs = tokenizer(text, return_tensors='pt').to(DEVICE)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model.generate(**inputs, max_new_tokens=max_new_tokens, do_sample=False)\n",
        "\n",
        "    return tokenizer.decode(output[0][inputs['input_ids'].shape[1]:], skip_special_tokens=True)\n",
        "\n",
        "# List of prompts to test\n",
        "prompts = [\n",
        "    'What is the capital of France?',\n",
        "    'What is Apple Neural Engine?',\n",
        "    'Explain quantum mechanics',\n",
        "    'What is speed of light'\n",
        "]\n",
        "\n",
        "model.eval() # Set model to evaluation mode once\n",
        "\n",
        "for prompt in prompts:\n",
        "    response = run_inference(model, tokenizer, prompt,max_new_tokens=1024)\n",
        "    print(f'Prompt: {prompt}')\n",
        "    print(f'Response: {response}')\n",
        "    print('-' * 50) # Separator for readability\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKGYuTbyFCuX"
      },
      "source": [
        "## Next Steps\n",
        "\n",
        "After layer-by-layer training, you can:\n",
        "\n",
        "1. **End-to-end refinement** - Unfreeze all layers and train together\n",
        "2. **Train scales (A, B)** - Unfreeze scale_A, scale_B parameters\n",
        "3. **LoRA recovery** - Add LoRA adapters to recover quality"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **EXPORT FOR ANEMLL CONVERTER**\n",
        "\n",
        "Snap weights to quantized values and export for external tools.\n",
        "\n",
        "Two export modes:\n",
        "- `store_lut_values=True`: weights = LUT[idx] (normalized in [-1,1]), scales separate\n",
        "- `store_lut_values=False`: weights = LUT[idx] * scale (full dequant)"
      ],
      "metadata": {
        "id": "rYhCJltqD2hL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# SNAP WEIGHTS AND EXPORT\n",
        "# ============================================================\n",
        "# Snap weights to LUT[idx] values for ANEMLL converter\n",
        "\n",
        "from qat_lora import snap_all_weights, export_quantized_model, unfreeze_model_for_training\n",
        "\n",
        "# First unfreeze to clear cached weights\n",
        "unfreeze_model_for_training(model)\n",
        "\n",
        "# Export quantized representation BEFORE snapping (keeps original weights)\n",
        "print('Exporting quantized model representation...')\n",
        "export_dict = export_quantized_model(model, verbose=True)\n",
        "\n",
        "# Save export for ANEMLL converter\n",
        "EXPORT_DIR = f'{LOCAL_RUNS}/{E2E_RUN_NAME}_export'\n",
        "os.makedirs(EXPORT_DIR, exist_ok=True)\n",
        "torch.save(export_dict, f'{EXPORT_DIR}/quantized_model.pt')\n",
        "print(f'\\nSaved export to {EXPORT_DIR}/quantized_model.pt')\n",
        "\n",
        "# Each layer in export_dict contains:\n",
        "# - indices: [out, in] uint8 LUT indices\n",
        "# - quantized_weights: [out, in] LUT[idx] values in [-1, 1]\n",
        "# - scales: {'scale_A': [out, rank], 'scale_B': [rank, in]} or full [out, in]\n",
        "# - lut: [lut_size] values\n",
        "# - bias, in_features, out_features, etc."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alJrTNGED2hL",
        "outputId": "33417478-c46b-4125-aba6-b9f3fd0fb977"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exporting quantized model representation...\n",
            "  [export] model.layers.0.self_attn.q_proj: idx=2048.0KB, qw=4096.0KB [-1.000, 1.000], scales=48.0KB\n",
            "  [export] model.layers.0.self_attn.k_proj: idx=1024.0KB, qw=2048.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.0.self_attn.v_proj: idx=1024.0KB, qw=2048.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.0.self_attn.o_proj: idx=2048.0KB, qw=4096.0KB [-1.000, 1.000], scales=48.0KB\n",
            "  [export] model.layers.0.mlp.gate_proj: idx=3072.0KB, qw=6144.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.0.mlp.up_proj: idx=3072.0KB, qw=6144.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.0.mlp.down_proj: idx=3072.0KB, qw=6144.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.1.self_attn.q_proj: idx=2048.0KB, qw=4096.0KB [-1.000, 1.000], scales=48.0KB\n",
            "  [export] model.layers.1.self_attn.k_proj: idx=1024.0KB, qw=2048.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.1.self_attn.v_proj: idx=1024.0KB, qw=2048.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.1.self_attn.o_proj: idx=2048.0KB, qw=4096.0KB [-1.000, 1.000], scales=48.0KB\n",
            "  [export] model.layers.1.mlp.gate_proj: idx=3072.0KB, qw=6144.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.1.mlp.up_proj: idx=3072.0KB, qw=6144.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.1.mlp.down_proj: idx=3072.0KB, qw=6144.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.2.self_attn.q_proj: idx=2048.0KB, qw=4096.0KB [-1.000, 1.000], scales=48.0KB\n",
            "  [export] model.layers.2.self_attn.k_proj: idx=1024.0KB, qw=2048.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.2.self_attn.v_proj: idx=1024.0KB, qw=2048.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.2.self_attn.o_proj: idx=2048.0KB, qw=4096.0KB [-1.000, 1.000], scales=48.0KB\n",
            "  [export] model.layers.2.mlp.gate_proj: idx=3072.0KB, qw=6144.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.2.mlp.up_proj: idx=3072.0KB, qw=6144.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.2.mlp.down_proj: idx=3072.0KB, qw=6144.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.3.self_attn.q_proj: idx=2048.0KB, qw=4096.0KB [-1.000, 1.000], scales=48.0KB\n",
            "  [export] model.layers.3.self_attn.k_proj: idx=1024.0KB, qw=2048.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.3.self_attn.v_proj: idx=1024.0KB, qw=2048.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.3.self_attn.o_proj: idx=2048.0KB, qw=4096.0KB [-1.000, 1.000], scales=48.0KB\n",
            "  [export] model.layers.3.mlp.gate_proj: idx=3072.0KB, qw=6144.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.3.mlp.up_proj: idx=3072.0KB, qw=6144.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.3.mlp.down_proj: idx=3072.0KB, qw=6144.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.4.self_attn.q_proj: idx=2048.0KB, qw=4096.0KB [-1.000, 1.000], scales=48.0KB\n",
            "  [export] model.layers.4.self_attn.k_proj: idx=1024.0KB, qw=2048.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.4.self_attn.v_proj: idx=1024.0KB, qw=2048.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.4.self_attn.o_proj: idx=2048.0KB, qw=4096.0KB [-1.000, 1.000], scales=48.0KB\n",
            "  [export] model.layers.4.mlp.gate_proj: idx=3072.0KB, qw=6144.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.4.mlp.up_proj: idx=3072.0KB, qw=6144.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.4.mlp.down_proj: idx=3072.0KB, qw=6144.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.5.self_attn.q_proj: idx=2048.0KB, qw=4096.0KB [-1.000, 1.000], scales=48.0KB\n",
            "  [export] model.layers.5.self_attn.k_proj: idx=1024.0KB, qw=2048.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.5.self_attn.v_proj: idx=1024.0KB, qw=2048.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.5.self_attn.o_proj: idx=2048.0KB, qw=4096.0KB [-1.000, 1.000], scales=48.0KB\n",
            "  [export] model.layers.5.mlp.gate_proj: idx=3072.0KB, qw=6144.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.5.mlp.up_proj: idx=3072.0KB, qw=6144.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.5.mlp.down_proj: idx=3072.0KB, qw=6144.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.6.self_attn.q_proj: idx=2048.0KB, qw=4096.0KB [-1.000, 1.000], scales=48.0KB\n",
            "  [export] model.layers.6.self_attn.k_proj: idx=1024.0KB, qw=2048.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.6.self_attn.v_proj: idx=1024.0KB, qw=2048.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.6.self_attn.o_proj: idx=2048.0KB, qw=4096.0KB [-1.000, 1.000], scales=48.0KB\n",
            "  [export] model.layers.6.mlp.gate_proj: idx=3072.0KB, qw=6144.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.6.mlp.up_proj: idx=3072.0KB, qw=6144.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.6.mlp.down_proj: idx=3072.0KB, qw=6144.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.7.self_attn.q_proj: idx=2048.0KB, qw=4096.0KB [-1.000, 1.000], scales=48.0KB\n",
            "  [export] model.layers.7.self_attn.k_proj: idx=1024.0KB, qw=2048.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.7.self_attn.v_proj: idx=1024.0KB, qw=2048.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.7.self_attn.o_proj: idx=2048.0KB, qw=4096.0KB [-1.000, 1.000], scales=48.0KB\n",
            "  [export] model.layers.7.mlp.gate_proj: idx=3072.0KB, qw=6144.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.7.mlp.up_proj: idx=3072.0KB, qw=6144.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.7.mlp.down_proj: idx=3072.0KB, qw=6144.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.8.self_attn.q_proj: idx=2048.0KB, qw=4096.0KB [-1.000, 1.000], scales=48.0KB\n",
            "  [export] model.layers.8.self_attn.k_proj: idx=1024.0KB, qw=2048.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.8.self_attn.v_proj: idx=1024.0KB, qw=2048.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.8.self_attn.o_proj: idx=2048.0KB, qw=4096.0KB [-1.000, 1.000], scales=48.0KB\n",
            "  [export] model.layers.8.mlp.gate_proj: idx=3072.0KB, qw=6144.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.8.mlp.up_proj: idx=3072.0KB, qw=6144.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.8.mlp.down_proj: idx=3072.0KB, qw=6144.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.9.self_attn.q_proj: idx=2048.0KB, qw=4096.0KB [-1.000, 1.000], scales=48.0KB\n",
            "  [export] model.layers.9.self_attn.k_proj: idx=1024.0KB, qw=2048.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.9.self_attn.v_proj: idx=1024.0KB, qw=2048.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.9.self_attn.o_proj: idx=2048.0KB, qw=4096.0KB [-1.000, 1.000], scales=48.0KB\n",
            "  [export] model.layers.9.mlp.gate_proj: idx=3072.0KB, qw=6144.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.9.mlp.up_proj: idx=3072.0KB, qw=6144.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.9.mlp.down_proj: idx=3072.0KB, qw=6144.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.10.self_attn.q_proj: idx=2048.0KB, qw=4096.0KB [-1.000, 1.000], scales=48.0KB\n",
            "  [export] model.layers.10.self_attn.k_proj: idx=1024.0KB, qw=2048.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.10.self_attn.v_proj: idx=1024.0KB, qw=2048.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.10.self_attn.o_proj: idx=2048.0KB, qw=4096.0KB [-1.000, 1.000], scales=48.0KB\n",
            "  [export] model.layers.10.mlp.gate_proj: idx=3072.0KB, qw=6144.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.10.mlp.up_proj: idx=3072.0KB, qw=6144.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.10.mlp.down_proj: idx=3072.0KB, qw=6144.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.11.self_attn.q_proj: idx=2048.0KB, qw=4096.0KB [-1.000, 1.000], scales=48.0KB\n",
            "  [export] model.layers.11.self_attn.k_proj: idx=1024.0KB, qw=2048.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.11.self_attn.v_proj: idx=1024.0KB, qw=2048.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.11.self_attn.o_proj: idx=2048.0KB, qw=4096.0KB [-1.000, 1.000], scales=48.0KB\n",
            "  [export] model.layers.11.mlp.gate_proj: idx=3072.0KB, qw=6144.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.11.mlp.up_proj: idx=3072.0KB, qw=6144.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.11.mlp.down_proj: idx=3072.0KB, qw=6144.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.12.self_attn.q_proj: idx=2048.0KB, qw=4096.0KB [-1.000, 1.000], scales=48.0KB\n",
            "  [export] model.layers.12.self_attn.k_proj: idx=1024.0KB, qw=2048.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.12.self_attn.v_proj: idx=1024.0KB, qw=2048.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.12.self_attn.o_proj: idx=2048.0KB, qw=4096.0KB [-1.000, 1.000], scales=48.0KB\n",
            "  [export] model.layers.12.mlp.gate_proj: idx=3072.0KB, qw=6144.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.12.mlp.up_proj: idx=3072.0KB, qw=6144.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.12.mlp.down_proj: idx=3072.0KB, qw=6144.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.13.self_attn.q_proj: idx=2048.0KB, qw=4096.0KB [-1.000, 1.000], scales=48.0KB\n",
            "  [export] model.layers.13.self_attn.k_proj: idx=1024.0KB, qw=2048.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.13.self_attn.v_proj: idx=1024.0KB, qw=2048.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.13.self_attn.o_proj: idx=2048.0KB, qw=4096.0KB [-1.000, 1.000], scales=48.0KB\n",
            "  [export] model.layers.13.mlp.gate_proj: idx=3072.0KB, qw=6144.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.13.mlp.up_proj: idx=3072.0KB, qw=6144.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.13.mlp.down_proj: idx=3072.0KB, qw=6144.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.14.self_attn.q_proj: idx=2048.0KB, qw=4096.0KB [-1.000, 1.000], scales=48.0KB\n",
            "  [export] model.layers.14.self_attn.k_proj: idx=1024.0KB, qw=2048.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.14.self_attn.v_proj: idx=1024.0KB, qw=2048.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.14.self_attn.o_proj: idx=2048.0KB, qw=4096.0KB [-1.000, 1.000], scales=48.0KB\n",
            "  [export] model.layers.14.mlp.gate_proj: idx=3072.0KB, qw=6144.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.14.mlp.up_proj: idx=3072.0KB, qw=6144.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.14.mlp.down_proj: idx=3072.0KB, qw=6144.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.15.self_attn.q_proj: idx=2048.0KB, qw=4096.0KB [-1.000, 1.000], scales=48.0KB\n",
            "  [export] model.layers.15.self_attn.k_proj: idx=1024.0KB, qw=2048.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.15.self_attn.v_proj: idx=1024.0KB, qw=2048.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.15.self_attn.o_proj: idx=2048.0KB, qw=4096.0KB [-1.000, 1.000], scales=48.0KB\n",
            "  [export] model.layers.15.mlp.gate_proj: idx=3072.0KB, qw=6144.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.15.mlp.up_proj: idx=3072.0KB, qw=6144.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.15.mlp.down_proj: idx=3072.0KB, qw=6144.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.16.self_attn.q_proj: idx=2048.0KB, qw=4096.0KB [-1.000, 1.000], scales=48.0KB\n",
            "  [export] model.layers.16.self_attn.k_proj: idx=1024.0KB, qw=2048.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.16.self_attn.v_proj: idx=1024.0KB, qw=2048.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.16.self_attn.o_proj: idx=2048.0KB, qw=4096.0KB [-1.000, 1.000], scales=48.0KB\n",
            "  [export] model.layers.16.mlp.gate_proj: idx=3072.0KB, qw=6144.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.16.mlp.up_proj: idx=3072.0KB, qw=6144.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.16.mlp.down_proj: idx=3072.0KB, qw=6144.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.17.self_attn.q_proj: idx=2048.0KB, qw=4096.0KB [-1.000, 1.000], scales=48.0KB\n",
            "  [export] model.layers.17.self_attn.k_proj: idx=1024.0KB, qw=2048.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.17.self_attn.v_proj: idx=1024.0KB, qw=2048.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.17.self_attn.o_proj: idx=2048.0KB, qw=4096.0KB [-1.000, 1.000], scales=48.0KB\n",
            "  [export] model.layers.17.mlp.gate_proj: idx=3072.0KB, qw=6144.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.17.mlp.up_proj: idx=3072.0KB, qw=6144.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.17.mlp.down_proj: idx=3072.0KB, qw=6144.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.18.self_attn.q_proj: idx=2048.0KB, qw=4096.0KB [-1.000, 1.000], scales=48.0KB\n",
            "  [export] model.layers.18.self_attn.k_proj: idx=1024.0KB, qw=2048.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.18.self_attn.v_proj: idx=1024.0KB, qw=2048.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.18.self_attn.o_proj: idx=2048.0KB, qw=4096.0KB [-1.000, 1.000], scales=48.0KB\n",
            "  [export] model.layers.18.mlp.gate_proj: idx=3072.0KB, qw=6144.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.18.mlp.up_proj: idx=3072.0KB, qw=6144.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.18.mlp.down_proj: idx=3072.0KB, qw=6144.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.19.self_attn.q_proj: idx=2048.0KB, qw=4096.0KB [-1.000, 1.000], scales=48.0KB\n",
            "  [export] model.layers.19.self_attn.k_proj: idx=1024.0KB, qw=2048.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.19.self_attn.v_proj: idx=1024.0KB, qw=2048.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.19.self_attn.o_proj: idx=2048.0KB, qw=4096.0KB [-1.000, 1.000], scales=48.0KB\n",
            "  [export] model.layers.19.mlp.gate_proj: idx=3072.0KB, qw=6144.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.19.mlp.up_proj: idx=3072.0KB, qw=6144.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.19.mlp.down_proj: idx=3072.0KB, qw=6144.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.20.self_attn.q_proj: idx=2048.0KB, qw=4096.0KB [-1.000, 1.000], scales=48.0KB\n",
            "  [export] model.layers.20.self_attn.k_proj: idx=1024.0KB, qw=2048.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.20.self_attn.v_proj: idx=1024.0KB, qw=2048.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.20.self_attn.o_proj: idx=2048.0KB, qw=4096.0KB [-1.000, 1.000], scales=48.0KB\n",
            "  [export] model.layers.20.mlp.gate_proj: idx=3072.0KB, qw=6144.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.20.mlp.up_proj: idx=3072.0KB, qw=6144.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.20.mlp.down_proj: idx=3072.0KB, qw=6144.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.21.self_attn.q_proj: idx=2048.0KB, qw=4096.0KB [-1.000, 1.000], scales=48.0KB\n",
            "  [export] model.layers.21.self_attn.k_proj: idx=1024.0KB, qw=2048.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.21.self_attn.v_proj: idx=1024.0KB, qw=2048.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.21.self_attn.o_proj: idx=2048.0KB, qw=4096.0KB [-1.000, 1.000], scales=48.0KB\n",
            "  [export] model.layers.21.mlp.gate_proj: idx=3072.0KB, qw=6144.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.21.mlp.up_proj: idx=3072.0KB, qw=6144.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.21.mlp.down_proj: idx=3072.0KB, qw=6144.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.22.self_attn.q_proj: idx=2048.0KB, qw=4096.0KB [-1.000, 1.000], scales=48.0KB\n",
            "  [export] model.layers.22.self_attn.k_proj: idx=1024.0KB, qw=2048.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.22.self_attn.v_proj: idx=1024.0KB, qw=2048.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.22.self_attn.o_proj: idx=2048.0KB, qw=4096.0KB [-1.000, 1.000], scales=48.0KB\n",
            "  [export] model.layers.22.mlp.gate_proj: idx=3072.0KB, qw=6144.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.22.mlp.up_proj: idx=3072.0KB, qw=6144.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.22.mlp.down_proj: idx=3072.0KB, qw=6144.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.23.self_attn.q_proj: idx=2048.0KB, qw=4096.0KB [-1.000, 1.000], scales=48.0KB\n",
            "  [export] model.layers.23.self_attn.k_proj: idx=1024.0KB, qw=2048.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.23.self_attn.v_proj: idx=1024.0KB, qw=2048.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.23.self_attn.o_proj: idx=2048.0KB, qw=4096.0KB [-1.000, 1.000], scales=48.0KB\n",
            "  [export] model.layers.23.mlp.gate_proj: idx=3072.0KB, qw=6144.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.23.mlp.up_proj: idx=3072.0KB, qw=6144.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.23.mlp.down_proj: idx=3072.0KB, qw=6144.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.24.self_attn.q_proj: idx=2048.0KB, qw=4096.0KB [-1.000, 1.000], scales=48.0KB\n",
            "  [export] model.layers.24.self_attn.k_proj: idx=1024.0KB, qw=2048.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.24.self_attn.v_proj: idx=1024.0KB, qw=2048.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.24.self_attn.o_proj: idx=2048.0KB, qw=4096.0KB [-1.000, 1.000], scales=48.0KB\n",
            "  [export] model.layers.24.mlp.gate_proj: idx=3072.0KB, qw=6144.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.24.mlp.up_proj: idx=3072.0KB, qw=6144.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.24.mlp.down_proj: idx=3072.0KB, qw=6144.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.25.self_attn.q_proj: idx=2048.0KB, qw=4096.0KB [-1.000, 1.000], scales=48.0KB\n",
            "  [export] model.layers.25.self_attn.k_proj: idx=1024.0KB, qw=2048.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.25.self_attn.v_proj: idx=1024.0KB, qw=2048.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.25.self_attn.o_proj: idx=2048.0KB, qw=4096.0KB [-1.000, 1.000], scales=48.0KB\n",
            "  [export] model.layers.25.mlp.gate_proj: idx=3072.0KB, qw=6144.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.25.mlp.up_proj: idx=3072.0KB, qw=6144.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.25.mlp.down_proj: idx=3072.0KB, qw=6144.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.26.self_attn.q_proj: idx=2048.0KB, qw=4096.0KB [-1.000, 1.000], scales=48.0KB\n",
            "  [export] model.layers.26.self_attn.k_proj: idx=1024.0KB, qw=2048.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.26.self_attn.v_proj: idx=1024.0KB, qw=2048.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.26.self_attn.o_proj: idx=2048.0KB, qw=4096.0KB [-1.000, 1.000], scales=48.0KB\n",
            "  [export] model.layers.26.mlp.gate_proj: idx=3072.0KB, qw=6144.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.26.mlp.up_proj: idx=3072.0KB, qw=6144.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.26.mlp.down_proj: idx=3072.0KB, qw=6144.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.27.self_attn.q_proj: idx=2048.0KB, qw=4096.0KB [-1.000, 1.000], scales=48.0KB\n",
            "  [export] model.layers.27.self_attn.k_proj: idx=1024.0KB, qw=2048.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.27.self_attn.v_proj: idx=1024.0KB, qw=2048.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.27.self_attn.o_proj: idx=2048.0KB, qw=4096.0KB [-1.000, 1.000], scales=48.0KB\n",
            "  [export] model.layers.27.mlp.gate_proj: idx=3072.0KB, qw=6144.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.27.mlp.up_proj: idx=3072.0KB, qw=6144.0KB [-1.000, 1.000], scales=32.0KB\n",
            "  [export] model.layers.27.mlp.down_proj: idx=3072.0KB, qw=6144.0KB [-1.000, 1.000], scales=32.0KB\n",
            "\n",
            "Exported 196 layers:\n",
            "  indices:           420.00 MB\n",
            "  quantized_weights: 840.00 MB (LUT[idx])\n",
            "  scales:            7.00 MB\n",
            "\n",
            "Saved export to runs/anemll_q4_a4_e2e_v1_export/quantized_model.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# SNAP WEIGHTS TO FULL DEQUANT AND TEST\n",
        "# ============================================================\n",
        "# Snap weights = LUT[idx] * scale, then disable fake_quant for direct use\n",
        "\n",
        "print('Snapping weights to full dequantized values (LUT[idx] * scale)...')\n",
        "indices = snap_all_weights(model, store_lut_values=False, verbose=True)\n",
        "\n",
        "# Disable fake quantization - use snapped weights directly\n",
        "for name, module in model.named_modules():\n",
        "    if type(module).__name__ == 'AnemllQATLinear':\n",
        "        module.enable_fake_quant = False\n",
        "\n",
        "print('\\nTesting inference with snapped weights...')\n",
        "model.eval()\n",
        "\n",
        "# Quick test\n",
        "response = run_inference(model, tokenizer, 'What is 2+2?', max_new_tokens=1024)\n",
        "print(f'Prompt: What is 2+2?')\n",
        "print(f'Response: {response}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ny_MXsYgD2hL",
        "outputId": "73134690-8c43-4466-d32d-f95bad7965b4"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Snapping weights to full dequantized values (LUT[idx] * scale)...\n",
            "  [snapped] model.layers.0.self_attn.q_proj: rel_error=0.114258, range=[-0.586, 0.570]\n",
            "  [snapped] model.layers.0.self_attn.k_proj: rel_error=0.110840, range=[-0.426, 0.395]\n",
            "  [snapped] model.layers.0.self_attn.v_proj: rel_error=0.101562, range=[-0.128, 0.169]\n",
            "  [snapped] model.layers.0.self_attn.o_proj: rel_error=0.127930, range=[-0.439, 0.249]\n",
            "  [snapped] model.layers.0.mlp.gate_proj: rel_error=0.425781, range=[-0.385, 0.381]\n",
            "  [snapped] model.layers.0.mlp.up_proj: rel_error=0.433594, range=[-0.355, 0.334]\n",
            "  [snapped] model.layers.0.mlp.down_proj: rel_error=0.449219, range=[-0.365, 0.359]\n",
            "  [snapped] model.layers.1.self_attn.q_proj: rel_error=0.112305, range=[-0.494, 0.641]\n",
            "  [snapped] model.layers.1.self_attn.k_proj: rel_error=0.111328, range=[-0.340, 0.328]\n",
            "  [snapped] model.layers.1.self_attn.v_proj: rel_error=0.103027, range=[-0.154, 0.188]\n",
            "  [snapped] model.layers.1.self_attn.o_proj: rel_error=0.126953, range=[-0.285, 0.260]\n",
            "  [snapped] model.layers.1.mlp.gate_proj: rel_error=0.427734, range=[-0.418, 0.322]\n",
            "  [snapped] model.layers.1.mlp.up_proj: rel_error=0.433594, range=[-0.279, 0.270]\n",
            "  [snapped] model.layers.1.mlp.down_proj: rel_error=0.478516, range=[-0.377, 0.266]\n",
            "  [snapped] model.layers.2.self_attn.q_proj: rel_error=0.100586, range=[-0.531, 0.400]\n",
            "  [snapped] model.layers.2.self_attn.k_proj: rel_error=0.101562, range=[-0.256, 0.227]\n",
            "  [snapped] model.layers.2.self_attn.v_proj: rel_error=0.108887, range=[-0.173, 0.168]\n",
            "  [snapped] model.layers.2.self_attn.o_proj: rel_error=0.151367, range=[-0.258, 0.303]\n",
            "  [snapped] model.layers.2.mlp.gate_proj: rel_error=0.433594, range=[-0.328, 0.383]\n",
            "  [snapped] model.layers.2.mlp.up_proj: rel_error=0.427734, range=[-0.260, 0.516]\n",
            "  [snapped] model.layers.2.mlp.down_proj: rel_error=0.472656, range=[-0.703, 0.574]\n",
            "  [snapped] model.layers.3.self_attn.q_proj: rel_error=0.112793, range=[-0.377, 0.416]\n",
            "  [snapped] model.layers.3.self_attn.k_proj: rel_error=0.109863, range=[-0.566, 0.457]\n",
            "  [snapped] model.layers.3.self_attn.v_proj: rel_error=0.105957, range=[-0.387, 0.301]\n",
            "  [snapped] model.layers.3.self_attn.o_proj: rel_error=0.133789, range=[-0.258, 0.268]\n",
            "  [snapped] model.layers.3.mlp.gate_proj: rel_error=0.435547, range=[-0.477, 0.391]\n",
            "  [snapped] model.layers.3.mlp.up_proj: rel_error=0.423828, range=[-0.270, 0.277]\n",
            "  [snapped] model.layers.3.mlp.down_proj: rel_error=0.460938, range=[-0.352, 0.287]\n",
            "  [snapped] model.layers.4.self_attn.q_proj: rel_error=0.127930, range=[-0.480, 0.482]\n",
            "  [snapped] model.layers.4.self_attn.k_proj: rel_error=0.121582, range=[-0.314, 0.385]\n",
            "  [snapped] model.layers.4.self_attn.v_proj: rel_error=0.111816, range=[-0.207, 0.199]\n",
            "  [snapped] model.layers.4.self_attn.o_proj: rel_error=0.135742, range=[-0.316, 0.344]\n",
            "  [snapped] model.layers.4.mlp.gate_proj: rel_error=0.433594, range=[-0.389, 0.416]\n",
            "  [snapped] model.layers.4.mlp.up_proj: rel_error=0.417969, range=[-0.228, 0.223]\n",
            "  [snapped] model.layers.4.mlp.down_proj: rel_error=0.457031, range=[-0.379, 0.268]\n",
            "  [snapped] model.layers.5.self_attn.q_proj: rel_error=0.127930, range=[-0.443, 0.340]\n",
            "  [snapped] model.layers.5.self_attn.k_proj: rel_error=0.131836, range=[-0.344, 0.416]\n",
            "  [snapped] model.layers.5.self_attn.v_proj: rel_error=0.117188, range=[-0.185, 0.213]\n",
            "  [snapped] model.layers.5.self_attn.o_proj: rel_error=0.138672, range=[-0.562, 0.354]\n",
            "  [snapped] model.layers.5.mlp.gate_proj: rel_error=0.433594, range=[-0.582, 0.586]\n",
            "  [snapped] model.layers.5.mlp.up_proj: rel_error=0.423828, range=[-0.316, 0.363]\n",
            "  [snapped] model.layers.5.mlp.down_proj: rel_error=0.453125, range=[-0.352, 0.369]\n",
            "  [snapped] model.layers.6.self_attn.q_proj: rel_error=0.140625, range=[-0.391, 0.412]\n",
            "  [snapped] model.layers.6.self_attn.k_proj: rel_error=0.129883, range=[-0.482, 0.473]\n",
            "  [snapped] model.layers.6.self_attn.v_proj: rel_error=0.105957, range=[-0.161, 0.155]\n",
            "  [snapped] model.layers.6.self_attn.o_proj: rel_error=0.133789, range=[-0.245, 0.303]\n",
            "  [snapped] model.layers.6.mlp.gate_proj: rel_error=0.437500, range=[-0.307, 0.277]\n",
            "  [snapped] model.layers.6.mlp.up_proj: rel_error=0.419922, range=[-0.229, 0.235]\n",
            "  [snapped] model.layers.6.mlp.down_proj: rel_error=0.462891, range=[-0.389, 0.605]\n",
            "  [snapped] model.layers.7.self_attn.q_proj: rel_error=0.133789, range=[-0.381, 0.328]\n",
            "  [snapped] model.layers.7.self_attn.k_proj: rel_error=0.128906, range=[-0.270, 0.244]\n",
            "  [snapped] model.layers.7.self_attn.v_proj: rel_error=0.110352, range=[-0.332, 0.504]\n",
            "  [snapped] model.layers.7.self_attn.o_proj: rel_error=0.134766, range=[-0.240, 0.297]\n",
            "  [snapped] model.layers.7.mlp.gate_proj: rel_error=0.435547, range=[-0.299, 0.305]\n",
            "  [snapped] model.layers.7.mlp.up_proj: rel_error=0.419922, range=[-0.260, 0.301]\n",
            "  [snapped] model.layers.7.mlp.down_proj: rel_error=0.464844, range=[-0.539, 0.395]\n",
            "  [snapped] model.layers.8.self_attn.q_proj: rel_error=0.121582, range=[-0.287, 0.342]\n",
            "  [snapped] model.layers.8.self_attn.k_proj: rel_error=0.118164, range=[-0.648, 0.574]\n",
            "  [snapped] model.layers.8.self_attn.v_proj: rel_error=0.109375, range=[-0.185, 0.183]\n",
            "  [snapped] model.layers.8.self_attn.o_proj: rel_error=0.132812, range=[-0.314, 0.324]\n",
            "  [snapped] model.layers.8.mlp.gate_proj: rel_error=0.433594, range=[-0.660, 0.871]\n",
            "  [snapped] model.layers.8.mlp.up_proj: rel_error=0.419922, range=[-0.242, 0.383]\n",
            "  [snapped] model.layers.8.mlp.down_proj: rel_error=0.464844, range=[-0.330, 0.389]\n",
            "  [snapped] model.layers.9.self_attn.q_proj: rel_error=0.130859, range=[-0.346, 0.359]\n",
            "  [snapped] model.layers.9.self_attn.k_proj: rel_error=0.127930, range=[-0.439, 0.570]\n",
            "  [snapped] model.layers.9.self_attn.v_proj: rel_error=0.113770, range=[-0.330, 0.237]\n",
            "  [snapped] model.layers.9.self_attn.o_proj: rel_error=0.147461, range=[-0.363, 0.338]\n",
            "  [snapped] model.layers.9.mlp.gate_proj: rel_error=0.433594, range=[-0.361, 0.402]\n",
            "  [snapped] model.layers.9.mlp.up_proj: rel_error=0.423828, range=[-0.231, 0.196]\n",
            "  [snapped] model.layers.9.mlp.down_proj: rel_error=0.470703, range=[-0.387, 0.402]\n",
            "  [snapped] model.layers.10.self_attn.q_proj: rel_error=0.136719, range=[-0.299, 0.295]\n",
            "  [snapped] model.layers.10.self_attn.k_proj: rel_error=0.128906, range=[-0.232, 0.230]\n",
            "  [snapped] model.layers.10.self_attn.v_proj: rel_error=0.112793, range=[-0.132, 0.134]\n",
            "  [snapped] model.layers.10.self_attn.o_proj: rel_error=0.143555, range=[-0.277, 0.242]\n",
            "  [snapped] model.layers.10.mlp.gate_proj: rel_error=0.437500, range=[-0.498, 0.441]\n",
            "  [snapped] model.layers.10.mlp.up_proj: rel_error=0.427734, range=[-0.287, 0.406]\n",
            "  [snapped] model.layers.10.mlp.down_proj: rel_error=0.480469, range=[-0.287, 0.275]\n",
            "  [snapped] model.layers.11.self_attn.q_proj: rel_error=0.148438, range=[-0.406, 0.402]\n",
            "  [snapped] model.layers.11.self_attn.k_proj: rel_error=0.136719, range=[-0.354, 0.320]\n",
            "  [snapped] model.layers.11.self_attn.v_proj: rel_error=0.117188, range=[-0.208, 0.189]\n",
            "  [snapped] model.layers.11.self_attn.o_proj: rel_error=0.133789, range=[-0.416, 0.379]\n",
            "  [snapped] model.layers.11.mlp.gate_proj: rel_error=0.441406, range=[-0.477, 0.465]\n",
            "  [snapped] model.layers.11.mlp.up_proj: rel_error=0.427734, range=[-0.236, 0.293]\n",
            "  [snapped] model.layers.11.mlp.down_proj: rel_error=0.468750, range=[-0.479, 0.480]\n",
            "  [snapped] model.layers.12.self_attn.q_proj: rel_error=0.140625, range=[-0.320, 0.334]\n",
            "  [snapped] model.layers.12.self_attn.k_proj: rel_error=0.130859, range=[-0.326, 0.330]\n",
            "  [snapped] model.layers.12.self_attn.v_proj: rel_error=0.117676, range=[-0.145, 0.135]\n",
            "  [snapped] model.layers.12.self_attn.o_proj: rel_error=0.130859, range=[-0.236, 0.244]\n",
            "  [snapped] model.layers.12.mlp.gate_proj: rel_error=0.437500, range=[-0.281, 0.320]\n",
            "  [snapped] model.layers.12.mlp.up_proj: rel_error=0.429688, range=[-0.250, 0.293]\n",
            "  [snapped] model.layers.12.mlp.down_proj: rel_error=0.474609, range=[-0.594, 0.443]\n",
            "  [snapped] model.layers.13.self_attn.q_proj: rel_error=0.151367, range=[-0.434, 0.361]\n",
            "  [snapped] model.layers.13.self_attn.k_proj: rel_error=0.145508, range=[-0.279, 0.258]\n",
            "  [snapped] model.layers.13.self_attn.v_proj: rel_error=0.116699, range=[-0.130, 0.142]\n",
            "  [snapped] model.layers.13.self_attn.o_proj: rel_error=0.126953, range=[-0.223, 0.234]\n",
            "  [snapped] model.layers.13.mlp.gate_proj: rel_error=0.441406, range=[-0.426, 0.498]\n",
            "  [snapped] model.layers.13.mlp.up_proj: rel_error=0.437500, range=[-0.213, 0.225]\n",
            "  [snapped] model.layers.13.mlp.down_proj: rel_error=0.480469, range=[-0.365, 0.465]\n",
            "  [snapped] model.layers.14.self_attn.q_proj: rel_error=0.137695, range=[-0.328, 0.318]\n",
            "  [snapped] model.layers.14.self_attn.k_proj: rel_error=0.129883, range=[-0.322, 0.352]\n",
            "  [snapped] model.layers.14.self_attn.v_proj: rel_error=0.110840, range=[-0.132, 0.128]\n",
            "  [snapped] model.layers.14.self_attn.o_proj: rel_error=0.125977, range=[-0.246, 0.295]\n",
            "  [snapped] model.layers.14.mlp.gate_proj: rel_error=0.443359, range=[-0.449, 0.459]\n",
            "  [snapped] model.layers.14.mlp.up_proj: rel_error=0.439453, range=[-0.340, 0.277]\n",
            "  [snapped] model.layers.14.mlp.down_proj: rel_error=0.494141, range=[-0.396, 0.346]\n",
            "  [snapped] model.layers.15.self_attn.q_proj: rel_error=0.130859, range=[-0.410, 0.439]\n",
            "  [snapped] model.layers.15.self_attn.k_proj: rel_error=0.125977, range=[-0.244, 0.256]\n",
            "  [snapped] model.layers.15.self_attn.v_proj: rel_error=0.111328, range=[-0.244, 0.232]\n",
            "  [snapped] model.layers.15.self_attn.o_proj: rel_error=0.127930, range=[-0.229, 0.226]\n",
            "  [snapped] model.layers.15.mlp.gate_proj: rel_error=0.447266, range=[-0.543, 0.490]\n",
            "  [snapped] model.layers.15.mlp.up_proj: rel_error=0.443359, range=[-0.277, 0.258]\n",
            "  [snapped] model.layers.15.mlp.down_proj: rel_error=0.494141, range=[-0.316, 0.367]\n",
            "  [snapped] model.layers.16.self_attn.q_proj: rel_error=0.144531, range=[-0.432, 0.344]\n",
            "  [snapped] model.layers.16.self_attn.k_proj: rel_error=0.137695, range=[-0.852, 0.590]\n",
            "  [snapped] model.layers.16.self_attn.v_proj: rel_error=0.108887, range=[-0.144, 0.161]\n",
            "  [snapped] model.layers.16.self_attn.o_proj: rel_error=0.129883, range=[-0.232, 0.295]\n",
            "  [snapped] model.layers.16.mlp.gate_proj: rel_error=0.451172, range=[-0.426, 0.402]\n",
            "  [snapped] model.layers.16.mlp.up_proj: rel_error=0.453125, range=[-0.332, 0.352]\n",
            "  [snapped] model.layers.16.mlp.down_proj: rel_error=0.507812, range=[-0.361, 0.420]\n",
            "  [snapped] model.layers.17.self_attn.q_proj: rel_error=0.141602, range=[-0.322, 0.348]\n",
            "  [snapped] model.layers.17.self_attn.k_proj: rel_error=0.132812, range=[-0.243, 0.266]\n",
            "  [snapped] model.layers.17.self_attn.v_proj: rel_error=0.108398, range=[-0.186, 0.197]\n",
            "  [snapped] model.layers.17.self_attn.o_proj: rel_error=0.121582, range=[-0.222, 0.194]\n",
            "  [snapped] model.layers.17.mlp.gate_proj: rel_error=0.445312, range=[-0.424, 0.428]\n",
            "  [snapped] model.layers.17.mlp.up_proj: rel_error=0.437500, range=[-0.262, 0.279]\n",
            "  [snapped] model.layers.17.mlp.down_proj: rel_error=0.486328, range=[-0.406, 0.268]\n",
            "  [snapped] model.layers.18.self_attn.q_proj: rel_error=0.134766, range=[-0.359, 0.385]\n",
            "  [snapped] model.layers.18.self_attn.k_proj: rel_error=0.124023, range=[-0.361, 0.389]\n",
            "  [snapped] model.layers.18.self_attn.v_proj: rel_error=0.107910, range=[-0.178, 0.168]\n",
            "  [snapped] model.layers.18.self_attn.o_proj: rel_error=0.125000, range=[-0.258, 0.240]\n",
            "  [snapped] model.layers.18.mlp.gate_proj: rel_error=0.455078, range=[-0.582, 0.602]\n",
            "  [snapped] model.layers.18.mlp.up_proj: rel_error=0.439453, range=[-0.287, 0.295]\n",
            "  [snapped] model.layers.18.mlp.down_proj: rel_error=0.500000, range=[-0.459, 0.295]\n",
            "  [snapped] model.layers.19.self_attn.q_proj: rel_error=0.139648, range=[-0.381, 0.379]\n",
            "  [snapped] model.layers.19.self_attn.k_proj: rel_error=0.122559, range=[-0.324, 0.418]\n",
            "  [snapped] model.layers.19.self_attn.v_proj: rel_error=0.106445, range=[-0.201, 0.208]\n",
            "  [snapped] model.layers.19.self_attn.o_proj: rel_error=0.118164, range=[-0.250, 0.270]\n",
            "  [snapped] model.layers.19.mlp.gate_proj: rel_error=0.439453, range=[-0.422, 0.416]\n",
            "  [snapped] model.layers.19.mlp.up_proj: rel_error=0.437500, range=[-0.590, 0.428]\n",
            "  [snapped] model.layers.19.mlp.down_proj: rel_error=0.515625, range=[-0.336, 0.359]\n",
            "  [snapped] model.layers.20.self_attn.q_proj: rel_error=0.125977, range=[-0.449, 0.424]\n",
            "  [snapped] model.layers.20.self_attn.k_proj: rel_error=0.126953, range=[-0.301, 0.301]\n",
            "  [snapped] model.layers.20.self_attn.v_proj: rel_error=0.111328, range=[-0.266, 0.252]\n",
            "  [snapped] model.layers.20.self_attn.o_proj: rel_error=0.127930, range=[-0.320, 0.295]\n",
            "  [snapped] model.layers.20.mlp.gate_proj: rel_error=0.435547, range=[-0.551, 0.463]\n",
            "  [snapped] model.layers.20.mlp.up_proj: rel_error=0.435547, range=[-0.387, 0.484]\n",
            "  [snapped] model.layers.20.mlp.down_proj: rel_error=0.492188, range=[-0.359, 0.465]\n",
            "  [snapped] model.layers.21.self_attn.q_proj: rel_error=0.126953, range=[-0.367, 0.383]\n",
            "  [snapped] model.layers.21.self_attn.k_proj: rel_error=0.125977, range=[-0.582, 0.582]\n",
            "  [snapped] model.layers.21.self_attn.v_proj: rel_error=0.107910, range=[-0.219, 0.207]\n",
            "  [snapped] model.layers.21.self_attn.o_proj: rel_error=0.119629, range=[-0.268, 0.264]\n",
            "  [snapped] model.layers.21.mlp.gate_proj: rel_error=0.435547, range=[-0.594, 0.594]\n",
            "  [snapped] model.layers.21.mlp.up_proj: rel_error=0.433594, range=[-0.602, 0.629]\n",
            "  [snapped] model.layers.21.mlp.down_proj: rel_error=0.486328, range=[-0.373, 0.551]\n",
            "  [snapped] model.layers.22.self_attn.q_proj: rel_error=0.133789, range=[-0.334, 0.352]\n",
            "  [snapped] model.layers.22.self_attn.k_proj: rel_error=0.121094, range=[-0.214, 0.249]\n",
            "  [snapped] model.layers.22.self_attn.v_proj: rel_error=0.107422, range=[-0.213, 0.239]\n",
            "  [snapped] model.layers.22.self_attn.o_proj: rel_error=0.125000, range=[-0.287, 0.289]\n",
            "  [snapped] model.layers.22.mlp.gate_proj: rel_error=0.433594, range=[-0.586, 0.676]\n",
            "  [snapped] model.layers.22.mlp.up_proj: rel_error=0.433594, range=[-0.338, 0.574]\n",
            "  [snapped] model.layers.22.mlp.down_proj: rel_error=0.474609, range=[-0.527, 0.645]\n",
            "  [snapped] model.layers.23.self_attn.q_proj: rel_error=0.140625, range=[-0.363, 0.336]\n",
            "  [snapped] model.layers.23.self_attn.k_proj: rel_error=0.132812, range=[-0.260, 0.262]\n",
            "  [snapped] model.layers.23.self_attn.v_proj: rel_error=0.111328, range=[-0.279, 0.262]\n",
            "  [snapped] model.layers.23.self_attn.o_proj: rel_error=0.121094, range=[-0.192, 0.229]\n",
            "  [snapped] model.layers.23.mlp.gate_proj: rel_error=0.423828, range=[-0.494, 0.490]\n",
            "  [snapped] model.layers.23.mlp.up_proj: rel_error=0.429688, range=[-0.625, 0.598]\n",
            "  [snapped] model.layers.23.mlp.down_proj: rel_error=0.482422, range=[-0.551, 0.664]\n",
            "  [snapped] model.layers.24.self_attn.q_proj: rel_error=0.134766, range=[-0.375, 0.342]\n",
            "  [snapped] model.layers.24.self_attn.k_proj: rel_error=0.128906, range=[-0.242, 0.231]\n",
            "  [snapped] model.layers.24.self_attn.v_proj: rel_error=0.109863, range=[-0.169, 0.190]\n",
            "  [snapped] model.layers.24.self_attn.o_proj: rel_error=0.122070, range=[-0.237, 0.189]\n",
            "  [snapped] model.layers.24.mlp.gate_proj: rel_error=0.419922, range=[-0.598, 0.574]\n",
            "  [snapped] model.layers.24.mlp.up_proj: rel_error=0.429688, range=[-0.432, 0.375]\n",
            "  [snapped] model.layers.24.mlp.down_proj: rel_error=0.480469, range=[-0.404, 0.488]\n",
            "  [snapped] model.layers.25.self_attn.q_proj: rel_error=0.126953, range=[-0.326, 0.342]\n",
            "  [snapped] model.layers.25.self_attn.k_proj: rel_error=0.123047, range=[-0.208, 0.198]\n",
            "  [snapped] model.layers.25.self_attn.v_proj: rel_error=0.110840, range=[-0.214, 0.226]\n",
            "  [snapped] model.layers.25.self_attn.o_proj: rel_error=0.125977, range=[-0.246, 0.193]\n",
            "  [snapped] model.layers.25.mlp.gate_proj: rel_error=0.419922, range=[-0.547, 0.523]\n",
            "  [snapped] model.layers.25.mlp.up_proj: rel_error=0.427734, range=[-0.531, 0.609]\n",
            "  [snapped] model.layers.25.mlp.down_proj: rel_error=0.472656, range=[-0.496, 0.379]\n",
            "  [snapped] model.layers.26.self_attn.q_proj: rel_error=0.133789, range=[-0.283, 0.301]\n",
            "  [snapped] model.layers.26.self_attn.k_proj: rel_error=0.122559, range=[-0.223, 0.194]\n",
            "  [snapped] model.layers.26.self_attn.v_proj: rel_error=0.110840, range=[-0.151, 0.167]\n",
            "  [snapped] model.layers.26.self_attn.o_proj: rel_error=0.126953, range=[-0.355, 0.287]\n",
            "  [snapped] model.layers.26.mlp.gate_proj: rel_error=0.417969, range=[-0.941, 0.918]\n",
            "  [snapped] model.layers.26.mlp.up_proj: rel_error=0.427734, range=[-0.992, 0.918]\n",
            "  [snapped] model.layers.26.mlp.down_proj: rel_error=0.474609, range=[-0.582, 0.395]\n",
            "  [snapped] model.layers.27.self_attn.q_proj: rel_error=0.153320, range=[-0.402, 0.373]\n",
            "  [snapped] model.layers.27.self_attn.k_proj: rel_error=0.130859, range=[-0.645, 0.668]\n",
            "  [snapped] model.layers.27.self_attn.v_proj: rel_error=0.115234, range=[-0.250, 0.234]\n",
            "  [snapped] model.layers.27.self_attn.o_proj: rel_error=0.150391, range=[-0.252, 0.283]\n",
            "  [snapped] model.layers.27.mlp.gate_proj: rel_error=0.429688, range=[-1.422, 1.148]\n",
            "  [snapped] model.layers.27.mlp.up_proj: rel_error=0.423828, range=[-1.281, 1.164]\n",
            "  [snapped] model.layers.27.mlp.down_proj: rel_error=0.531250, range=[-0.715, 0.617]\n",
            "\n",
            "Snapped 196 layers to LUT[idx]*scale (avg rel_error=0.263555, indices=420.0 MB)\n",
            "\n",
            "Testing inference with snapped weights...\n",
            "Prompt: What is 2+2?\n",
            "Response: <think>\n",
            "<think>\n",
            "</think>\n",
            "\n",
            "2 + 2 = 4.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZUlMBHHEcQ0R"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}