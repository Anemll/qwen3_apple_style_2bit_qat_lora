{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# TPU LoRA KD Training: WikiText-103 L=1024\n\n**Run 1:** Long-context coherence + anti-repetition training\n\n**Target:** TPU v6e-1 (single chip) on Colab\n\n**Goals:**\n- Reduce repetitions\n- Improve long-context coherence at 1024 tokens\n- Minimal drift / no new hallucinations\n- Prepare for ANE evaluation\n\n**Prerequisites:**\n- WikiText-103 KD cache (L=1024, K=128) on Google Drive\n- V2 QAT checkpoint (q4_r32) on Google Drive\n- Colab TPU v6e-1 runtime\n\n**Documentation:** See [docs/TPU.md](../docs/TPU.md) for TPU debugging and troubleshooting guide."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup TPU Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check TPU availability (don't initialize - let training script handle it)\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Check if we're on TPU\n",
    "tpu_env = os.environ.get('TPU_NAME', os.environ.get('COLAB_TPU_ADDR', None))\n",
    "print(f\"TPU environment: {tpu_env or 'not detected'}\")\n",
    "\n",
    "if tpu_env is None:\n",
    "    print(\"\\n[WARNING] No TPU detected!\")\n",
    "    print(\"Go to: Runtime > Change runtime type > TPU v6e-1\")\n",
    "else:\n",
    "    print(\"TPU detected - will be initialized by training script\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install torch_xla for TPU support\n",
    "try:\n",
    "    import torch_xla\n",
    "    print(f'torch_xla already installed: {torch_xla.__version__}')\n",
    "except ImportError:\n",
    "    print('Installing torch_xla...')\n",
    "    !pip install torch_xla[tpu] -f https://storage.googleapis.com/libtpu-releases/index.html -q\n",
    "    import torch_xla\n",
    "    print(f'Installed torch_xla: {torch_xla.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Define paths\n",
    "GDRIVE_BASE = '/content/drive/MyDrive'\n",
    "GDRIVE_RUNS = f'{GDRIVE_BASE}/qwen3_runs'\n",
    "GDRIVE_CACHES = f'{GDRIVE_BASE}/qwen3_caches'\n",
    "\n",
    "print(f\"Drive mounted. Checking paths...\")\n",
    "!ls -la {GDRIVE_RUNS} 2>/dev/null | head -10 || echo \"qwen3_runs not found\"\n",
    "!ls -la {GDRIVE_CACHES} 2>/dev/null | head -10 || echo \"qwen3_caches not found\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Setup W&B (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install and login to Weights & Biases\n",
    "!pip install -q wandb\n",
    "\n",
    "# Try to get API key from Colab secrets\n",
    "# Setup: Colab menu -> Secrets (key icon) -> Add \"WANDB_API_KEY\"\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    wandb_key = userdata.get('WANDB_API_KEY')\n",
    "    if wandb_key:\n",
    "        import wandb\n",
    "        wandb.login(key=wandb_key)\n",
    "        print(\"W&B: Logged in via Colab secret\")\n",
    "        USE_WANDB = True\n",
    "    else:\n",
    "        print(\"W&B: No API key in secrets (will skip wandb logging)\")\n",
    "        USE_WANDB = False\n",
    "except Exception as e:\n",
    "    print(f\"W&B: Not configured - {e}\")\n",
    "    USE_WANDB = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Clone Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ============================================================\n# CONFIGURATION - WikiText L1024 KD-LoRA Training\n# ============================================================\n\n# Model\nMODEL_ID = \"Qwen/Qwen3-0.6B\"\n\n# V2 checkpoint (on Google Drive)\n# Update this path to your checkpoint\nV2_CHECKPOINT_GDRIVE = f\"{GDRIVE_RUNS}/SR-008a-revive-hermes/final_v2_q4_r32_fp32_20260107_015153.pt\"\n\n# KD Cache (on Google Drive) - WikiText-103 L=1024\n# This was generated by Generate_KD_Cache_WikiText103_L1024.ipynb\nKD_CACHE_GDRIVE = f\"{GDRIVE_CACHES}/wikitext103_32B_L1024_K128_R64_N8000\"\n\n# LoRA config - MLP-only first for stability\nRECOVERY_R = 8\nMLP_ONLY = True  # Start with MLP-only, widen later if needed\n\n# Training config for TPU v6e-1\nSEQ_LEN = 1024\nBATCH_SIZE = 4\nACCUMULATION_STEPS = 8  # Tokens/update: 4 * 1024 * 8 = 32K\nMAX_STEPS = 1200\nLOG_INTERVAL = 10\n\n# KD settings - gentle, no-think\nKD_TEMPERATURE = 1.05  # Safe with K=128 logits\nKD_ALPHA = 0.7\nHARD_TOP1 = 0.02       # Tiny \"snap\" early\nHARD_TOP1_END = 0.00   # Ends purely soft KD\n\n# Regularization\nDROPOUT = 0.05\nANCHOR_KL_WEIGHT = 0.01  # Prevents drift into weird behaviors\nANCHOR_SAMPLES = 32\n\n# Learning rate\nLR = 8e-5\nWARMUP_STEPS = 100\n\n# Saving\nSAVE_STEPS = 200\nKEEP_CHECKPOINTS = 5\n\n# Output\nOUTPUT_DIR = \"runs/lora_wikitext1024_r8_mlp_only\"\nWANDB_RUN = \"lora_wikitext_L1024_r8_mlp\"\nWANDB_PROJECT = \"qwen3-recovery-lora\"\n\n# Compute token counts\ntokens_per_step = BATCH_SIZE * SEQ_LEN\ntokens_per_update = tokens_per_step * ACCUMULATION_STEPS\n\nprint(\"=\"*60)\nprint(\"Configuration: WikiText L1024 KD-LoRA Training\")\nprint(\"=\"*60)\nprint(f\"Model:          {MODEL_ID}\")\nprint(f\"LoRA rank:      {RECOVERY_R} ({'MLP-only' if MLP_ONLY else 'MLP + attention'})\")\nprint(f\"Seq length:     {SEQ_LEN}\")\nprint(f\"Batch size:     {BATCH_SIZE}, Accumulation: {ACCUMULATION_STEPS}\")\nprint(f\"Tokens/step:    {tokens_per_step:,}\")\nprint(f\"Tokens/update:  {tokens_per_update:,}\")\nprint(f\"Max steps:      {MAX_STEPS}\")\nprint(f\"KD temp:        {KD_TEMPERATURE}, alpha: {KD_ALPHA}\")\nprint(f\"Hard top1:      {HARD_TOP1} -> {HARD_TOP1_END}\")\nprint(f\"Anchor KL:      {ANCHOR_KL_WEIGHT}\")\nprint(f\"LR:             {LR}, warmup: {WARMUP_STEPS}\")\nprint(\"=\"*60)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install -q transformers accelerate datasets sentencepiece protobuf jinja2>=3.1.0\n",
    "print('Dependencies installed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CONFIGURATION - WikiText L1024 KD-LoRA Training\n",
    "# ============================================================\n",
    "\n",
    "# Model\n",
    "MODEL_ID = \"Qwen/Qwen3-0.6B\"\n",
    "\n",
    "# V2 checkpoint (on Google Drive)\n",
    "# Update this path to your checkpoint\n",
    "V2_CHECKPOINT_GDRIVE = f\"{GDRIVE_RUNS}/SR-008a-revive-hermes/final_v2_q4_r32_fp32_20260107_015153.pt\"\n",
    "\n",
    "# KD Cache (on Google Drive) - WikiText-103 L=1024\n",
    "# This was generated by Generate_KD_Cache_WikiText103_L1024.ipynb\n",
    "KD_CACHE_GDRIVE = f\"{GDRIVE_CACHES}/wikitext103_32B_L1024_K128_R64_N8000\"\n",
    "\n",
    "# LoRA config - MLP-only first for stability\n",
    "RECOVERY_R = 8\n",
    "MLP_ONLY = True  # Start with MLP-only, widen later if needed\n",
    "\n",
    "# Training config for TPU v6e-1\n",
    "SEQ_LEN = 1024\n",
    "BATCH_SIZE = 4\n",
    "ACCUMULATION_STEPS = 8  # Effective batch: 4 * 1024 * 8 = 32K tokens/update\n",
    "MAX_STEPS = 1200\n",
    "LOG_INTERVAL = 10\n",
    "\n",
    "# KD settings - gentle, no-think\n",
    "KD_TEMPERATURE = 1.05  # Safe with K=128 logits\n",
    "KD_ALPHA = 0.7\n",
    "HARD_TOP1 = 0.02       # Tiny \"snap\" early\n",
    "HARD_TOP1_END = 0.00   # Ends purely soft KD\n",
    "\n",
    "# Regularization\n",
    "DROPOUT = 0.05\n",
    "ANCHOR_KL_WEIGHT = 0.01  # Prevents drift into weird behaviors\n",
    "ANCHOR_SAMPLES = 32\n",
    "\n",
    "# Learning rate\n",
    "LR = 8e-5\n",
    "WARMUP_STEPS = 100\n",
    "\n",
    "# Saving\n",
    "SAVE_STEPS = 200\n",
    "KEEP_CHECKPOINTS = 5\n",
    "\n",
    "# Output\n",
    "OUTPUT_DIR = \"runs/lora_wikitext1024_r8_mlp_only\"\n",
    "WANDB_RUN = \"lora_wikitext_L1024_r8_mlp\"\n",
    "WANDB_PROJECT = \"qwen3-recovery-lora\"\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"Configuration: WikiText L1024 KD-LoRA Training\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Model:          {MODEL_ID}\")\n",
    "print(f\"LoRA rank:      {RECOVERY_R} ({'MLP-only' if MLP_ONLY else 'MLP + attention'})\")\n",
    "print(f\"Seq length:     {SEQ_LEN}\")\n",
    "print(f\"Batch size:     {BATCH_SIZE} x {ACCUMULATION_STEPS} accum = {BATCH_SIZE * ACCUMULATION_STEPS} effective\")\n",
    "print(f\"Tokens/update:  {BATCH_SIZE * SEQ_LEN * ACCUMULATION_STEPS:,}\")\n",
    "print(f\"Max steps:      {MAX_STEPS}\")\n",
    "print(f\"KD temp:        {KD_TEMPERATURE}, alpha: {KD_ALPHA}\")\n",
    "print(f\"Hard top1:      {HARD_TOP1} -> {HARD_TOP1_END}\")\n",
    "print(f\"Anchor KL:      {ANCHOR_KL_WEIGHT}\")\n",
    "print(f\"LR:             {LR}, warmup: {WARMUP_STEPS}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Build training command\nos.chdir(REPO_DIR)\n\n# Use local paths for faster I/O\nckpt_path = LOCAL_CHECKPOINT if 'LOCAL_CHECKPOINT' in dir() else V2_CHECKPOINT_GDRIVE\ncache_path = LOCAL_CACHE if 'LOCAL_CACHE' in dir() else KD_CACHE_GDRIVE\n\n# Build command as list then join (avoids escaping issues)\ncmd_parts = [\n    \"python scripts/train_recovery_lora.py\",\n    \"--tpu\",\n    f\"--model {MODEL_ID}\",\n    f'--v2-checkpoint \"{ckpt_path}\"',\n    f'--kd-cache-dir \"{cache_path}\"',\n    \"--lora-mode kd\",\n    f\"--recovery-r {RECOVERY_R}\",\n]\n\nif MLP_ONLY:\n    cmd_parts.append(\"--mlp-only\")\n\ncmd_parts.extend([\n    f\"--seq-len {SEQ_LEN}\",\n    f\"--batch-size {BATCH_SIZE}\",\n    f\"--accumulation-steps {ACCUMULATION_STEPS}\",\n    f\"--max-steps {MAX_STEPS}\",\n    f\"--log-interval {LOG_INTERVAL}\",\n    f\"--kd-temperature {KD_TEMPERATURE}\",\n    f\"--kd-alpha {KD_ALPHA}\",\n    f\"--hard-top1 {HARD_TOP1}\",\n    f\"--hard-top1-end {HARD_TOP1_END}\",\n    f\"--dropout {DROPOUT}\",\n    f\"--lr {LR}\",\n    f\"--warmup-steps {WARMUP_STEPS}\",\n    f\"--anchor-kl-weight {ANCHOR_KL_WEIGHT}\",\n    f\"--anchor-samples {ANCHOR_SAMPLES}\",\n    f\"--save-steps {SAVE_STEPS}\",\n    f\"--keep-checkpoints {KEEP_CHECKPOINTS}\",\n    f'--output \"{OUTPUT_DIR}\"',\n])\n\nif USE_WANDB:\n    cmd_parts.extend([\n        \"--wandb\",\n        f\"--wandb-project {WANDB_PROJECT}\",\n        f\"--wandb-run {WANDB_RUN}\",\n    ])\n\ncmd = \" \\\\\\n  \".join(cmd_parts)\n\nprint(\"Training command:\")\nprint(cmd)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "%%time\n# Run training with XLA debug to show compilation events\n# \n# Expected timing on TPU v6e-1:\n# - Step 1: 5-15 min (XLA compilation)\n# - Step 2-3: 1-3 min (possible recompilation)\n# - Step 4+: ~1-3 sec/step (stable)\n#\n# Debug output will show:\n# - [Step N] Starting/Forward/Backward/Optimizer timing\n# - If stuck >15min, likely dynamic shape issue\n#\n# XLA env vars:\n# - PT_XLA_DEBUG=1: PyTorch/XLA debug info\n# - XLA_HLO_DEBUG=1: HLO compilation debug\n\nimport os\nos.environ['PJRT_DEVICE'] = 'TPU'\n\n!PT_XLA_DEBUG=1 {cmd}"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Sync KD Cache ---\n",
    "print(\"[2/2] Syncing KD cache...\")\n",
    "if not os.path.exists(KD_CACHE_GDRIVE):\n",
    "    print(f\"  ERROR: Cache not found: {KD_CACHE_GDRIVE}\")\n",
    "    print(\"\\n  Available caches:\")\n",
    "    !ls -la {GDRIVE_CACHES} 2>/dev/null || echo \"No caches directory\"\n",
    "else:\n",
    "    cache_name = Path(KD_CACHE_GDRIVE).name\n",
    "    LOCAL_CACHE = f\"{LOCAL_CACHE_DIR}/{cache_name}\"\n",
    "    \n",
    "    if not os.path.exists(LOCAL_CACHE):\n",
    "        # Count files and size\n",
    "        num_files = len(list(Path(KD_CACHE_GDRIVE).glob(\"*\")))\n",
    "        total_size = sum(f.stat().st_size for f in Path(KD_CACHE_GDRIVE).glob(\"*\")) / 1e9\n",
    "        print(f\"  Copying {cache_name} ({num_files} files, {total_size:.2f} GB)...\")\n",
    "        print(f\"  This may take a few minutes...\")\n",
    "        !rsync -ah --info=progress2 {KD_CACHE_GDRIVE}/ {LOCAL_CACHE}/\n",
    "        print(f\"  Done: {LOCAL_CACHE}\")\n",
    "    else:\n",
    "        print(f\"  Already exists: {LOCAL_CACHE}\")\n",
    "    \n",
    "    # Verify cache\n",
    "    print(f\"\\n  Cache contents:\")\n",
    "    !ls -la {LOCAL_CACHE} | head -5\n",
    "    if os.path.exists(f\"{LOCAL_CACHE}/meta.json\"):\n",
    "        print(f\"\\n  Meta:\")\n",
    "        !cat {LOCAL_CACHE}/meta.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build training command\n",
    "os.chdir(REPO_DIR)\n",
    "\n",
    "# Use local paths for faster I/O\n",
    "ckpt_path = LOCAL_CHECKPOINT if 'LOCAL_CHECKPOINT' in dir() else V2_CHECKPOINT_GDRIVE\n",
    "cache_path = LOCAL_CACHE if 'LOCAL_CACHE' in dir() else KD_CACHE_GDRIVE\n",
    "\n",
    "cmd = f\"\"\"\n",
    "PJRT_DEVICE=TPU python scripts/train_recovery_lora.py \\\\\n",
    "  --model {MODEL_ID} \\\\\n",
    "  --v2-checkpoint \"{ckpt_path}\" \\\\\n",
    "  --kd-cache-dir \"{cache_path}\" \\\\\n",
    "  --lora-mode kd \\\\\n",
    "  --recovery-r {RECOVERY_R} \\\\\n",
    "  {'--mlp-only' if MLP_ONLY else ''} \\\\\n",
    "  --seq-len {SEQ_LEN} \\\\\n",
    "  --batch-size {BATCH_SIZE} \\\\\n",
    "  --accumulation-steps {ACCUMULATION_STEPS} \\\\\n",
    "  --max-steps {MAX_STEPS} \\\\\n",
    "  --log-interval {LOG_INTERVAL} \\\\\n",
    "  --kd-temperature {KD_TEMPERATURE} --kd-alpha {KD_ALPHA} \\\\\n",
    "  --hard-top1 {HARD_TOP1} --hard-top1-end {HARD_TOP1_END} \\\\\n",
    "  --dropout {DROPOUT} \\\\\n",
    "  --lr {LR} --warmup-steps {WARMUP_STEPS} \\\\\n",
    "  --anchor-kl-weight {ANCHOR_KL_WEIGHT} --anchor-samples {ANCHOR_SAMPLES} \\\\\n",
    "  --save-steps {SAVE_STEPS} --keep-checkpoints {KEEP_CHECKPOINTS} \\\\\n",
    "  --output \"{OUTPUT_DIR}\"\n",
    "\"\"\"\n",
    "\n",
    "# Add wandb flags if configured\n",
    "if USE_WANDB:\n",
    "    cmd = cmd.rstrip() + f\" \\\\ \\n  --wandb --wandb-project {WANDB_PROJECT} --wandb-run {WANDB_RUN}\"\n",
    "\n",
    "print(\"Training command:\")\n",
    "print(cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Run training\n",
    "# Expected: ~30-60 min for 1200 steps on TPU v6e-1\n",
    "!{cmd}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Test Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find latest checkpoint\n",
    "from pathlib import Path\n",
    "\n",
    "output_path = Path(OUTPUT_DIR)\n",
    "checkpoints = sorted(output_path.glob(\"recovery_*.pt\"))\n",
    "\n",
    "if checkpoints:\n",
    "    LATEST_CKPT = str(checkpoints[-1])\n",
    "    print(f\"Found {len(checkpoints)} checkpoints\")\n",
    "    print(f\"Latest: {LATEST_CKPT}\")\n",
    "else:\n",
    "    print(\"No checkpoints found!\")\n",
    "    LATEST_CKPT = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test prompts for repetition + coherence evaluation\n",
    "TEST_PROMPTS = [\n",
    "    # Long-context coherence test\n",
    "    \"The ancient library contained thousands of scrolls. Among them was a rare manuscript describing a forgotten city. The city was said to have towers made of crystal. What material were the towers made of?\",\n",
    "    \n",
    "    # Repetition trigger test\n",
    "    \"List the first 10 prime numbers:\",\n",
    "    \n",
    "    # General knowledge\n",
    "    \"What is the capital of France?\",\n",
    "    \n",
    "    # Reasoning\n",
    "    \"If a train travels at 60 mph for 2 hours, how far does it go?\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with LoRA checkpoint\n",
    "if LATEST_CKPT:\n",
    "    print(\"=\" * 60)\n",
    "    print(\"TESTING WITH RECOVERY LoRA\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for i, prompt in enumerate(TEST_PROMPTS, 1):\n",
    "        print(f\"\\n[{i}/{len(TEST_PROMPTS)}] Prompt: {prompt[:80]}...\" if len(prompt) > 80 else f\"\\n[{i}/{len(TEST_PROMPTS)}] Prompt: {prompt}\")\n",
    "        print(\"-\" * 40)\n",
    "        !python scripts/test_inference.py \"{LATEST_CKPT}\" --prompt \"{prompt}\" --max-tokens 256 2>/dev/null | tail -10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare: Base (no LoRA) vs With LoRA\n",
    "base_ckpt = ckpt_path  # The original V2 checkpoint\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"COMPARISON: BASE vs LoRA\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "comparison_prompt = TEST_PROMPTS[0]  # Long-context test\n",
    "\n",
    "print(f\"\\nPrompt: {comparison_prompt}\")\n",
    "\n",
    "print(\"\\n--- BASE (no LoRA) ---\")\n",
    "!python scripts/test_inference.py \"{base_ckpt}\" --prompt \"{comparison_prompt}\" --max-tokens 256 2>/dev/null | tail -8\n",
    "\n",
    "if LATEST_CKPT:\n",
    "    print(\"\\n--- WITH LoRA ---\")\n",
    "    !python scripts/test_inference.py \"{LATEST_CKPT}\" --prompt \"{comparison_prompt}\" --max-tokens 256 2>/dev/null | tail -8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save to Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to Google Drive\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "\n",
    "# Output directory on Drive\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "GDRIVE_OUTPUT = f\"{GDRIVE_RUNS}/SR-011-lora-wikitext-L1024-{timestamp}\"\n",
    "\n",
    "os.makedirs(GDRIVE_OUTPUT, exist_ok=True)\n",
    "\n",
    "# Copy checkpoints\n",
    "output_path = Path(OUTPUT_DIR)\n",
    "if output_path.exists():\n",
    "    print(f\"Saving to: {GDRIVE_OUTPUT}\")\n",
    "    \n",
    "    for f in output_path.glob(\"*.pt\"):\n",
    "        dest = Path(GDRIVE_OUTPUT) / f.name\n",
    "        print(f\"  Copying {f.name}...\")\n",
    "        shutil.copy(f, dest)\n",
    "    \n",
    "    # Copy logs\n",
    "    for f in output_path.glob(\"*.csv\"):\n",
    "        shutil.copy(f, Path(GDRIVE_OUTPUT) / f.name)\n",
    "        print(f\"  Copied {f.name}\")\n",
    "    \n",
    "    for f in output_path.glob(\"*.json\"):\n",
    "        shutil.copy(f, Path(GDRIVE_OUTPUT) / f.name)\n",
    "        print(f\"  Copied {f.name}\")\n",
    "    \n",
    "    print(f\"\\nSaved to: {GDRIVE_OUTPUT}\")\n",
    "else:\n",
    "    print(f\"Output directory not found: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Plot Training Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "log_file = Path(OUTPUT_DIR) / \"training_log.csv\"\n",
    "if log_file.exists():\n",
    "    df = pd.read_csv(log_file)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "    \n",
    "    # Loss plot\n",
    "    axes[0].plot(df['step'], df['train_loss'], label='Train Loss', alpha=0.8)\n",
    "    if 'eval_loss' in df.columns:\n",
    "        axes[0].plot(df['step'], df['eval_loss'], label='Eval Loss', linestyle='--')\n",
    "    axes[0].set_xlabel('Step')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[0].set_title('Training Loss')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # LR plot\n",
    "    if 'lr' in df.columns:\n",
    "        axes[1].plot(df['step'], df['lr'], color='orange')\n",
    "        axes[1].set_xlabel('Step')\n",
    "        axes[1].set_ylabel('Learning Rate')\n",
    "        axes[1].set_title('Learning Rate Schedule')\n",
    "        axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nFinal loss: {df['train_loss'].iloc[-1]:.4f}\")\n",
    "    print(f\"Best loss:  {df['train_loss'].min():.4f}\")\n",
    "    print(f\"Steps:      {len(df)}\")\n",
    "else:\n",
    "    print(\"No training log found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Run 2 (Optional): Widen to Attention LoRA\n",
    "\n",
    "Only if Run 1 shows improvement but needs more capacity.\n",
    "\n",
    "- Remove `--mlp-only`\n",
    "- Lower LR to 5e-5\n",
    "- Shorter run (300-800 steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run 2: Attention + MLP LoRA (uncomment to run)\n",
    "\n",
    "# RUN2_CMD = f\"\"\"\n",
    "# PJRT_DEVICE=TPU python scripts/train_recovery_lora.py \\\\\n",
    "#   --model {MODEL_ID} \\\\\n",
    "#   --v2-checkpoint \"{ckpt_path}\" \\\\\n",
    "#   --kd-cache-dir \"{cache_path}\" \\\\\n",
    "#   --lora-mode kd \\\\\n",
    "#   --recovery-r 8 \\\\\n",
    "#   --seq-len 1024 \\\\\n",
    "#   --batch-size 4 \\\\\n",
    "#   --accumulation-steps 8 \\\\\n",
    "#   --max-steps 600 \\\\\n",
    "#   --log-interval 10 \\\\\n",
    "#   --kd-temperature 1.05 --kd-alpha 0.7 \\\\\n",
    "#   --hard-top1 0.01 --hard-top1-end 0.00 \\\\\n",
    "#   --dropout 0.05 \\\\\n",
    "#   --lr 5e-5 --warmup-steps 50 \\\\\n",
    "#   --anchor-kl-weight 0.01 --anchor-samples 32 \\\\\n",
    "#   --save-steps 100 --keep-checkpoints 5 \\\\\n",
    "#   --output \"runs/lora_wikitext1024_r8_full\" \\\\\n",
    "#   --wandb --wandb-project {WANDB_PROJECT} --wandb-run \"lora_wikitext_L1024_r8_full\"\n",
    "# \"\"\"\n",
    "# print(\"Run 2 command (attention + MLP):\")\n",
    "# print(RUN2_CMD)\n",
    "# # !{RUN2_CMD}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Notes\n",
    "\n",
    "**TPU v6e-1 Memory:**\n",
    "- Single chip: ~16GB HBM\n",
    "- Batch 4 x L1024 x accum 8 = 32K tokens/update should fit\n",
    "\n",
    "**What to evaluate after training:**\n",
    "1. Long prompt with detail early, question late\n",
    "2. Known repetition triggers\n",
    "3. ANE reproduction prompts (if available)\n",
    "\n",
    "**If repetition improves on TPU but ANE still loops:**\n",
    "- Run Phase 2 targeting attention LoRA\n",
    "- Check if ANE has different numeric behavior"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V6E",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}